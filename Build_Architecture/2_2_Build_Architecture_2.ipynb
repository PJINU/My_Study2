{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_2_Build_Architecture_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Build Architecture2 - 모델 디버그를 위한 shape출력\n",
        "- 레이어가 많아질 경우 어떻게 할 것인가?\n",
        "- 모든 레이어를 다 작성할 것인지?\n",
        "- 디버그를 위한 shape 출력문은 어떻게 만들 것인지?\n",
        "- 여러개의 레이어를 통과시킨 후 merge할 경우"
      ],
      "metadata": {
        "id": "g3_vLHYFyd6Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "v49Sp7BrUJmv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 임의의 데이터 생성\n",
        "\n",
        "input_data = torch.randn((1,3,244,244))\n",
        "\n",
        "print(input_data.shape)\n",
        "print(input_data.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANuzUO-EUS1y",
        "outputId": "1a5c74a7-a523-4b29-90fb-84db5c866f3c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 244, 244])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 리스트 활용\n",
        "- 리스트(or nn.ModuleList)에 layer를 담아 활용하기\n",
        "- forward 함수(디버그)\n",
        "    - for문을 통해 리스트에서 레이어를 하나씩 가져오고 -> 각 레이어마다 shape을 확인\n",
        "\n",
        "- forward 함수(디버그 완료 후)\n",
        "    - nn.Sequential"
      ],
      "metadata": {
        "id": "J4mIzQRTsDFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ModuleList를 활용\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = [nn.Conv2d(3,5,kernel_size=3),\n",
        "                  nn.ReLU()]\n",
        "        self.layers2 = [nn.Conv2d(3,7,kernel_size=3),\n",
        "                   nn.Conv2d(7,5,kernel_size=1),\n",
        "                   nn.ReLU()]\n",
        "\n",
        "        # 두 개의 레이어에 각각 통과시킨 후 merge하기\n",
        "        self.modules1 = nn.ModuleList(self.layers)\n",
        "        self.modules2 = nn.ModuleList(self.layers2)\n",
        "\n",
        "        self.seq1 = nn.Sequential(*self.layers)\n",
        "        self.seq2 = nn.Sequential(*self.layers2)\n",
        "\n",
        "        self.fc1 = nn.Linear(5*242*242, 512)\n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "        for idx, module1 in enumerate(self.modules1):\n",
        "            if idx == 0:\n",
        "                x1 =  module1(x)\n",
        "            else:\n",
        "                x1 = module1(x1)\n",
        "            print('x1.shape :', x1.shape)\n",
        "\n",
        "        for idx, module2 in enumerate(self.modules2):\n",
        "            if idx == 0:\n",
        "                x2 = module2(x)\n",
        "            else:\n",
        "                x2 = module2(x2)\n",
        "            print('x2 :', x2.shape)\n",
        "\n",
        "        # merge(addtion)\n",
        "        conv_out = x1 + x2\n",
        "        print('conv_out :', conv_out.shape)\n",
        "\n",
        "        fc_input = conv_out.view(conv_out.size(0), -1)\n",
        "        print('fc_input:', fc_input.shape)\n",
        "        fc_output = self.fc1(fc_input)\n",
        "        print(fc_output.shape)\n",
        "\n",
        "        return fc_output"
      ],
      "metadata": {
        "id": "y20e5zsRi0JC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQT7u4RxmYlJ",
        "outputId": "9a121047-fcf5-4d9e-e139-8a74daa3a1c1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (modules1): ModuleList(\n",
              "    (0): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (modules2): ModuleList(\n",
              "    (0): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): Conv2d(7, 5, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (seq1): Sequential(\n",
              "    (0): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (seq2): Sequential(\n",
              "    (0): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): Conv2d(7, 5, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (fc1): Linear(in_features=292820, out_features=512, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model(input_data)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIiiSrrVmfec",
        "outputId": "f99c35c8-9fe4-45ee-b520-30e89bf5a627"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x1.shape : torch.Size([1, 5, 242, 242])\n",
            "x1.shape : torch.Size([1, 5, 242, 242])\n",
            "x2 : torch.Size([1, 7, 242, 242])\n",
            "x2 : torch.Size([1, 5, 242, 242])\n",
            "x2 : torch.Size([1, 5, 242, 242])\n",
            "conv_out : torch.Size([1, 5, 242, 242])\n",
            "fc_input: torch.Size([1, 292820])\n",
            "torch.Size([1, 512])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.1551e-01,  2.5978e-01,  2.3493e-01, -1.8462e-01, -1.6629e-01,\n",
              "         -2.3492e-01, -2.3347e-01, -1.4957e-01, -1.3519e-01, -4.5818e-02,\n",
              "          1.0914e-02, -2.0891e-01,  1.0223e-01, -4.3385e-01,  6.3775e-01,\n",
              "          1.9781e-01,  8.7146e-02, -3.5904e-01, -3.4130e-01,  2.9791e-01,\n",
              "          1.5553e-01, -2.6370e-01,  3.1170e-01, -9.0019e-02,  5.0368e-02,\n",
              "          3.0533e-01,  3.0194e-01,  2.3758e-01, -2.0877e-01, -4.6861e-01,\n",
              "          3.6627e-01,  2.5046e-01,  3.8613e-01, -2.9908e-02,  1.8210e-01,\n",
              "         -2.0361e-01, -2.9469e-01, -5.3945e-01, -1.2438e-02,  2.8009e-01,\n",
              "         -2.2920e-01, -1.3573e-01,  5.9221e-01, -3.1375e-01, -3.5598e-01,\n",
              "         -1.1571e+00,  1.9777e-01,  3.5915e-02,  5.4564e-01, -2.4963e-01,\n",
              "         -1.0737e-01,  3.0913e-01, -3.4046e-01,  2.8810e-01, -2.1276e-01,\n",
              "         -1.5422e-01,  2.0147e-01, -1.8585e-01,  7.9911e-02,  2.4307e-01,\n",
              "          4.0571e-01,  5.5964e-02,  1.8388e-01, -5.2872e-01, -3.1467e-01,\n",
              "          2.3075e-01, -2.5623e-01,  1.6111e-01, -1.4145e-01, -5.9480e-02,\n",
              "          1.6636e-01, -3.5647e-02, -3.6786e-02,  6.2423e-01,  3.0162e-02,\n",
              "         -4.3288e-01, -5.5036e-02,  3.2891e-02,  1.6966e-01,  6.3773e-01,\n",
              "          1.7920e-01, -5.5553e-01,  2.1856e-01,  4.6011e-01,  1.9255e-01,\n",
              "         -4.6247e-02, -6.1956e-02,  2.5384e-02,  1.5563e-01,  1.5316e-01,\n",
              "         -2.6988e-01,  3.9035e-01,  5.3968e-02, -1.4640e-01, -4.0463e-01,\n",
              "         -2.8090e-01,  2.4120e-02, -3.5004e-01, -3.2851e-01, -8.9977e-03,\n",
              "         -9.6955e-02,  5.0988e-02,  3.1520e-01,  7.5880e-02,  3.9155e-02,\n",
              "          1.0255e-01, -2.8224e-01, -1.8677e-02,  1.1226e-01, -3.2894e-01,\n",
              "         -4.4775e-02,  1.0037e-01,  5.3479e-01, -4.7324e-01,  2.5569e-01,\n",
              "          8.5601e-02, -2.5348e-01, -5.7602e-01,  3.9857e-01,  2.6275e-02,\n",
              "         -3.8359e-01,  1.6201e-01,  3.7647e-01,  3.4799e-01,  2.1161e-01,\n",
              "         -3.4556e-01, -1.5886e-01, -2.4208e-02, -1.7292e-01,  4.1115e-01,\n",
              "          4.8581e-01, -2.0407e-01, -4.1879e-02, -1.6321e-01,  2.3403e-01,\n",
              "         -6.8618e-02,  5.6707e-01,  7.2651e-02,  9.9834e-02, -1.1037e-01,\n",
              "          2.7195e-01,  4.4260e-01, -3.2277e-01,  6.6627e-01,  2.4367e-01,\n",
              "         -2.7072e-01,  9.1562e-02, -8.9555e-02,  5.1892e-01, -6.8662e-02,\n",
              "         -2.7820e-01,  3.6893e-01, -4.8585e-01, -4.1237e-01,  1.9628e-01,\n",
              "          1.5701e-01,  2.3401e-01, -3.9391e-01, -8.0020e-02,  1.3133e-01,\n",
              "          2.1227e-01,  5.1058e-02, -3.5770e-02,  1.4699e-01,  1.2040e-01,\n",
              "         -1.7524e-01,  2.6269e-01,  1.5231e-01,  1.4026e-01, -1.3123e-01,\n",
              "         -1.4701e-01,  5.2791e-02,  1.3236e-01, -1.7925e-01,  1.7837e-01,\n",
              "         -6.0123e-01,  2.5500e-01, -1.7937e-01,  3.1009e-01,  2.4715e-01,\n",
              "          1.5213e-01,  1.5010e-01, -3.7760e-02,  5.1433e-01, -3.8316e-03,\n",
              "          3.5661e-01, -2.9831e-02, -7.3014e-01,  5.3373e-02,  4.9016e-01,\n",
              "         -2.4477e-01, -1.3793e-01,  2.3845e-01,  4.2232e-01, -4.7529e-01,\n",
              "          1.3015e-02, -1.8126e-01, -5.8853e-01,  2.0397e-01,  1.4484e-01,\n",
              "         -7.1358e-02, -1.6991e-02, -1.6031e-01,  9.8295e-02, -5.3587e-01,\n",
              "          2.8090e-01, -1.2279e-01, -2.9810e-01,  5.3772e-01,  2.3566e-02,\n",
              "         -2.5264e-01, -1.3973e-01, -3.1361e-01,  1.1869e-01, -1.6852e-01,\n",
              "         -2.8048e-01, -4.1249e-01, -4.3574e-01,  1.5692e-01,  2.3519e-01,\n",
              "          2.1159e-01,  9.4896e-02,  2.3757e-01,  1.6642e-01,  2.0477e-01,\n",
              "         -2.8289e-01,  1.1057e-01,  6.5335e-01, -9.6205e-03, -5.3444e-02,\n",
              "          3.8846e-01, -3.1740e-02, -3.0845e-01, -9.1531e-03, -4.9157e-02,\n",
              "          4.9108e-02, -8.6941e-02, -1.3873e-01, -2.1005e-01,  5.4634e-01,\n",
              "         -2.7334e-02,  6.3679e-01, -3.7899e-02,  4.7543e-02,  6.4372e-02,\n",
              "          2.4981e-01, -5.2199e-01,  1.8608e-01, -4.5801e-01, -5.5423e-02,\n",
              "         -8.6961e-01,  8.0447e-02,  2.6915e-01, -6.3557e-03, -1.8720e-01,\n",
              "          3.8508e-01, -2.0497e-01,  5.0074e-01, -1.1191e-01, -1.2113e-01,\n",
              "          1.5117e-01, -1.3610e-01, -1.3929e-01,  3.2205e-01,  4.4675e-01,\n",
              "          3.2005e-01, -1.1200e+00,  2.4459e-01, -2.3960e-01,  1.4761e-01,\n",
              "         -1.9818e-01,  3.8721e-01, -7.8790e-02, -3.0335e-01,  3.1052e-03,\n",
              "          5.6031e-01, -1.6899e-01,  3.5109e-01,  7.3397e-01, -1.3842e-01,\n",
              "          2.3323e-01,  3.6416e-02, -1.4818e-01, -1.2083e-01,  5.2853e-02,\n",
              "         -2.2786e-01, -5.4486e-01,  5.2827e-01,  4.3377e-01, -6.7547e-02,\n",
              "          5.6642e-02, -3.5313e-01, -7.5223e-01, -1.4324e-01, -1.7058e-01,\n",
              "          2.6299e-02,  3.8023e-01, -6.0128e-02, -6.3179e-02,  2.0610e-01,\n",
              "          7.9889e-02,  3.9375e-01, -2.1303e-01,  3.2104e-02, -2.5147e-01,\n",
              "         -2.5727e-01, -9.2258e-02,  4.0772e-02,  3.0668e-01,  3.5203e-01,\n",
              "         -2.1772e-01,  1.9502e-01,  5.4299e-01,  2.4652e-01,  2.6479e-02,\n",
              "          1.0955e-01,  1.3454e-01,  9.5981e-02,  5.0680e-01, -3.1583e-01,\n",
              "         -3.4986e-02,  4.9530e-01, -6.0687e-01,  4.4143e-01,  6.9036e-02,\n",
              "          5.3587e-01, -1.6400e-01,  1.6696e-01,  2.6051e-02, -1.5460e-01,\n",
              "         -1.5803e-01,  1.2401e-01, -7.8446e-02, -3.3449e-01,  1.6352e-01,\n",
              "          2.4625e-01, -7.0795e-02, -1.0646e-01,  4.9315e-02,  4.4484e-01,\n",
              "          3.3034e-01, -4.2947e-01,  4.2050e-01, -4.2615e-01,  6.9939e-02,\n",
              "         -3.4888e-01, -5.8744e-02,  1.2476e-01,  9.7349e-03, -8.3433e-02,\n",
              "         -4.9494e-02,  1.6311e-01,  1.3397e-01,  2.9031e-01, -3.6046e-01,\n",
              "         -1.8373e-01, -1.4269e-01,  1.4888e-01, -1.7063e-01, -9.9957e-02,\n",
              "          5.7904e-01,  1.6131e-01,  1.3451e-01, -3.7994e-01,  3.2110e-01,\n",
              "          1.0177e+00, -2.8511e-01,  8.6732e-02, -2.4806e-01,  1.3357e-01,\n",
              "         -2.8441e-01, -4.4905e-01,  4.5513e-02,  2.9604e-02,  3.3574e-01,\n",
              "          3.4225e-03,  2.3094e-01,  3.9893e-01,  3.0492e-01,  3.6377e-01,\n",
              "          1.3950e-01, -3.0358e-01,  3.7988e-01,  1.4480e-01, -2.0903e-01,\n",
              "         -2.6413e-01, -2.5949e-01,  3.3004e-01, -5.7757e-01, -3.2316e-01,\n",
              "         -3.6223e-01,  2.6731e-01, -2.7399e-01, -5.2850e-01,  3.4162e-01,\n",
              "          4.7765e-02,  2.4998e-01, -4.6549e-03, -3.5811e-01, -6.2641e-01,\n",
              "         -2.9520e-01, -5.6078e-01, -4.8037e-01,  2.9082e-01,  8.8731e-02,\n",
              "         -7.6435e-02, -7.5603e-03, -5.1692e-02, -1.8672e-01,  4.7299e-01,\n",
              "         -1.7811e-01, -2.2388e-02,  2.6885e-01,  8.4637e-02, -1.6106e-01,\n",
              "         -5.7056e-02, -5.2541e-01,  6.8798e-01,  6.7443e-01,  5.3966e-01,\n",
              "          6.4143e-02,  2.3017e-01,  7.3973e-02, -1.2848e-01, -2.0581e-02,\n",
              "          3.1454e-01, -1.5955e-04, -5.5004e-02, -8.3694e-02, -2.1400e-01,\n",
              "         -7.3255e-01, -1.5526e-01,  2.2234e-01,  6.2161e-03, -2.2045e-01,\n",
              "          1.1305e-01, -4.8110e-01, -1.7359e-02,  3.9656e-02, -1.6192e-01,\n",
              "         -3.6960e-02,  2.2425e-01,  4.0685e-01,  8.0195e-02, -4.8942e-01,\n",
              "          3.4370e-01,  1.1973e-01,  4.5185e-01,  4.1235e-01,  1.4001e-01,\n",
              "         -9.3881e-02,  2.6343e-01,  7.3095e-02, -2.0664e-01,  1.4802e-01,\n",
              "          2.8365e-01, -1.3166e-01, -1.2903e-01, -4.3768e-01,  4.4646e-01,\n",
              "          8.3040e-02, -4.8759e-02,  2.0703e-01,  7.6282e-02,  3.0298e-01,\n",
              "          3.0332e-01, -3.7511e-01,  1.5222e-01, -1.2717e-01,  2.1704e-01,\n",
              "          3.5154e-01,  6.5919e-02, -2.0728e-01, -8.4189e-02, -5.4953e-02,\n",
              "          1.2361e-01, -2.1972e-01,  2.8516e-01, -1.6292e-01,  2.1869e-01,\n",
              "          2.8388e-03,  7.7268e-02,  3.8394e-01, -1.3939e-02,  2.5019e-01,\n",
              "         -3.9747e-01, -7.2032e-02,  1.3173e-01, -4.1299e-01,  9.0552e-02,\n",
              "          1.5890e-01,  1.1778e-01,  7.4027e-01,  2.7963e-01,  2.2246e-01,\n",
              "          4.8984e-01,  3.1620e-02,  5.7733e-02,  1.0762e-01,  3.7431e-01,\n",
              "         -1.9598e-01, -2.1386e-01,  2.0325e-01, -3.7488e-02,  1.6733e-01,\n",
              "         -1.4060e-02,  2.6993e-01, -5.0116e-01,  1.8338e-01,  1.7543e-01,\n",
              "         -5.6870e-02, -4.2622e-01]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cat n Dog 데이터셋 실습"
      ],
      "metadata": {
        "id": "pNxfmY76uz6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.frame import DataFrame\n",
        "paths = []\n",
        "dataset_type = []\n",
        "labels = []\n",
        "\n",
        "for dirname, _, filenames in os.walk('/content/drive/MyDrive/고모부_머신러닝/dogncat'):\n",
        "    for filename in filenames:\n",
        "        filepath = dirname + '/' + filename\n",
        "        paths.append(filepath)\n",
        "\n",
        "        if '/training_set' in filepath:\n",
        "            dataset_type.append('train')\n",
        "\n",
        "        elif '/test_set' in filepath:\n",
        "            dataset_type.append('test')\n",
        "\n",
        "        if 'dogs' in filepath:\n",
        "            labels.append('DOG')\n",
        "        \n",
        "        elif 'cats' in filepath:\n",
        "            labels.append('CAT')\n",
        "\n",
        "print(len(paths))\n",
        "print(len(dataset_type))\n",
        "print(len(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ePcHC6mxOHm",
        "outputId": "ea1f4a13-a570-4520-ffe7-e0a408f6f128"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10032\n",
            "10032\n",
            "10032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnd_df = pd.DataFrame({'path' : paths, 'type' : dataset_type, 'label' : labels})\n",
        "cnd_df.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "r8OrH6pifV_H",
        "outputId": "e4edd2fa-0894-4911-d07c-439703053881"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 path  type label\n",
              "0   /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "1   /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "2   /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "3   /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "4   /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "5   /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "6   /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "7   /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "8   /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "9   /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "10  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "11  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "12  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "13  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "14  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "15  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "16  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "17  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "18  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "19  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13cd9768-fd22-4d0c-86b0-239fb997213f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>type</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13cd9768-fd22-4d0c-86b0-239fb997213f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-13cd9768-fd22-4d0c-86b0-239fb997213f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-13cd9768-fd22-4d0c-86b0-239fb997213f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# '.jpg'를 포함하는 path만 df로 만들기\n",
        "filter = cnd_df['path'].str.contains('.jpg') \n",
        "cnd_df = cnd_df[filter]"
      ],
      "metadata": {
        "id": "SfFiuh0Sf0bv"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnd_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lt_VHOqhhY6A",
        "outputId": "2bbddcae-e18f-46e2-e96c-301cb58d75ac"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10028, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train, testset으로 분리\n",
        "train_df = cnd_df[cnd_df['type'] == 'train']\n",
        "test_df = cnd_df[cnd_df['type'] == 'test']\n",
        "\n",
        "train_path = train_df['path'].values\n",
        "test_path = test_df['path'].values\n",
        "\n",
        "train_label = train_df['label'].values\n",
        "test_label = test_df['label'].values"
      ],
      "metadata": {
        "id": "sKp5R02V2y8E"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(cv2.imread(train_path[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1u8bZn2Jk9OK",
        "outputId": "0444cf26-854b-49e5-8ab3-d7a5d02cb39e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 만들기\n",
        "\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import cv2\n",
        "\n",
        "class CndDataset(Dataset):\n",
        "    def __init__(self, paths, labels):\n",
        "        super(CndDataset, self).__init__()\n",
        "        self.path = paths\n",
        "        self.label = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.path)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = cv2.cvtColor(cv2.imread(self.path[idx]), cv2.COLOR_BGR2RGB)\n",
        "        image = cv2.resize(image, (244, 244))\n",
        "        image = np.asarray(image, dtype=np.float32).transpose(2,0,1)\n",
        "\n",
        "        if self.label is not None:\n",
        "            label = self.label[idx]\n",
        "\n",
        "        return image, label\n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "JU521EL43kKt"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnd_dataset = CndDataset(train_path, train_label)\n",
        "loader = DataLoader(cnd_dataset, batch_size=10, shuffle=True)\n",
        "i, l = next(iter(loader))\n",
        "print(i.view(i.size(0),-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omcMOv2c--C2",
        "outputId": "954efb90-0bbc-454f-b8a5-d8b0757ad404"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[217., 217., 218.,  ..., 249., 248., 247.],\n",
            "        [ 14.,  17.,  18.,  ...,  35.,  31.,  32.],\n",
            "        [125., 125., 124.,  ..., 216., 217., 220.],\n",
            "        ...,\n",
            "        [ 55.,  55.,  55.,  ..., 142., 144., 155.],\n",
            "        [242., 244., 250.,  ...,  83.,  55.,  77.],\n",
            "        [ 85.,  46.,  31.,  ..., 117.,  98., 133.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = [nn.Conv2d(3,5,kernel_size=3),\n",
        "                  nn.ReLU()]\n",
        "        self.layers2 = [nn.Conv2d(3,7,kernel_size=3),\n",
        "                   nn.Conv2d(7,5,kernel_size=1),\n",
        "                   nn.ReLU()]\n",
        "\n",
        "        # 두 개의 레이어에 각각 통과시킨 후 merge하기\n",
        "        self.modules1 = nn.ModuleList(self.layers)\n",
        "        self.modules2 = nn.ModuleList(self.layers2)\n",
        "\n",
        "        self.seq1 = nn.Sequential(*self.layers)\n",
        "        self.seq2 = nn.Sequential(*self.layers2)\n",
        "\n",
        "        self.fc1 = nn.Linear(5 * 242 * 242, 512)\n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "        print('input_image_shape :', x.shape)\n",
        "        print('input_image_max :', torch.amax(x, dim=(1,2,3)))\n",
        "        print('input_image_min :', torch.amin(x, dim=(1,2,3)))\n",
        "        print('input_image_l2_norm :', torch.linalg.vector_norm(x, dim=(1,2,3)))\n",
        "        print()\n",
        "\n",
        "        for idx, module1 in enumerate(self.modules1):\n",
        "            if idx == 0:\n",
        "                x1 =  module1(x)\n",
        "            else:\n",
        "                x1 = module1(x1)\n",
        "            print('x1.shape :', x1.shape)\n",
        "            print('x1_max :', torch.amax(x1, dim=(1,2,3)))\n",
        "            print('x1_min :', torch.amin(x1, dim=(1,2,3)))\n",
        "            print('x1_l2_norm :', torch.linalg.vector_norm(x1, dim=(1,2,3)))\n",
        "            print()\n",
        "\n",
        "        for idx, module2 in enumerate(self.modules2):\n",
        "            if idx == 0:\n",
        "                x2 = module2(x)\n",
        "            else:\n",
        "                x2 = module2(x2)\n",
        "            print('x2.shape :', x2.shape)\n",
        "            print('x2_max :', torch.amax(x2, dim=(1,2,3)))\n",
        "            print('x2_min :', torch.amin(x2, dim=(1,2,3)))\n",
        "            print('x2_l2_norm :', torch.linalg.vector_norm(x2, dim=(1,2,3)))\n",
        "            print()\n",
        "\n",
        "        # merge(addtion)\n",
        "        conv_out = x1 + x2\n",
        "        print('conv_out :', conv_out.shape)\n",
        "        print('conv_out_max :', torch.amax(conv_out, dim=(1,2,3)))\n",
        "        print('conv_out_min :', torch.amin(conv_out, dim=(1,2,3)))\n",
        "        print('conv_out_l2_norm :', torch.linalg.vector_norm(conv_out, dim=(1,2,3)))\n",
        "        print()\n",
        "        \n",
        "        fc_input = conv_out.view(conv_out.size(0), -1)\n",
        "        print('fc_input:', fc_input.shape)\n",
        "        print('fc_input_max :', torch.amax(fc_input, dim=(1)))\n",
        "        print('fc_input_min :', torch.amin(fc_input, dim=(1)))\n",
        "        print('fc_input_l2_norm :', torch.linalg.vector_norm(fc_input, dim=(1)))\n",
        "        print()\n",
        "\n",
        "        fc_output = self.fc1(fc_input)\n",
        "        print('fc_output :', fc_output.shape)\n",
        "        print('fc_output_max :', torch.amax(fc_output, dim=(1)))\n",
        "        print('fc_output_min :', torch.amin(fc_output, dim=(1)))\n",
        "        print('fc_output_l2_norm :', torch.linalg.vector_norm(fc_output, dim=(1)))\n",
        "        print()\n",
        "\n",
        "        # return fc_output"
      ],
      "metadata": {
        "id": "uS90Asd9BID8"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnd_model = CNN2()\n",
        "cnd_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVbXCIXjBQWk",
        "outputId": "1c6dc103-b0ed-47df-a683-f3d4d4fdc59c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN2(\n",
              "  (modules1): ModuleList(\n",
              "    (0): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (modules2): ModuleList(\n",
              "    (0): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): Conv2d(7, 5, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (seq1): Sequential(\n",
              "    (0): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (seq2): Sequential(\n",
              "    (0): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): Conv2d(7, 5, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (fc1): Linear(in_features=292820, out_features=512, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### feature map 데이터의 특성을 파악하기\n",
        "\n",
        "- 각 배치 내에서 모든 과정의 min 값과 max값을 출력\n",
        "\n",
        "- 각 배치 내에서 모든 과정의 l2 norm을 프린트해보기"
      ],
      "metadata": {
        "id": "nswIQT7_Ivc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_array, image_label = next(iter(loader))\n",
        "cnd_model(image_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSRFLG6LAk5-",
        "outputId": "120e10d2-19f8-4ecd-c3fc-2917787e166f"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_image_shape : torch.Size([10, 3, 244, 244])\n",
            "input_image_max : tensor([255., 255., 255., 242., 249., 253., 255., 255., 255., 255.])\n",
            "input_image_min : tensor([0., 4., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
            "input_image_l2_norm : tensor([54412.6055, 67641.2422, 52337.1367, 50719.5391, 59310.3633, 45167.4453,\n",
            "        53339.7852, 72071.0703, 43673.6094, 62296.3203])\n",
            "\n",
            "x1.shape : torch.Size([10, 5, 242, 242])\n",
            "x1_max : tensor([218.3160, 252.0642, 228.9841, 203.2696, 196.6485, 219.1621, 277.1967,\n",
            "        222.3608, 233.2589, 239.1934], grad_fn=<AmaxBackward0>)\n",
            "x1_min : tensor([-129.0866, -164.9603, -137.0276, -118.7575, -105.3153, -139.9174,\n",
            "        -220.2619, -138.9643, -149.8814, -146.0530], grad_fn=<AminBackward0>)\n",
            "x1_l2_norm : tensor([30677.2031, 38855.7578, 29369.9277, 27775.2031, 34202.7656, 26326.6367,\n",
            "        31269.0137, 41243.7266, 25910.0488, 35890.1680],\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "x1.shape : torch.Size([10, 5, 242, 242])\n",
            "x1_max : tensor([218.3160, 252.0642, 228.9841, 203.2696, 196.6485, 219.1621, 277.1967,\n",
            "        222.3608, 233.2589, 239.1934], grad_fn=<AmaxBackward0>)\n",
            "x1_min : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<AminBackward0>)\n",
            "x1_l2_norm : tensor([26983.8926, 34256.9883, 25837.2441, 24374.4941, 29224.2656, 23074.0488,\n",
            "        27480.5918, 36665.2148, 22579.8652, 31439.4531],\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "x2.shape : torch.Size([10, 7, 242, 242])\n",
            "x2_max : tensor([219.3474, 228.0883, 214.0720, 191.7585, 179.1893, 190.4005, 268.7313,\n",
            "        256.3678, 207.0581, 219.0295], grad_fn=<AmaxBackward0>)\n",
            "x2_min : tensor([-241.4983, -260.4611, -241.2009, -225.1358, -217.2334, -220.5914,\n",
            "        -283.3533, -236.4785, -250.6812, -248.2899], grad_fn=<AminBackward0>)\n",
            "x2_l2_norm : tensor([49659.6016, 62897.9961, 48685.0469, 50160.0664, 51542.7930, 41542.6211,\n",
            "        50171.9766, 70139.5078, 40291.9570, 58523.2539],\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "x2.shape : torch.Size([10, 5, 242, 242])\n",
            "x2_max : tensor([ 77.5459,  99.8420,  89.0007,  80.1776,  64.6160,  91.3215, 124.4683,\n",
            "         83.8865,  89.1567,  95.6758], grad_fn=<AmaxBackward0>)\n",
            "x2_min : tensor([ -44.4493,  -62.2443,  -48.8707,  -44.6194,  -48.2912,  -81.6877,\n",
            "        -114.7856,  -61.6207,  -69.9727,  -70.1806], grad_fn=<AminBackward0>)\n",
            "x2_l2_norm : tensor([11952.7070, 15311.1768, 12165.6221, 13937.3613, 12043.2324,  9885.4902,\n",
            "        12500.9648, 17932.9863, 10154.7812, 14956.4512],\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "x2.shape : torch.Size([10, 5, 242, 242])\n",
            "x2_max : tensor([ 77.5459,  99.8420,  89.0007,  80.1776,  64.6160,  91.3215, 124.4683,\n",
            "         83.8865,  89.1567,  95.6758], grad_fn=<AmaxBackward0>)\n",
            "x2_min : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<AminBackward0>)\n",
            "x2_l2_norm : tensor([11809.8018, 14978.4414, 11916.4062, 13259.9395, 11938.1074,  9739.3604,\n",
            "        12105.7725, 17347.3008,  9815.7754, 14526.2744],\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "conv_out : torch.Size([10, 5, 242, 242])\n",
            "conv_out_max : tensor([218.3160, 261.3288, 241.0972, 203.2696, 202.5533, 219.1621, 282.2489,\n",
            "        222.3608, 258.2584, 252.8215], grad_fn=<AmaxBackward0>)\n",
            "conv_out_min : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<AminBackward0>)\n",
            "conv_out_l2_norm : tensor([30505.4746, 39003.7227, 29542.5801, 29509.3438, 32433.8223, 25977.8789,\n",
            "        31638.6816, 43241.8320, 25706.8340, 36221.3477],\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "fc_input: torch.Size([10, 292820])\n",
            "fc_input_max : tensor([218.3160, 261.3288, 241.0972, 203.2696, 202.5533, 219.1621, 282.2489,\n",
            "        222.3608, 258.2584, 252.8215], grad_fn=<AmaxBackward0>)\n",
            "fc_input_min : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<AminBackward0>)\n",
            "fc_input_l2_norm : tensor([30505.4746, 39003.7227, 29542.5801, 29509.3438, 32433.8223, 25977.8789,\n",
            "        31638.6816, 43241.8320, 25706.8340, 36221.3477],\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "fc_output : torch.Size([10, 512])\n",
            "fc_output_max : tensor([111.0508, 126.3922, 103.0185, 101.3951, 120.1261,  88.4049, 120.2364,\n",
            "        160.5165,  90.3022, 120.1767], grad_fn=<AmaxBackward0>)\n",
            "fc_output_min : tensor([-102.0287, -128.5763,  -85.8614,  -74.6405,  -83.9676,  -81.2265,\n",
            "        -105.4163, -124.0931,  -80.9057, -112.9302], grad_fn=<AminBackward0>)\n",
            "fc_output_l2_norm : tensor([ 725.0814,  917.1143,  684.8104,  658.5659,  772.7447,  615.8710,\n",
            "         748.9176, 1006.9962,  630.3348,  835.9072],\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Activation Neuron 확인\n",
        "\n",
        "- 1. 몇개의 뉴런이 activation되는지 print \n",
        "- 2. activation map을 확인하는 과정이 중요\n",
        "    - relu를 지나고 나서 어떤 neuron이 activation이 되는지 확인하는 과정\n",
        "\n",
        "- 3. class activation map\n",
        "    - 클래스가 들어왔을 떄 어떤 뉴런이 activation 되는지\n",
        "    - ex) 개일떄 활성화되는 뉴런과 고양이 일 때 활성화되는 뉴런이 다를 때 가장 좋은 것\n"
      ],
      "metadata": {
        "id": "H3MD04K9niac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layers = [nn.Conv2d(3, 10, [5,5], padding='same')]\n",
        "layers.append(nn.ReLU())\n",
        "layers.append(nn.Conv2d(10, 20, [5,5], stride=2))\n",
        "layers.append(nn.ReLU())\n"
      ],
      "metadata": {
        "id": "Z2dY7f-aN54g"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modules = nn.ModuleList(layers)"
      ],
      "metadata": {
        "id": "bhjMj1kcAeAt"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq = nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "belmWoZ0AfGr"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn([1,3,224,224])\n",
        "print(input.shape)\n",
        "print(input.dtype)\n",
        "print(type(input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3O_BAZEA_Ko",
        "outputId": "f5662d5c-a517-42d8-e7b8-0ecd37cd7606"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 224, 224])\n",
            "torch.float32\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = seq(input)"
      ],
      "metadata": {
        "id": "7_MFKPjqA086"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYDQalAQBHmh",
        "outputId": "b6dfc7e3-e816-490f-e740-a7b9e64def1c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 20, 110, 110])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "o = modules[0](input)\n",
        "o.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASVlz-O2B7go",
        "outputId": "db01517a-5445-49fa-cf40-1d9fb97eeb42"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "o = modules[1](input)\n",
        "o.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiNEt1MeCIUI",
        "outputId": "2740d689-0953-4af4-fec4-4c0ce198fbf7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "o = modules[2](0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "2he7hYOaCLNR",
        "outputId": "150959c4-6077-4c1f-faeb-2f221eb4fee8"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-f11cd1de3f55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    443\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 444\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (int, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!int!, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!int!, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 디버그하는 방법. list를 돌면서 하나씩 확인\n",
        "\n",
        "def forward(input):\n",
        "    x = input\n",
        "    for module in modules:\n",
        "        x = module(x)\n",
        "        print()"
      ],
      "metadata": {
        "id": "5btexOAACMvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 디버그가 완료된 후 nn.Sequential을 사용\n",
        "\n",
        "def forward(input):\n",
        "    x = input\n",
        "    for layer in seq:\n",
        "        x = module(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "dHIO_fVZDfXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-ujUQIEXyD8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet 구현해보기\n",
        "- 참조  \n",
        "    https://towardsdev.com/implement-resnet-with-pytorch-a9fb40a77448"
      ],
      "metadata": {
        "id": "7WAzMGfsiKS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PrintShape(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PrintShape, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(x.shape)\n",
        "        return x"
      ],
      "metadata": {
        "id": "HRY4_5y6IePF"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.batchnorm import BatchNorm2d\n",
        "import torch.nn.functional as F\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsample):\n",
        "        super(ResBlock, self).__init__()\n",
        "        if downsample:\n",
        "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "        else:\n",
        "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "            self.shortcut = nn.Sequential(\n",
        "                # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1),\n",
        "                # nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = self.shortcut(x)\n",
        "        # print('shortcut :', shortcut.size())\n",
        "        x = self.bn1(self.conv1(x))\n",
        "        x = F.ReLU(x)\n",
        "        # print('conv1 :', x.size())\n",
        "        x = self.bn2(self.conv2(x))\n",
        "        x = F.ReLU(x)\n",
        "        # print('conv2 :', x.size())\n",
        "        output = shortcut + x\n",
        "        # print('output :', x.size())\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "VxLbFZEvr0rh"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18(nn.Module):\n",
        "    def __init__(self, in_channels, resblock, outputs=1000):\n",
        "        super(ResNet18, self).__init__()\n",
        "        self.layer0 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3), # 7x7 kernel을 사용하고 output shape을 1/2로 줄이기 위해서는 padding이 필요\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            resblock(64, 64, downsample=False),\n",
        "            resblock(64, 64, downsample=False)\n",
        "        )\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            resblock(64, 128, downsample=True),\n",
        "            resblock(128, 128, downsample=False)\n",
        "        )\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            resblock(128, 256, downsample=True),\n",
        "            resblock(256, 256, downsample=False)\n",
        "        )\n",
        "        \n",
        "        self.layer4 = nn.Sequential(\n",
        "            resblock(256, 512, downsample=True),\n",
        "            resblock(512, 512, downsample=False)\n",
        "        )\n",
        "\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc1 = nn.Linear(512, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.layer0(x),\n",
        "        # print(x.size())\n",
        "        x = self.layer1(x),\n",
        "        x = self.layer2(x),\n",
        "        x = self.layer3(x),\n",
        "        x = self.layer4(x),\n",
        "        x = self.gap(x),\n",
        "        output = self.fc(x)\n",
        "        # print('output :', output.size())\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "iv0lWdFPvvr6"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "resnet18 = ResNet18(3, ResBlock, outputs=1000)\n",
        "summary(resnet18, input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "xT-cIo4u3MYo",
        "outputId": "d839d6d3-db76-4575-a8c9-d64d473dacce"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-123-18d5a25238cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresnet18\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# batch_size of 2 for batchnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0min_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0min_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;31m# print(type(x[0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# batch_size of 2 for batchnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0min_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0min_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;31m# print(type(x[0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: rand(): argument 'size' must be tuple of ints, but found element of type Tensor at pos 2"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 후기\n",
        "\n",
        "TypeError: conv2d() received an invalid combination of arguments - got (tuple, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:  \n",
        "이거 왜 자꾸 나오는거냐.."
      ],
      "metadata": {
        "id": "PjG16dvaL7QV"
      }
    }
  ]
}