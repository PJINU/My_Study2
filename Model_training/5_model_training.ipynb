{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_model_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n6oT8FnQERsx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import SGD\n",
        "from torch.optim.lr_scheduler import LinearLR\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU 사용 설정"
      ],
      "metadata": {
        "id": "LS8XkyMMFXPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SnGHzgSwEj_3",
        "outputId": "bca09fa8-054c-4b48-95ef-2857fc39d603"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 가져오기"
      ],
      "metadata": {
        "id": "o9XFVVWXFWQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/drive/MyDrive/고모부_머신러닝/dogncat\n",
        "paths = []\n",
        "dataset_type = []\n",
        "labels = []\n",
        "\n",
        "def make_dataframe(dirpath):\n",
        "    for dirname, _, filenames in os.walk(dirpath):\n",
        "        for filename in filenames:\n",
        "            file_path = dirname+'/'+filename\n",
        "            paths.append(file_path)\n",
        "\n",
        "            if '/training_set' in file_path:\n",
        "                dataset_type.append('train')\n",
        "            elif '/test_set' in file_path:\n",
        "                dataset_type.append('test')\n",
        "            else:\n",
        "                dataset_type.append('N/A')\n",
        "            \n",
        "            if 'dogs' in file_path:\n",
        "                labels.append('DOG')\n",
        "            elif 'cats' in file_path:\n",
        "                labels.append('CAT')\n",
        "            else:\n",
        "                labels.append('N/A')\n",
        "\n",
        "    df = pd.DataFrame({'path' : paths, 'type' : dataset_type, 'label' : labels})\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "K4dHXAT4FbLl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnd_df = make_dataframe('/content/drive/MyDrive/고모부_머신러닝/dogncat')\n",
        "cnd_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TZGsFEuqHlwS",
        "outputId": "a346b8b9-1dad-4e7c-81bd-1acc7bf758e0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                path  type label\n",
              "0  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "1  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "2  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "3  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "4  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7493eb62-624c-4e11-8327-355b207c1e83\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>type</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7493eb62-624c-4e11-8327-355b207c1e83')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7493eb62-624c-4e11-8327-355b207c1e83 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7493eb62-624c-4e11-8327-355b207c1e83');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnd_df = cnd_df[cnd_df['path'].str.contains('.jpg')].copy() # '.jpg'파일만 저장\n",
        "cnd_df.info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYEVxo13HsK5",
        "outputId": "66e73afe-ee12-40ab-cb0a-57c4c6d110cb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 10028 entries, 0 to 10031\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   path    10028 non-null  object\n",
            " 1   type    10028 non-null  object\n",
            " 2   label   10028 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 313.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train, valid dataset 만들기\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train, validation 분리\n",
        "train_df, valid_df = train_test_split(cnd_df[cnd_df['type']=='train'], test_size = 0.25)\n",
        "\n",
        "# train dataset\n",
        "train_data = train_df['path'].values\n",
        "train_label = train_df['label'].values\n",
        "train_label_indices = train_df['label'].replace(['CAT', 'DOG'], [0, 1]).values\n",
        "\n",
        "# validation dataset\n",
        "valid_data = valid_df['path'].values\n",
        "valid_label = valid_df['label'].values\n",
        "valid_label_indices = valid_df['label'].replace(['CAT', 'DOG'], [0,1]).values\n"
      ],
      "metadata": {
        "id": "GiZrO5gRIGoy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eXijHLvyS1O4",
        "outputId": "7784a5ad-8398-48f8-d77a-fa9f357e963c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   path   type label\n",
              "4140  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   CAT\n",
              "7251  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   DOG\n",
              "4798  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   CAT\n",
              "7654  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   DOG\n",
              "3622  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   CAT"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea0b84f4-1e70-44cb-be9b-9660451f5d6a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>type</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4140</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>train</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7251</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>train</td>\n",
              "      <td>DOG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4798</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>train</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7654</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>train</td>\n",
              "      <td>DOG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3622</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>train</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea0b84f4-1e70-44cb-be9b-9660451f5d6a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea0b84f4-1e70-44cb-be9b-9660451f5d6a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea0b84f4-1e70-44cb-be9b-9660451f5d6a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_c = 0\n",
        "count_d = 0\n",
        "for file_name in valid_data:\n",
        "    if 'cats' in file_name:\n",
        "        count_c += 1\n",
        "    elif 'dogs' in file_name:\n",
        "        count_d += 1\n",
        "\n",
        "print(count_c, count_d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AMUCfbzEg5j",
        "outputId": "a39df031-25dc-4028-959a-d15428e24c8f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "983 1019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 샘플용 데이터 만들기"
      ],
      "metadata": {
        "id": "FuX0fD12ZCuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_dog = train_df[train_df['label'] == 'DOG'].sample(30)\n",
        "sample_cat = train_df[train_df['label'] == 'CAT'].sample(30)\n",
        "\n",
        "sample_df = pd.concat([sample_dog, sample_cat])\n",
        "# sample_df = sample_df.sample(frac=1).reset_index()\n",
        "sample_tr, sample_val = train_test_split(sample_df, test_size=0.2)"
      ],
      "metadata": {
        "id": "14JLtSN-AmGo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tr['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Kr6ulW-Zl55",
        "outputId": "b34e95ec-dba4-423b-ff07-52d2799e95f7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CAT    26\n",
              "DOG    22\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tr_data = sample_tr['path'].values\n",
        "sample_tr_label = sample_tr['label'].replace(['CAT', 'DOG'], [0,1]).values\n",
        "sample_val_data = sample_val['path'].values\n",
        "sample_val_label = sample_val['label'].replace(['CAT', 'DOG'], [0,1]).values"
      ],
      "metadata": {
        "id": "txpeEVRgBSgS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 테스트 데이터 만들기"
      ],
      "metadata": {
        "id": "v0h39YG6t8PQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test 데이터 만들기\n",
        "test_data = cnd_df['path'][cnd_df['type']=='test']\n",
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVlxa300K3E6",
        "outputId": "faba08c8-d6c2-487f-f179-25c7cd2867c5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "1       /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "2       /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "3       /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "4       /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "                              ...                        \n",
              "2020    /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "2021    /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "2022    /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "2023    /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "2024    /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "Name: path, Length: 2023, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom dataset 만들기"
      ],
      "metadata": {
        "id": "UWS3WukiO50z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, datapath, label=None):\n",
        "        super(MyDataset, self).__init__()\n",
        "\n",
        "        self.path = datapath\n",
        "        self.label = label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.path)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "\n",
        "        image = cv2.cvtColor(cv2.imread(self.path[idx]), cv2.COLOR_BGR2RGB)\n",
        "        image = cv2.resize(image, (244,244))\n",
        "        image = np.asarray(image, dtype=np.float32).transpose(2,0,1)\n",
        "        normal_image = (image - np.amin(image)) / (np.amax(image) - np.amin(image))\n",
        "        \n",
        "        if self.label is not None:\n",
        "            label = self.label[idx]\n",
        "\n",
        "        return normal_image, label\n"
      ],
      "metadata": {
        "id": "Dah4BaTtPUMR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MyDataset(train_data, train_label_indices)\n",
        "valid_dataset = MyDataset(valid_data, valid_label_indices)\n",
        "test_dataset = MyDataset(test_data)"
      ],
      "metadata": {
        "id": "yePXrmtCT7gl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 샘플용 dataset만들기"
      ],
      "metadata": {
        "id": "KWFazLKHaXtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tr_dataset = MyDataset(sample_tr_data, sample_tr_label)\n",
        "sample_val_dataset = MyDataset(sample_val_data, sample_val_label)"
      ],
      "metadata": {
        "id": "QUjpikl5CelL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(sample_tr_dataset))\n",
        "print(len(sample_val_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6eQjE_auLdf",
        "outputId": "973583b2-c4d9-4f7f-9a1f-1dcd8faf8be7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48\n",
            "12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loader 만들기"
      ],
      "metadata": {
        "id": "1q5i3R95TVTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False) # 왜 valid loader에서는 shuffle을 false로 하지?"
      ],
      "metadata": {
        "id": "jn8MGXYtTW6Y"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 샘플용 loader 만들기"
      ],
      "metadata": {
        "id": "INtSKKAjaf0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tr_loader = DataLoader(sample_tr_dataset, batch_size=4, shuffle=True)\n",
        "sample_val_loader = DataLoader(sample_val_dataset, batch_size=2, shuffle=False)"
      ],
      "metadata": {
        "id": "rK8Y8CnKCNYN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sample_val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUySVUcgcn3q",
        "outputId": "6f794f20-18f1-4112-df73-ae3ad858235b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 만들기"
      ],
      "metadata": {
        "id": "hEBzJynxXtRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 5, kernel_size=3, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc1 = nn.Linear(5*244*244, 2)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print('input size :', x.shape)\n",
        "        # print('input max :', torch.amax(x, dim=(1,2,3)))\n",
        "        # print('input min :', torch.amin(x, dim=(1,2,3)))\n",
        "        # print('input l2norm :', torch.linalg.vector_norm(x, dim=(1,2,3)))\n",
        "\n",
        "        conv = self.conv1(x)\n",
        "        # print('conv size :', conv.shape)\n",
        "        # print('conv max :', torch.amax(conv, dim=(1,2,3)))\n",
        "        # print('conv min :', torch.amin(conv, dim=(1,2,3)))\n",
        "        # print('conv l2norm :', torch.linalg.vector_norm(conv, dim=(1,2,3)))\n",
        "\n",
        "        conv_out = self.relu(conv)\n",
        "        # print('conv_out size :', conv_out.shape)\n",
        "        # print('conv_out max :', torch.amax(conv_out, dim=(1,2,3)))\n",
        "        # print('conv_out min :', torch.amin(conv_out, dim=(1,2,3)))\n",
        "        # print('conv_out l2norm :', torch.linalg.vector_norm(conv_out, dim=(1,2,3)))\n",
        "\n",
        "        fc_input = conv_out.view(conv_out.size(0), -1)\n",
        "        # print('fc_input size :', fc_input.shape)\n",
        "        # print('fc_input max :', torch.amax(fc_input, dim=(1)))\n",
        "        # print('fc_input min :', torch.amin(fc_input, dim=(1)))\n",
        "        # print('fc_input l2norm :', torch.linalg.vector_norm(fc_input, dim=(1)))\n",
        "\n",
        "        fc_logit = self.fc1(fc_input)\n",
        "        # print('fc_logit size :', fc_logit.shape)\n",
        "        # print('fc_logit max :', torch.amax(fc_logit, dim=(1)))\n",
        "        # print('fc_logit min :', torch.amin(fc_logit, dim=(1)))\n",
        "        # print('fc_logit l2norm :', torch.linalg.vector_norm(fc_logit, dim=(1)))\n",
        "        # print()\n",
        "\n",
        "        return fc_logit"
      ],
      "metadata": {
        "id": "1fR_fHs4Ynlj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN().to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8v11c71bKJ4",
        "outputId": "2cfef7b7-18e5-4123-84fa-b5e6e4b35eba"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (relu): ReLU()\n",
              "  (fc1): Linear(in_features=297680, out_features=2, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ex_image, ex_label = next(iter(sample_tr_loader))\n",
        "ex_image = ex_image.to(device)\n",
        "ex_label = ex_label.to(device)\n",
        "print(ex_image.shape)\n",
        "print(ex_label)\n",
        "model_logit, model_output = model(ex_image)\n",
        "print(model_logit)\n",
        "print(model_output)"
      ],
      "metadata": {
        "id": "dW-ywTELw47w",
        "outputId": "8e55fa67-332d-4a20-b23d-fb386b30c9ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 244, 244])\n",
            "tensor([1, 1, 1, 0], device='cuda:0')\n",
            "tensor([[-0.5536,  0.6319],\n",
            "        [ 0.0263, -0.0585],\n",
            "        [-0.4439,  0.3296],\n",
            "        [ 0.1677, -0.2683]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.2341, 0.7659],\n",
            "        [0.5212, 0.4788],\n",
            "        [0.3157, 0.6843],\n",
            "        [0.6073, 0.3927]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(ex_label))"
      ],
      "metadata": {
        "id": "-0SSSswYx9ju",
        "outputId": "e43df861-f8ed-4da0-db58-e206881b4f85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(model_logit))\n",
        "print(type(model_output))"
      ],
      "metadata": {
        "id": "p1StzBwWxjGF",
        "outputId": "bf915434-4f26-47e5-b97d-e33a4a85a87c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.argmax(model_output, dim=1))"
      ],
      "metadata": {
        "id": "tYF4Ushaxmya",
        "outputId": "9e9c2382-4d30-4a94-e80a-2e2cf04e3762",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 0, 1, 0], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(model_output.cpu().detach().numpy()))"
      ],
      "metadata": {
        "id": "aSvX7u3qyfxv",
        "outputId": "32894bc1-5ceb-4cbf-8577-14047815372e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### loss function"
      ],
      "metadata": {
        "id": "OCb0U7mFbMqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "id": "191rvsBBbP0w"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### optimzer, lr_scheduler 설정"
      ],
      "metadata": {
        "id": "D4uHvlBIbS9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = SGD(model.parameters(), lr=0.001)\n",
        "scheduler = LinearLR(optimizer)"
      ],
      "metadata": {
        "id": "6PoD6t7ZbcjC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 training"
      ],
      "metadata": {
        "id": "0jJQXZ_JcCiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy, recall, precision 구하는 함수 만들기!!\n",
        "\n",
        "def confusion_matrix(predicted, label, class_num):\n",
        "    TP_num = 0\n",
        "    TN_num = 0\n",
        "    FP_num = 0\n",
        "    FN_num = 0\n",
        "    for i in range(label):\n",
        "        pred_value = predicted[i]\n",
        "        label_value = label[i]\n",
        "\n",
        "        for class_idx in range(class_num):\n",
        "            if (pred_value == class_idx) and (label_value) == class_idx:\n",
        "                TP_num += 1\n",
        "                \n",
        "                "
      ],
      "metadata": {
        "id": "pMYNoXw7VHrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(loader):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "\n",
        "    for i, data in enumerate(loader):\n",
        "        image_data, label_data = data\n",
        "        image_data = image_data.to(device)\n",
        "        label_data = label_data.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        hyphothesis = model(image_data)\n",
        "\n",
        "        loss = loss_fn(hyphothesis, label_data)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # print(f'batch{i+1} loss : {loss}')\n",
        "        # print()\n",
        "        # print(f'gradient max :', torch.amax(torch.tensor([torch.amax(param.grad) for param in model.parameters()])))\n",
        "        # print(f'gradient min :', torch.amin(torch.tensor([torch.amax(param.grad) for param in model.parameters()])))\n",
        "        # print(f'gradient l2norm :', torch.amax(torch.tensor([torch.linalg.vector_norm(param.grad) for param in model.parameters()])))\n",
        "        # print()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # last_loss = running_loss / len(loader)\n",
        "        # print(f'Average batch loss :', last_loss)\n",
        "        # print()\n",
        "        # last_loss = 0\n",
        "\n",
        "\n",
        "        if i+1 == len(loader):\n",
        "            last_loss = running_loss / len(loader)\n",
        "            print(f'Average batch loss :', last_loss)\n",
        "            print()\n",
        "            running_loss = 0\n",
        "\n",
        "    return last_loss\n"
      ],
      "metadata": {
        "id": "i7NaWtP4eI8f"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training, Evaluation"
      ],
      "metadata": {
        "id": "fHE632P5PGEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 30\n",
        "running_loss = 0.\n",
        "running_vloss = 0.\n",
        "for i in range(epoch):\n",
        "    print(f'========= Epoch{i+1} =========')\n",
        "    print()\n",
        "    # train\n",
        "    model.train()\n",
        "    for batch_idx, data in enumerate(sample_tr_loader):\n",
        "        image_data, label_data = data\n",
        "        image_data = image_data.to(device)\n",
        "        label_data = label_data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        tr_output= model(image_data)\n",
        "        loss = loss_fn(tr_output, label_data)\n",
        "        print(f'batch{batch_idx+1} loss :', loss)\n",
        "        running_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx + 1 == len(sample_tr_loader):\n",
        "            avg_loss = running_loss / len(sample_tr_loader)\n",
        "            print('Loss/train :', avg_loss)\n",
        "            running_loss = 0.\n",
        "\n",
        "    #evaluate\n",
        "    model.eval()\n",
        "    for batch_idx, val_data in enumerate(sample_tr_loader): # training data로 우선 evaluation해보기\n",
        "        valid_image, valid_label = val_data\n",
        "        valid_image = valid_image.to(device)\n",
        "        valid_label = valid_label.to(device)\n",
        "        val_output = model(valid_image)\n",
        "        val_output_idx = torch.argmax(val_output, dim=1)\n",
        "        vloss = loss_fn(val_output, valid_label)\n",
        "        running_vloss += vloss.item()\n",
        "        \n",
        "        if batch_idx + 1 == len(sample_tr_loader):\n",
        "            avg_vloss = running_vloss / len(sample_tr_loader)\n",
        "            print('Loss/valid :', avg_vloss)\n",
        "            print('Accuracy :', accuracy_score(valid_label.cpu().detach().numpy(), val_output_idx.cpu().detach().numpy()))\n",
        "            print('Recall :', recall_score(valid_label.cpu().detach().numpy(), val_output_idx.cpu().detach().numpy()))\n",
        "            print('Precision :', precision_score(valid_label.cpu().detach().numpy(), val_output_idx.cpu().detach().numpy()))\n",
        "            running_vloss = 0.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2OET9RvhreZ",
        "outputId": "3c70dc9e-79a3-411f-cd46-748fccecc72f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= Epoch1 =========\n",
            "\n",
            "batch1 loss : tensor(0.7340, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(2.3638, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(2.1353, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(1.4521, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.6541, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.8021, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(1.5517, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(3.2341, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(1.7181, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.6439, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.6215, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.9571, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 1.405660738547643\n",
            "Loss/valid : 1.4467197880148888\n",
            "Accuracy : 0.25\n",
            "Recall : 1.0\n",
            "Precision : 0.25\n",
            "========= Epoch2 =========\n",
            "\n",
            "batch1 loss : tensor(1.9417, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(2.1332, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.0997, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.8663, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.7427, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(4.2082, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(2.3403, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(1.0379, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(1.1628, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.5408, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(2.2179, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(1.3171, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 1.5507079487045605\n",
            "Loss/valid : 0.6042737911144892\n",
            "Accuracy : 1.0\n",
            "Recall : 1.0\n",
            "Precision : 1.0\n",
            "========= Epoch3 =========\n",
            "\n",
            "batch1 loss : tensor(0.8237, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.5884, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.9269, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.4744, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(1.6255, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.9817, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.5901, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.3791, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(1.1293, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(1.3952, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.5824, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.6555, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.8460209891200066\n",
            "Loss/valid : 0.94392529129982\n",
            "Accuracy : 0.5\n",
            "Recall : 1.0\n",
            "Precision : 0.5\n",
            "========= Epoch4 =========\n",
            "\n",
            "batch1 loss : tensor(1.5673, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(1.4544, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(1.0733, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.6802, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.4913, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.4321, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.3815, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.4791, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.2469, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.8078, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.6310, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.7640711963176727\n",
            "Loss/valid : 0.6338887363672256\n",
            "Accuracy : 0.5\n",
            "Recall : 1.0\n",
            "Precision : 0.3333333333333333\n",
            "========= Epoch5 =========\n",
            "\n",
            "batch1 loss : tensor(0.5455, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.4090, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.8391, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.6473, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1692, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.5073, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.6675, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.0887, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(1.3026, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.8995, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.1274, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.5204, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.5602935968587796\n",
            "Loss/valid : 0.4649202711880207\n",
            "Accuracy : 0.75\n",
            "Recall : 0.75\n",
            "Precision : 1.0\n",
            "========= Epoch6 =========\n",
            "\n",
            "batch1 loss : tensor(0.3951, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.4488, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.5371, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.9436, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.9593, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.3421, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.3416, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.3954, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1760, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.6038, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.6336, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.8059, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.5485260051985582\n",
            "Loss/valid : 0.7110685997953018\n",
            "Accuracy : 0.75\n",
            "Recall : 0.0\n",
            "Precision : 0.0\n",
            "========= Epoch7 =========\n",
            "\n",
            "batch1 loss : tensor(0.3480, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.2398, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.5184, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(1.1331, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch5 loss : tensor(0.4804, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.6912, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1402, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.6898, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.7798, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.7124, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.4660, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.3798, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.5482522062957287\n",
            "Loss/valid : 0.3298368714749813\n",
            "Accuracy : 0.5\n",
            "Recall : 0.3333333333333333\n",
            "Precision : 1.0\n",
            "========= Epoch8 =========\n",
            "\n",
            "batch1 loss : tensor(0.3123, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.8508, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.2500, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.7139, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.3102, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.4948, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1225, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.4140, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.3750, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.3580, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.3619, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.5365, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.42499256258209545\n",
            "Loss/valid : 0.3817697887619336\n",
            "Accuracy : 0.5\n",
            "Recall : 1.0\n",
            "Precision : 0.5\n",
            "========= Epoch9 =========\n",
            "\n",
            "batch1 loss : tensor(0.4422, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1903, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.4888, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.6745, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1435, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.2607, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.3522, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.3881, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.2270, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.5357, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.4263, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.2380, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.36394263058900833\n",
            "Loss/valid : 0.27967046201229095\n",
            "Accuracy : 1.0\n",
            "Recall : 1.0\n",
            "Precision : 1.0\n",
            "========= Epoch10 =========\n",
            "\n",
            "batch1 loss : tensor(0.1991, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.2364, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.2924, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.2410, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.6839, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.4785, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1988, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.6343, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.2327, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.1576, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.7146, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.3893, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.3715596869587898\n",
            "Loss/valid : 0.34141564307113487\n",
            "Accuracy : 1.0\n",
            "Recall : 1.0\n",
            "Precision : 1.0\n",
            "========= Epoch11 =========\n",
            "\n",
            "batch1 loss : tensor(0.7994, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(1.1916, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.5108, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.9921, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.6456, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.3084, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.2738, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.2691, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1563, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.1147, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.6707, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.5031, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.5362966315199932\n",
            "Loss/valid : 0.2396076029787461\n",
            "Accuracy : 1.0\n",
            "Recall : 1.0\n",
            "Precision : 1.0\n",
            "========= Epoch12 =========\n",
            "\n",
            "batch1 loss : tensor(0.1237, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0816, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.2345, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.4574, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.3375, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.2203, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.5086, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.8626, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1200, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.4393, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.5569, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.2799, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.35185737411181134\n",
            "Loss/valid : 0.2698980588465929\n",
            "Accuracy : 1.0\n",
            "Recall : 1.0\n",
            "Precision : 1.0\n",
            "========= Epoch13 =========\n",
            "\n",
            "batch1 loss : tensor(0.3659, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1956, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.2829, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.6237, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.3294, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.2265, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.2125, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.3160, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1737, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.3453, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.1541, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.1157, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.27843255052963894\n",
            "Loss/valid : 0.2494542362789313\n",
            "Accuracy : 1.0\n",
            "Recall : 1.0\n",
            "Precision : 1.0\n",
            "========= Epoch14 =========\n",
            "\n",
            "batch1 loss : tensor(0.2348, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1295, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.2044, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.2003, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1765, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.2456, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.2803, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.2046, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.2869, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.2992, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.3048, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.1454, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.22603139653801918\n",
            "Loss/valid : 0.22670395113527775\n",
            "Accuracy : 1.0\n",
            "Recall : 1.0\n",
            "Precision : 1.0\n",
            "========= Epoch15 =========\n",
            "\n",
            "batch1 loss : tensor(0.2459, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1568, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1655, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.1727, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.2463, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1660, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1968, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.3452, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1657, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.3049, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.1746, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.1978, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.21151923015713692\n",
            "Loss/valid : 0.1883899016926686\n",
            "Accuracy : 1.0\n",
            "Recall : 1.0\n",
            "Precision : 1.0\n",
            "========= Epoch16 =========\n",
            "\n",
            "batch1 loss : tensor(0.0887, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.4387, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1909, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.1391, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1645, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.2146, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.3007, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.0849, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.6474, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.7318, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.2409, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.4443, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.307204345241189\n",
            "Loss/valid : 0.22434401946763197\n",
            "Accuracy : 1.0\n",
            "Recall : 0.0\n",
            "Precision : 0.0\n",
            "========= Epoch17 =========\n",
            "\n",
            "batch1 loss : tensor(0.2322, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1180, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1896, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.2142, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch5 loss : tensor(0.1538, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1841, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.2077, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1903, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1700, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.1240, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.1935, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.2533, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.1858921218663454\n",
            "Loss/valid : 0.15569936111569405\n",
            "Accuracy : 1.0\n",
            "Recall : 1.0\n",
            "Precision : 1.0\n",
            "========= Epoch18 =========\n",
            "\n",
            "batch1 loss : tensor(0.2211, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.2042, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.0802, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.1089, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.2014, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.2454, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1916, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1903, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.2289, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.3788, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.4534, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.3755, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.23998567337791124\n",
            "Loss/valid : 0.18415573860208193\n",
            "Accuracy : 1.0\n",
            "Recall : 1.0\n",
            "Precision : 1.0\n",
            "========= Epoch19 =========\n",
            "\n",
            "batch1 loss : tensor(0.1513, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1788, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1689, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.2106, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1635, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1150, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1833, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.0686, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.0679, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.1707, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.2771, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.1700, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.16048050237198672\n",
            "Loss/valid : 0.13519890730579695\n",
            "Accuracy : 1.0\n",
            "Recall : 1.0\n",
            "Precision : 1.0\n",
            "========= Epoch20 =========\n",
            "\n",
            "batch1 loss : tensor(0.1443, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1607, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1703, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.1312, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.2174, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1274, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.0896, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1227, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.2948, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.2165, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.1068, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.0778, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.15495968610048294\n",
            "Loss/valid : 0.1758738818267981\n",
            "Accuracy : 1.0\n",
            "Recall : 1.0\n",
            "Precision : 1.0\n",
            "========= Epoch21 =========\n",
            "\n",
            "batch1 loss : tensor(0.2176, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1332, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1994, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.0684, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.0762, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1589, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1426, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.2149, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1796, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.1887, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.2053, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.1092, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.1578337543954452\n",
            "Loss/valid : 0.12183726020157337\n",
            "Accuracy : 1.0\n",
            "Recall : 1.0\n",
            "Precision : 1.0\n",
            "========= Epoch22 =========\n",
            "\n",
            "batch1 loss : tensor(0.1473, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0745, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.0957, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.1333, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.0960, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.0833, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.0852, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1780, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.0940, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.1270, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.1314, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.2335, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.12326819077134132\n",
            "Loss/valid : 0.11340779438614845\n",
            "Accuracy : 1.0\n",
            "Recall : 1.0\n",
            "Precision : 1.0\n",
            "========= Epoch23 =========\n",
            "\n",
            "batch1 loss : tensor(0.1253, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.2273, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1393, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.1476, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1500, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1309, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.0830, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1209, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.0838, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.0914, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.0825, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.1542, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.1280187883724769\n",
            "Loss/valid : 0.12338026364644368\n",
            "Accuracy : 1.0\n",
            "Recall : 1.0\n",
            "Precision : 1.0\n",
            "========= Epoch24 =========\n",
            "\n",
            "batch1 loss : tensor(0.2151, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1000, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.0745, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.0596, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.2026, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1198, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.0945, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1332, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1187, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.0897, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.0317, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.0684, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.1089733149856329\n",
            "Loss/valid : 0.12388643063604832\n",
            "Accuracy : 1.0\n",
            "Recall : 1.0\n",
            "Precision : 1.0\n",
            "========= Epoch25 =========\n",
            "\n",
            "batch1 loss : tensor(0.0786, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1292, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.0492, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.1130, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1184, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1115, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.0827, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1817, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1032, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.0960, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.1171, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.1885, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.11409531626850367\n",
            "Loss/valid : 0.09661351315056284\n",
            "Accuracy : 1.0\n",
            "Recall : 1.0\n",
            "Precision : 1.0\n",
            "========= Epoch26 =========\n",
            "\n",
            "batch1 loss : tensor(0.1157, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0734, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1364, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.1021, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1090, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.0794, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1546, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1213, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1427, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.0541, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.1303, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.0730, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.10767187488575776\n",
            "Loss/valid : 0.08976660327365\n",
            "Accuracy : 1.0\n",
            "Recall : 1.0\n",
            "Precision : 1.0\n",
            "========= Epoch27 =========\n",
            "\n",
            "batch1 loss : tensor(0.1123, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0757, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.0426, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.1395, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1134, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.0450, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.0348, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1085, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1283, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.1211, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.1241, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.0460, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.09093861095607281\n",
            "Loss/valid : 0.1019702263486882\n",
            "Accuracy : 1.0\n",
            "Recall : 1.0\n",
            "Precision : 1.0\n",
            "========= Epoch28 =========\n",
            "\n",
            "batch1 loss : tensor(0.1159, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0756, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1396, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.0781, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.0424, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1207, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.0623, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.0895, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1417, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.1129, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.1017, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.0480, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.09402610920369625\n",
            "Loss/valid : 0.08121906034648418\n",
            "Accuracy : 1.0\n",
            "Recall : 1.0\n",
            "Precision : 1.0\n",
            "========= Epoch29 =========\n",
            "\n",
            "batch1 loss : tensor(0.0590, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0360, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1353, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.1016, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.0786, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.0942, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1246, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.0779, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.0953, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.0934, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.0877, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.0220, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.08380325386921565\n",
            "Loss/valid : 0.07738345271597306\n",
            "Accuracy : 1.0\n",
            "Recall : 1.0\n",
            "Precision : 1.0\n",
            "========= Epoch30 =========\n",
            "\n",
            "batch1 loss : tensor(0.0798, grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0916, grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.0988, grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.0614, grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1688, grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1131, grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.0609, grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.0697, grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.0513, grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.0694, grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.0572, grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.0793, grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.08343968850870927\n",
            "Loss/valid : 0.08316768798977137\n",
            "Accuracy : 1.0\n",
            "Recall : 1.0\n",
            "Precision : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### avg_loss, avg_vloss가 계속 같은 값으로 나오는 현상\n",
        "- 학습이 진행되도 avg_loss와 avg_vloss가 계속 같은 값으로 나오는 현상이 발생했는데 처음에는 데이터 셋이나 모델에 문제가 있나 해서 살펴보았는데 딱히 문제는 없었다. 어디가 문제인가 살펴보니 loss가 변하지 않는다는 것은 파라미터 업데이트가 안된다는 것을 의미했고 다시 살펴보니 모델을 변경한 후에 optimizer를 새롭게 설정해주지 않아서 생긴 문제였다."
      ],
      "metadata": {
        "id": "9jhRSFG0iDrw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 전체 데이터로 모델을 돌리기 전에 샘플 데이터로 우선적으로 돌려보기\n",
        "- 모델 training은 많은 비용이 들어가는 작업이다. 특히, 데이터가 많고 클수록. 그렇기 때문에 비용을 절약하기 위해서는 전체 학습 데이터로 모델을 학습하기 전에 샘플 데이터로 우선적으로 학습을 진행하여 모델이 정상적으로 작동하는지 확인하는 작업이 필요하다."
      ],
      "metadata": {
        "id": "DiWuZSxg6d_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### accuracy, recall, precision을 구해봤는데 0.75, 0, 0이 나왔다. 왜지..?\n",
        "- recall이랑 precision이 0이 나왔다는 건 TP가 0이라는 건데 그렇게 되면 accuracy가 0.75가 나올 수가 없다. 데이터셋이 불균형한 경우가 아닌 이상 나와봐야 0.5인데..(현재 -> 개 : 30, 고양이 : 30)\n",
        "- 일단 모든 결과값을 출력해서 어디가 잘못된 것인지 확인해보자..."
      ],
      "metadata": {
        "id": "J4d4uRrN625Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wBYeKiphS9pM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}