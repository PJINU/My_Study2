{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_model_training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n6oT8FnQERsx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import SGD\n",
        "from torch.optim.lr_scheduler import LinearLR\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU 사용 설정"
      ],
      "metadata": {
        "id": "LS8XkyMMFXPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SnGHzgSwEj_3",
        "outputId": "21e969c7-8f01-46f4-9b99-6f0678fbc771"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 가져오기"
      ],
      "metadata": {
        "id": "o9XFVVWXFWQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/drive/MyDrive/고모부_머신러닝/dogncat\n",
        "paths = []\n",
        "dataset_type = []\n",
        "labels = []\n",
        "\n",
        "def make_dataframe(dirpath):\n",
        "    for dirname, _, filenames in os.walk(dirpath):\n",
        "        for filename in filenames:\n",
        "            file_path = dirname+'/'+filename\n",
        "            paths.append(file_path)\n",
        "\n",
        "            if '/training_set' in file_path:\n",
        "                dataset_type.append('train')\n",
        "            elif '/test_set' in file_path:\n",
        "                dataset_type.append('test')\n",
        "            else:\n",
        "                dataset_type.append('N/A')\n",
        "            \n",
        "            if 'dogs' in file_path:\n",
        "                labels.append('DOG')\n",
        "            elif 'cats' in file_path:\n",
        "                labels.append('CAT')\n",
        "            else:\n",
        "                labels.append('N/A')\n",
        "\n",
        "    df = pd.DataFrame({'path' : paths, 'type' : dataset_type, 'label' : labels})\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "K4dHXAT4FbLl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnd_df = make_dataframe('/content/drive/MyDrive/고모부_머신러닝/dogncat')\n",
        "cnd_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "TZGsFEuqHlwS",
        "outputId": "0b7916a3-c718-4103-a544-28ee80e62fb0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                path  type label\n",
              "0  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "1  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "2  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "3  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "4  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2dc00c77-3c3f-4e3d-bdef-0a25f0ecd9f8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>type</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2dc00c77-3c3f-4e3d-bdef-0a25f0ecd9f8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2dc00c77-3c3f-4e3d-bdef-0a25f0ecd9f8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2dc00c77-3c3f-4e3d-bdef-0a25f0ecd9f8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnd_df = cnd_df[cnd_df['path'].str.contains('.jpg')].copy()\n",
        "cnd_df.info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYEVxo13HsK5",
        "outputId": "8a6aabcb-3897-4f85-b4ce-b5cc1b768d3a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 10028 entries, 0 to 10031\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   path    10028 non-null  object\n",
            " 1   type    10028 non-null  object\n",
            " 2   label   10028 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 313.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train, valid dataset 만들기\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train, validation 분리\n",
        "train_df, valid_df = train_test_split(cnd_df[cnd_df['type']=='train'], test_size = 0.25)\n",
        "\n",
        "# train dataset\n",
        "train_data = train_df['path'].values\n",
        "train_label = train_df['label'].values\n",
        "train_label_indices = train_df['label'].replace(['CAT', 'DOG'], [0, 1]).values\n",
        "\n",
        "# validation dataset\n",
        "valid_data = valid_df['path'].values\n",
        "valid_label = valid_df['label'].values\n",
        "valid_label_indices = valid_df['label'].replace(['CAT', 'DOG'], [0,1]).values\n"
      ],
      "metadata": {
        "id": "GiZrO5gRIGoy"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eXijHLvyS1O4",
        "outputId": "d1d74b38-fddc-4b6d-e42e-85ff45c6f1be"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   path   type label\n",
              "8713  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   DOG\n",
              "6647  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   DOG\n",
              "6660  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   DOG\n",
              "6563  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   DOG\n",
              "6276  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   DOG"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c5c46b2f-646f-41ac-9841-db4a8d5309c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>type</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8713</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>train</td>\n",
              "      <td>DOG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6647</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>train</td>\n",
              "      <td>DOG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6660</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>train</td>\n",
              "      <td>DOG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6563</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>train</td>\n",
              "      <td>DOG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6276</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>train</td>\n",
              "      <td>DOG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5c46b2f-646f-41ac-9841-db4a8d5309c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c5c46b2f-646f-41ac-9841-db4a8d5309c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c5c46b2f-646f-41ac-9841-db4a8d5309c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_c = 0\n",
        "count_d = 0\n",
        "for file_name in valid_data:\n",
        "    if 'cats' in file_name:\n",
        "        count_c += 1\n",
        "    elif 'dogs' in file_name:\n",
        "        count_d += 1\n",
        "\n",
        "print(count_c, count_d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AMUCfbzEg5j",
        "outputId": "b1b60d70-f546-4f16-de32-14b397839100"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "996 1006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 샘플용 데이터 만들기"
      ],
      "metadata": {
        "id": "FuX0fD12ZCuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_dog = train_df[train_df['label'] == 'DOG'].sample(60)\n",
        "sample_cat = train_df[train_df['label'] == 'CAT'].sample(60)\n",
        "\n",
        "sample_df = pd.concat([sample_dog, sample_cat])\n",
        "# sample_df = sample_df.sample(frac=1).reset_index()\n",
        "sample_tr, sample_val = train_test_split(sample_df, test_size=0.2)"
      ],
      "metadata": {
        "id": "14JLtSN-AmGo"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_val['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Kr6ulW-Zl55",
        "outputId": "9d2b521a-254d-4137-e221-5fdc44fb7ec6"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DOG    13\n",
              "CAT    11\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tr_data = sample_tr['path'].values\n",
        "sample_tr_label = sample_tr['label'].replace(['CAT', 'DOG'], [0,1]).values\n",
        "sample_val_data = sample_val['path'].values\n",
        "sample_val_label = sample_val['label'].replace(['CAT', 'DOG'], [0,1]).values"
      ],
      "metadata": {
        "id": "txpeEVRgBSgS"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data))\n",
        "print(len(train_label_indices))\n",
        "\n",
        "print(len(valid_data))\n",
        "print(len(valid_label_indices))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbRgOqjfNSAu",
        "outputId": "e2d65d4b-2f15-4092-873a-3ffcf030457a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6003\n",
            "6003\n",
            "2002\n",
            "2002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test dataset 만들기\n",
        "test_data = cnd_df['path'][cnd_df['type']=='test']\n",
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVlxa300K3E6",
        "outputId": "94049bfb-53c0-4c0a-c43b-1ef8cdb1d0a4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "1       /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "2       /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "3       /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "4       /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "                              ...                        \n",
              "2020    /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "2021    /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "2022    /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "2023    /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "2024    /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "Name: path, Length: 2023, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom dataset 만들기"
      ],
      "metadata": {
        "id": "UWS3WukiO50z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, datapath, label=None):\n",
        "        super(MyDataset, self).__init__()\n",
        "\n",
        "        self.path = datapath\n",
        "        self.label = label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.path)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "\n",
        "        image = cv2.cvtColor(cv2.imread(self.path[idx]), cv2.COLOR_BGR2RGB)\n",
        "        image = cv2.resize(image, (244,244))\n",
        "        image = np.asarray(image, dtype=np.float32).transpose(2,0,1)\n",
        "        normal_image = (image - np.amin(image)) / (np.amax(image) - np.amin(image))\n",
        "        \n",
        "        if self.label is not None:\n",
        "            label = self.label[idx]\n",
        "\n",
        "        return normal_image, label\n"
      ],
      "metadata": {
        "id": "Dah4BaTtPUMR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MyDataset(train_data, train_label_indices)\n",
        "valid_dataset = MyDataset(valid_data, valid_label_indices)\n",
        "test_dataset = MyDataset(test_data)"
      ],
      "metadata": {
        "id": "yePXrmtCT7gl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(len(train_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJMSQmuMfaCd",
        "outputId": "34496acb-9cce-4540-b645-76b7170f8436"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 샘플용 dataset만들기"
      ],
      "metadata": {
        "id": "KWFazLKHaXtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tr_dataset = MyDataset(sample_tr_data, sample_tr_label)\n",
        "sample_val_dataset = MyDataset(sample_val_data, sample_val_label)"
      ],
      "metadata": {
        "id": "QUjpikl5CelL"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loader 만들기"
      ],
      "metadata": {
        "id": "1q5i3R95TVTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False) # 왜 valid loader에서는 shuffle을 false로 하지?"
      ],
      "metadata": {
        "id": "jn8MGXYtTW6Y"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader_data = next(iter(train_loader))"
      ],
      "metadata": {
        "id": "tF8oVJMuaVgN"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 샘플용 loader 만들기"
      ],
      "metadata": {
        "id": "INtSKKAjaf0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tr_loader = DataLoader(sample_tr_dataset, batch_size=8, shuffle=True)\n",
        "sample_val_loader = DataLoader(sample_val_dataset, batch_size=8, shuffle=False)"
      ],
      "metadata": {
        "id": "rK8Y8CnKCNYN"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sample_val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUySVUcgcn3q",
        "outputId": "5ffde47f-fe32-4600-e01c-605ff528682f"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 만들기"
      ],
      "metadata": {
        "id": "hEBzJynxXtRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 5, kernel_size=3, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc1 = nn.Linear(5*244*244, 2)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print('input size :', x.shape)\n",
        "        # print('input max :', torch.amax(x, dim=(1,2,3)))\n",
        "        # print('input min :', torch.amin(x, dim=(1,2,3)))\n",
        "        # print('input l2norm :', torch.linalg.vector_norm(x, dim=(1,2,3)))\n",
        "\n",
        "        conv = self.conv1(x)\n",
        "        # print('conv size :', conv.shape)\n",
        "        # print('conv max :', torch.amax(conv, dim=(1,2,3)))\n",
        "        # print('conv min :', torch.amin(conv, dim=(1,2,3)))\n",
        "        # print('conv l2norm :', torch.linalg.vector_norm(conv, dim=(1,2,3)))\n",
        "\n",
        "        conv_out = self.relu(conv)\n",
        "        # print('conv_out size :', conv_out.shape)\n",
        "        # print('conv_out max :', torch.amax(conv_out, dim=(1,2,3)))\n",
        "        # print('conv_out min :', torch.amin(conv_out, dim=(1,2,3)))\n",
        "        # print('conv_out l2norm :', torch.linalg.vector_norm(conv_out, dim=(1,2,3)))\n",
        "\n",
        "        fc_input = conv_out.view(conv_out.size(0), -1)\n",
        "        # print('fc_input size :', fc_input.shape)\n",
        "        # print('fc_input max :', torch.amax(fc_input, dim=(1)))\n",
        "        # print('fc_input min :', torch.amin(fc_input, dim=(1)))\n",
        "        # print('fc_input l2norm :', torch.linalg.vector_norm(fc_input, dim=(1)))\n",
        "\n",
        "        fc_logit = self.fc1(fc_input)\n",
        "        # print('fc_logit size :', fc_logit.shape)\n",
        "        # print('fc_logit max :', torch.amax(fc_logit, dim=(1)))\n",
        "        # print('fc_logit min :', torch.amin(fc_logit, dim=(1)))\n",
        "        # print('fc_logit l2norm :', torch.linalg.vector_norm(fc_logit, dim=(1)))\n",
        "        # print()\n",
        "\n",
        "        fc_output = self.softmax(fc_logit)\n",
        "\n",
        "        return fc_logit, fc_output"
      ],
      "metadata": {
        "id": "1fR_fHs4Ynlj"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN().to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8v11c71bKJ4",
        "outputId": "f6e66ba9-6a18-4f4c-abf2-aacf45cff8ad"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (relu): ReLU()\n",
              "  (fc1): Linear(in_features=297680, out_features=2, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### loss function"
      ],
      "metadata": {
        "id": "OCb0U7mFbMqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "id": "191rvsBBbP0w"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### optimzer, lr_scheduler 설정"
      ],
      "metadata": {
        "id": "D4uHvlBIbS9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = SGD(model.parameters(), lr=0.001)\n",
        "scheduler = LinearLR(optimizer)"
      ],
      "metadata": {
        "id": "6PoD6t7ZbcjC"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 training"
      ],
      "metadata": {
        "id": "0jJQXZ_JcCiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(loader):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "\n",
        "    for i, data in enumerate(loader):\n",
        "        image_data, label_data = data\n",
        "        image_data = image_data.to(device)\n",
        "        label_data = label_data.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        hyphothesis = model(image_data)\n",
        "\n",
        "        loss = loss_fn(hyphothesis, label_data)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # print(f'batch{i+1} loss : {loss}')\n",
        "        # print()\n",
        "        # print(f'gradient max :', torch.amax(torch.tensor([torch.amax(param.grad) for param in model.parameters()])))\n",
        "        # print(f'gradient min :', torch.amin(torch.tensor([torch.amax(param.grad) for param in model.parameters()])))\n",
        "        # print(f'gradient l2norm :', torch.amax(torch.tensor([torch.linalg.vector_norm(param.grad) for param in model.parameters()])))\n",
        "        # print()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # last_loss = running_loss / len(loader)\n",
        "        # print(f'Average batch loss :', last_loss)\n",
        "        # print()\n",
        "        # last_loss = 0\n",
        "\n",
        "\n",
        "        if i+1 == len(loader):\n",
        "            last_loss = running_loss / len(loader)\n",
        "            print(f'Average batch loss :', last_loss)\n",
        "            print()\n",
        "            running_loss = 0\n",
        "\n",
        "    return last_loss\n"
      ],
      "metadata": {
        "id": "i7NaWtP4eI8f"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training, Evaluation"
      ],
      "metadata": {
        "id": "fHE632P5PGEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 50\n",
        "running_loss = 0.\n",
        "running_vloss = 0.\n",
        "for i in range(epoch):\n",
        "    print(f'========= Epoch{i+1} =========')\n",
        "    print()\n",
        "    # train\n",
        "    model.train(True)\n",
        "    for batch_idx, data in enumerate(sample_tr_loader):\n",
        "        image_data, label_data = data\n",
        "        image_data = image_data.to(device)\n",
        "        label_data = label_data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        tr_logit, tr_output= model(image_data)\n",
        "        # print('hyphothesis :', tr_output)\n",
        "        loss = loss_fn(tr_logit, label_data)\n",
        "        print(f'batch{batch_idx+1} loss :', loss)\n",
        "        # print()\n",
        "        # print(f'gradient max :', torch.amax(torch.tensor([torch.amax(param.grad) for param in model.parameters()])))\n",
        "        # print(f'gradient min :', torch.amin(torch.tensor([torch.amax(param.grad) for param in model.parameters()])))\n",
        "        # print(f'gradient l2norm :', torch.amax(torch.tensor([torch.linalg.vector_norm(param.grad) for param in model.parameters()])))\n",
        "        # print()\n",
        "        running_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx + 1 == len(sample_tr_loader):\n",
        "            avg_loss = running_loss / len(sample_tr_loader)\n",
        "            print('Loss/train :', avg_loss)\n",
        "            running_loss = 0.\n",
        "\n",
        "    model.train(False)\n",
        "\n",
        "    #evaluate\n",
        "    for batch_idx, val_data in enumerate(sample_val_loader):\n",
        "        valid_image, valid_label = val_data\n",
        "        valid_image = valid_image.to(device)\n",
        "        valid_label = valid_label.to(device)\n",
        "        val_logit, val_output = model(valid_image)\n",
        "        vloss = loss_fn(val_logit, valid_label)\n",
        "        running_vloss += vloss.item()\n",
        "        \n",
        "        if batch_idx + 1 == len(sample_val_loader):\n",
        "            avg_vloss = running_vloss / len(sample_val_loader)\n",
        "            print('Loss/valid :', avg_vloss)\n",
        "            running_vloss = 0.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2OET9RvhreZ",
        "outputId": "f8be3466-41e9-4184-cb82-9ee8a0a1de55"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= Epoch1 =========\n",
            "\n",
            "batch1 loss : tensor(0.6325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.9709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(2.6009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(1.1862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(5.0551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.9226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(2.0527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(1.3822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(2.4416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(2.8555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(3.2049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(2.8531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 2.1798370530207953\n",
            "Loss/valid : 3.1596528689066568\n",
            "========= Epoch2 =========\n",
            "\n",
            "batch1 loss : tensor(2.7537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(1.3142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(3.6428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.8140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(2.1152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.9792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(1.0323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.6044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.6033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.8490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(1.7795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(2.9973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 1.6237483372290928\n",
            "Loss/valid : 1.620690147082011\n",
            "========= Epoch3 =========\n",
            "\n",
            "batch1 loss : tensor(1.7054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.6715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.4531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(1.7987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(1.4275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(2.2205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(2.5699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.4440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.8518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.3440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.7682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.5629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 1.1514706735809643\n",
            "Loss/valid : 1.0276736815770466\n",
            "========= Epoch4 =========\n",
            "\n",
            "batch1 loss : tensor(1.2016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.8918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.5001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.3816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.7411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.6927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.4032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.6848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(1.2250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(2.3746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(1.6890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.4788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.9386888767282168\n",
            "Loss/valid : 0.9085497458775839\n",
            "========= Epoch5 =========\n",
            "\n",
            "batch1 loss : tensor(0.7438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.3700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.4955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.7480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.7387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.5042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.5428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.5164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.4681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.3737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.7222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.5274265563736359\n",
            "Loss/valid : 1.1669005552927654\n",
            "========= Epoch6 =========\n",
            "\n",
            "batch1 loss : tensor(0.7589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.4742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.3673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.5863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(1.1598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(1.7858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(1.5994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.8476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.4456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.2487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.4532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.4067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.7611018034319083\n",
            "Loss/valid : 0.7754007577896118\n",
            "========= Epoch7 =========\n",
            "\n",
            "batch1 loss : tensor(0.2962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.2927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.7198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.7712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(1.2956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.9139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.3157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.3726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.3536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.2872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.5068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.4432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.547384537756443\n",
            "Loss/valid : 0.718174676100413\n",
            "========= Epoch8 =========\n",
            "\n",
            "batch1 loss : tensor(0.4346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.2069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.5353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.3321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.6967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(1.0740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.6995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.3717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.4664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(1.5725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.5936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.8616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.653732298562924\n",
            "Loss/valid : 0.8988141616185507\n",
            "========= Epoch9 =========\n",
            "\n",
            "batch1 loss : tensor(0.8976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.7642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.6542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.1982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.4541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.3553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.3899, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.4533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.4727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.4471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.4712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.4835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.5034506892164549\n",
            "Loss/valid : 0.8282237847646078\n",
            "========= Epoch10 =========\n",
            "\n",
            "batch1 loss : tensor(0.2128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.5718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.2761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.1504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.3931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.4370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.4397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.2369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.3874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.2934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.3547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.32808201884229976\n",
            "Loss/valid : 0.7215715646743774\n",
            "========= Epoch11 =========\n",
            "\n",
            "batch1 loss : tensor(0.2803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.3675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.2839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.2973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.2972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.3143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.4539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.7871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.3693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.3822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.34520186483860016\n",
            "Loss/valid : 0.7051267425219218\n",
            "========= Epoch12 =========\n",
            "\n",
            "batch1 loss : tensor(0.1962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.2038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.2255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.2699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.4098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.3846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.4112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.4469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.2082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.4705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.33443738395969075\n",
            "Loss/valid : 0.8447858095169067\n",
            "========= Epoch13 =========\n",
            "\n",
            "batch1 loss : tensor(0.4663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.2593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.2248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.2894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.3672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.2467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.2081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.2553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.4575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.2589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.2837982016305129\n",
            "Loss/valid : 0.6890637278556824\n",
            "========= Epoch14 =========\n",
            "\n",
            "batch1 loss : tensor(0.2120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.2571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.2886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.2229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.4435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.2309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.3562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.2099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.2093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.2661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.2154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.2559155250589053\n",
            "Loss/valid : 0.6858748396237692\n",
            "========= Epoch15 =========\n",
            "\n",
            "batch1 loss : tensor(0.3592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.4096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.4986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.2351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.2207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.2262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.1739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.2610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.2434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.2571866810321808\n",
            "Loss/valid : 0.7473718325297037\n",
            "========= Epoch16 =========\n",
            "\n",
            "batch1 loss : tensor(0.4362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.2455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.2365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.2141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.4543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.4011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.2001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.3223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.3201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.2832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.2500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.2926265684266885\n",
            "Loss/valid : 0.6808418532212576\n",
            "========= Epoch17 =========\n",
            "\n",
            "batch1 loss : tensor(0.2224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.2346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.1640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.2097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.2785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.2210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.2237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.3122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.2017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.20994287232557932\n",
            "Loss/valid : 0.7342673341433207\n",
            "========= Epoch18 =========\n",
            "\n",
            "batch1 loss : tensor(0.1944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.2540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.2042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.2162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.3118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.2946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.2242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.2212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.2081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.22171024978160858\n",
            "Loss/valid : 0.7754790584246317\n",
            "========= Epoch19 =========\n",
            "\n",
            "batch1 loss : tensor(0.2391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.1393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.2837, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.2390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.2210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.0880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.2135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.2543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.19274494610726833\n",
            "Loss/valid : 0.7107076446215311\n",
            "========= Epoch20 =========\n",
            "\n",
            "batch1 loss : tensor(0.1635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.3077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.3064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.2441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.0914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.2352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.2666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.4998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.2955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.1549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.23570941823224226\n",
            "Loss/valid : 0.7250526746114095\n",
            "========= Epoch21 =========\n",
            "\n",
            "batch1 loss : tensor(0.2292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.1416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.3537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.1352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.2011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.2168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.1851243500908216\n",
            "Loss/valid : 0.813306192557017\n",
            "========= Epoch22 =========\n",
            "\n",
            "batch1 loss : tensor(0.2220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.0634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.1360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.2677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.1252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.2974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.2803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.17996403016149998\n",
            "Loss/valid : 0.7971359888712565\n",
            "========= Epoch23 =========\n",
            "\n",
            "batch1 loss : tensor(0.2986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.3108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.1554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.2075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.2085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.0713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.1407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.1647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.1851869523525238\n",
            "Loss/valid : 0.772355337937673\n",
            "========= Epoch24 =========\n",
            "\n",
            "batch1 loss : tensor(0.1212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.1797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.3710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.2998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.0640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.1657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.1723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.1731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.17969817978640398\n",
            "Loss/valid : 0.7818907896677653\n",
            "========= Epoch25 =========\n",
            "\n",
            "batch1 loss : tensor(0.1221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.2015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.2155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.2489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.1038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.1915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.1540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.16731003733972707\n",
            "Loss/valid : 0.7764819860458374\n",
            "========= Epoch26 =========\n",
            "\n",
            "batch1 loss : tensor(0.1046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.0631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.1194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.1191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.2028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.14480562756458917\n",
            "Loss/valid : 0.8107606371243795\n",
            "========= Epoch27 =========\n",
            "\n",
            "batch1 loss : tensor(0.1285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.0793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.1311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.2268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.2199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.0884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.1362457157423099\n",
            "Loss/valid : 0.7992949585119883\n",
            "========= Epoch28 =========\n",
            "\n",
            "batch1 loss : tensor(0.1250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.0770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.1410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.2011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.0863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.1361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.1605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.1575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.13440625431636968\n",
            "Loss/valid : 0.8078743020693461\n",
            "========= Epoch29 =========\n",
            "\n",
            "batch1 loss : tensor(0.1520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.0832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.0728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.1059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.1987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.1476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.1342988566805919\n",
            "Loss/valid : 0.8318725426991781\n",
            "========= Epoch30 =========\n",
            "\n",
            "batch1 loss : tensor(0.0944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.0952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.0857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.1235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.1295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.12608473685880503\n",
            "Loss/valid : 0.8750839233398438\n",
            "========= Epoch31 =========\n",
            "\n",
            "batch1 loss : tensor(0.1459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.0702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.0808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.1045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.1833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.0973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.12223634061714013\n",
            "Loss/valid : 0.8572683731714884\n",
            "========= Epoch32 =========\n",
            "\n",
            "batch1 loss : tensor(0.1462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.2127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.0853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.0610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.0865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.1425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.2354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.4061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.15884426174064478\n",
            "Loss/valid : 1.087045431137085\n",
            "========= Epoch33 =========\n",
            "\n",
            "batch1 loss : tensor(0.4513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.5551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.4021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.0700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.0843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.1418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.0698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.0912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.20323381759226322\n",
            "Loss/valid : 0.8547885517279307\n",
            "========= Epoch34 =========\n",
            "\n",
            "batch1 loss : tensor(0.0721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.0997, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.0797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.0785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.0827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.0778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.1248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.10496546079715093\n",
            "Loss/valid : 0.8759988149007162\n",
            "========= Epoch35 =========\n",
            "\n",
            "batch1 loss : tensor(0.0782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.0956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.0782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.0865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.0820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.0575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.1260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.1248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.10523216519504786\n",
            "Loss/valid : 0.8760898212591807\n",
            "========= Epoch36 =========\n",
            "\n",
            "batch1 loss : tensor(0.0865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.0786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.0782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.0849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.2129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.0933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.1047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.0633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.0757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.10071385962267716\n",
            "Loss/valid : 0.8769461313883463\n",
            "========= Epoch37 =========\n",
            "\n",
            "batch1 loss : tensor(0.0653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.0778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.0428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.0716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.1751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.1605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.0756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.10150215464333694\n",
            "Loss/valid : 0.8731121023495992\n",
            "========= Epoch38 =========\n",
            "\n",
            "batch1 loss : tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.0821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.1264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.0721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.0998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.0787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.0922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.0904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.0676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.1287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.09079521304617326\n",
            "Loss/valid : 0.8989488780498505\n",
            "========= Epoch39 =========\n",
            "\n",
            "batch1 loss : tensor(0.0440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.0598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.0854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.1031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.0932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.0967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.0894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.0745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.1206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.0698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.08482739919175704\n",
            "Loss/valid : 0.9018408258756002\n",
            "========= Epoch40 =========\n",
            "\n",
            "batch1 loss : tensor(0.1318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.0648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.1120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.0922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.0873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.0579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.0920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.0573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.0577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.0800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.0805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.08307983291645844\n",
            "Loss/valid : 0.883631964524587\n",
            "========= Epoch41 =========\n",
            "\n",
            "batch1 loss : tensor(0.0889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.1284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.0647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.0609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.0743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.0968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.0532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.0756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.1153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.0637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.0726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.08167550650735696\n",
            "Loss/valid : 0.8855803608894348\n",
            "========= Epoch42 =========\n",
            "\n",
            "batch1 loss : tensor(0.0581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.0165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.2081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.0681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.1612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.2432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.0991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.0813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.0402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.0505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.1257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.10226876940578222\n",
            "Loss/valid : 0.9081634084383646\n",
            "========= Epoch43 =========\n",
            "\n",
            "batch1 loss : tensor(0.0581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.0686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.0774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.0625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.0381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.0856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.0928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.0981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.0689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.07680793603261311\n",
            "Loss/valid : 0.9012227455774943\n",
            "========= Epoch44 =========\n",
            "\n",
            "batch1 loss : tensor(0.0804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.0492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.0861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.0851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.0919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.0317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.0595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.1018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.0639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.1576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.0872674376393358\n",
            "Loss/valid : 1.0282150705655415\n",
            "========= Epoch45 =========\n",
            "\n",
            "batch1 loss : tensor(0.1014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.0682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.0673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.0195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.0961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.0624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.1103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.0656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.0522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.0817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.07635918554539482\n",
            "Loss/valid : 0.9071545600891113\n",
            "========= Epoch46 =========\n",
            "\n",
            "batch1 loss : tensor(0.0540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.0668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.0677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.0385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.0682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.0714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.0561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.0631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.1021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.0907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.0988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.07048365970452626\n",
            "Loss/valid : 0.9205746452013651\n",
            "========= Epoch47 =========\n",
            "\n",
            "batch1 loss : tensor(0.0488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.0928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.0513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.0929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.0727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.1227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.0542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.0749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.0348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.0951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.0966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.07446058963735898\n",
            "Loss/valid : 0.9297589858373007\n",
            "========= Epoch48 =========\n",
            "\n",
            "batch1 loss : tensor(0.0727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.0573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.0811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.0392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.0537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.0771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.0471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.0352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.0617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.0592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.06915042052666347\n",
            "Loss/valid : 0.9379279414812723\n",
            "========= Epoch49 =========\n",
            "\n",
            "batch1 loss : tensor(0.0549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.0639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.0445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.0901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.0905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.0455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.0816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.0667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.0722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.0493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.0790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.0705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.06738171509156625\n",
            "Loss/valid : 0.9486874938011169\n",
            "========= Epoch50 =========\n",
            "\n",
            "batch1 loss : tensor(0.1436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch2 loss : tensor(0.1751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch3 loss : tensor(0.0611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch4 loss : tensor(0.0671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch5 loss : tensor(0.0833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch6 loss : tensor(0.0942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch7 loss : tensor(0.0279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch8 loss : tensor(0.1010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch9 loss : tensor(0.0818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch10 loss : tensor(0.0294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch11 loss : tensor(0.0436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "batch12 loss : tensor(0.0587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss/train : 0.0805637389421463\n",
            "Loss/valid : 0.9280391335487366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### avg_loss, avg_vloss가 계속 같은 값으로 나오는 현상\n",
        "- 학습이 진행되도 avg_loss와 avg_vloss가 계속 같은 값으로 나오는 현상이 발생했는데 처음에는 데이터 셋이나 모델에 문제가 있나 해서 살펴보았는데 딱히 문제는 없었다. 어디가 문제인가 살펴보니 loss가 변하지 않는다는 것은 파라미터 업데이트가 안된다는 것을 의미했고 다시 살펴보니 모델을 변경한 후에 optimizer를 새롭게 설정해주지 않아서 생긴 문제였다."
      ],
      "metadata": {
        "id": "9jhRSFG0iDrw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 전체 데이터로 모델을 돌리기 전에 샘플 데이터로 우선적으로 돌려보기\n",
        "- 모델 training은 많은 비용이 들어가는 작업이다. 특히, 데이터가 많고 클수록. 그렇기 때문에 비용을 절약하기 위해서는 전체 학습 데이터로 모델을 학습하기 전에 샘플 데이터로 우선적으로 학습을 진행하여 모델이 정상적으로 작동하는지 확인하는 작업이 필요하다."
      ],
      "metadata": {
        "id": "DiWuZSxg6d_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "J4d4uRrN625Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}