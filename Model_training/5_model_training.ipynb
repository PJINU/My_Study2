{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_model_training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "n6oT8FnQERsx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import SGD\n",
        "from torch.optim.lr_scheduler import LinearLR\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU 사용 설정"
      ],
      "metadata": {
        "id": "LS8XkyMMFXPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SnGHzgSwEj_3",
        "outputId": "89d7c7ff-5983-4b5b-e74f-6d6a1c75034c"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 가져오기"
      ],
      "metadata": {
        "id": "o9XFVVWXFWQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/drive/MyDrive/고모부_머신러닝/dogncat\n",
        "paths = []\n",
        "dataset_type = []\n",
        "labels = []\n",
        "\n",
        "def make_dataframe(dirpath):\n",
        "    for dirname, _, filenames in os.walk(dirpath):\n",
        "        for filename in filenames:\n",
        "            file_path = dirname+'/'+filename\n",
        "            paths.append(file_path)\n",
        "\n",
        "            if '/training_set' in file_path:\n",
        "                dataset_type.append('train')\n",
        "            elif '/test_set' in file_path:\n",
        "                dataset_type.append('test')\n",
        "            else:\n",
        "                dataset_type.append('N/A')\n",
        "            \n",
        "            if 'dogs' in file_path:\n",
        "                labels.append('DOG')\n",
        "            elif 'cats' in file_path:\n",
        "                labels.append('CAT')\n",
        "            else:\n",
        "                labels.append('N/A')\n",
        "\n",
        "    df = pd.DataFrame({'path' : paths, 'type' : dataset_type, 'label' : labels})\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "K4dHXAT4FbLl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnd_df = make_dataframe('/content/drive/MyDrive/고모부_머신러닝/dogncat')\n",
        "cnd_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TZGsFEuqHlwS",
        "outputId": "0cac5708-e70d-4c0a-efbd-0a671a3f63ce"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                path  type label\n",
              "0  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "1  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "2  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "3  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT\n",
              "4  /content/drive/MyDrive/고모부_머신러닝/dognc...  test   CAT"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32e6db22-47f0-4165-a550-971d0b346ef8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>type</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/고모부_머신러닝/dognc...</td>\n",
              "      <td>test</td>\n",
              "      <td>CAT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32e6db22-47f0-4165-a550-971d0b346ef8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32e6db22-47f0-4165-a550-971d0b346ef8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32e6db22-47f0-4165-a550-971d0b346ef8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnd_df = cnd_df[cnd_df['path'].str.contains('.jpg')].copy()\n",
        "cnd_df.info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYEVxo13HsK5",
        "outputId": "98a475f4-84f6-427c-d96d-7411135ab465"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 10028 entries, 0 to 10031\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   path    10028 non-null  object\n",
            " 1   type    10028 non-null  object\n",
            " 2   label   10028 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 313.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train, valid dataset 만들기\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train, validation 분리\n",
        "train_df, valid_df = train_test_split(cnd_df[cnd_df['type']=='train'], test_size = 0.25, )\n",
        "\n",
        "# train dataset\n",
        "train_data = train_df['path'].values\n",
        "train_label = train_df['label'].values\n",
        "train_label_indices = train_df['label'].replace(['CAT', 'DOG'], [0, 1]).values\n",
        "\n",
        "# validation dataset\n",
        "valid_data = valid_df['path'].values\n",
        "valid_label = valid_df['label'].values\n",
        "valid_label_indices = valid_df['label'].replace(['CAT', 'DOG'], [0,1]).values\n"
      ],
      "metadata": {
        "id": "GiZrO5gRIGoy"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tr = train_df.sample(10)\n",
        "sample_val = valid_df.sample(10)\n",
        "\n",
        "print(sample_tr.head(10))\n",
        "print(sample_val.head(10))"
      ],
      "metadata": {
        "id": "14JLtSN-AmGo",
        "outputId": "0b22bf80-1fd2-46c9-c902-1380032d49c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   path   type label\n",
            "7618  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   DOG\n",
            "9922  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   DOG\n",
            "4922  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   CAT\n",
            "2832  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   CAT\n",
            "2393  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   CAT\n",
            "4898  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   CAT\n",
            "9760  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   DOG\n",
            "2924  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   CAT\n",
            "6997  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   DOG\n",
            "7868  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   DOG\n",
            "                                                   path   type label\n",
            "3552  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   CAT\n",
            "2372  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   CAT\n",
            "6647  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   DOG\n",
            "5229  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   CAT\n",
            "7103  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   DOG\n",
            "7802  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   DOG\n",
            "8245  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   DOG\n",
            "3931  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   CAT\n",
            "3887  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   CAT\n",
            "3066  /content/drive/MyDrive/고모부_머신러닝/dognc...  train   CAT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tr_data = sample_tr['path'].values\n",
        "sample_tr_label = sample_tr['label'].replace(['CAT', 'DOG'], [0,1]).values\n",
        "sample_val_data = sample_val['path'].values\n",
        "sample_val_label = sample_val['label'].replace(['CAT', 'DOG'], [0,1]).values"
      ],
      "metadata": {
        "id": "txpeEVRgBSgS"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample_tr_data)\n",
        "print(sample_tr_label)"
      ],
      "metadata": {
        "id": "LOsSc46UBx9g",
        "outputId": "5d835c8d-f160-4a9c-b09b-d36b70b35d41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/고모부_머신러닝/dogncat/training_set/training_set/dogs/dog.3932.jpg'\n",
            " '/content/drive/MyDrive/고모부_머신러닝/dogncat/training_set/training_set/dogs/dog.1770.jpg'\n",
            " '/content/drive/MyDrive/고모부_머신러닝/dogncat/training_set/training_set/cats/cat.275.jpg'\n",
            " '/content/drive/MyDrive/고모부_머신러닝/dogncat/training_set/training_set/cats/cat.74.jpg'\n",
            " '/content/drive/MyDrive/고모부_머신러닝/dogncat/training_set/training_set/cats/cat.3329.jpg'\n",
            " '/content/drive/MyDrive/고모부_머신러닝/dogncat/training_set/training_set/cats/cat.2271.jpg'\n",
            " '/content/drive/MyDrive/고모부_머신러닝/dogncat/training_set/training_set/dogs/dog.185.jpg'\n",
            " '/content/drive/MyDrive/고모부_머신러닝/dogncat/training_set/training_set/cats/cat.950.jpg'\n",
            " '/content/drive/MyDrive/고모부_머신러닝/dogncat/training_set/training_set/dogs/dog.829.jpg'\n",
            " '/content/drive/MyDrive/고모부_머신러닝/dogncat/training_set/training_set/dogs/dog.396.jpg']\n",
            "[1 1 0 0 0 0 1 0 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data))\n",
        "print(len(train_label_indices))\n",
        "\n",
        "print(len(valid_data))\n",
        "print(len(valid_label_indices))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbRgOqjfNSAu",
        "outputId": "e2d65d4b-2f15-4092-873a-3ffcf030457a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6003\n",
            "6003\n",
            "2002\n",
            "2002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test dataset 만들기\n",
        "test_data = cnd_df['path'][cnd_df['type']=='test']\n",
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVlxa300K3E6",
        "outputId": "da631b12-aae6-4b60-b20e-94dc1bbef1e1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "1       /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "2       /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "3       /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "4       /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "                              ...                        \n",
              "2020    /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "2021    /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "2022    /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "2023    /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "2024    /content/drive/MyDrive/고모부_머신러닝/dognc...\n",
              "Name: path, Length: 2023, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom dataset 만들기"
      ],
      "metadata": {
        "id": "UWS3WukiO50z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, datapath, label=None):\n",
        "        super(MyDataset, self).__init__()\n",
        "\n",
        "        self.path = datapath\n",
        "        self.label = label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.path)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "\n",
        "        image = cv2.cvtColor(cv2.imread(self.path[idx]), cv2.COLOR_BGR2RGB)\n",
        "        image = cv2.resize(image, (244,244))\n",
        "        image = np.asarray(image, dtype=np.float32).transpose(2,0,1)\n",
        "        normal_image = (image - np.amin(image)) / (np.amax(image) - np.amin(image))\n",
        "        \n",
        "        if self.label is not None:\n",
        "            label = self.label[idx]\n",
        "\n",
        "        return normal_image, label\n"
      ],
      "metadata": {
        "id": "Dah4BaTtPUMR"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MyDataset(train_data, train_label_indices)\n",
        "valid_dataset = MyDataset(valid_data, valid_label_indices)\n",
        "test_dataset = MyDataset(test_data)"
      ],
      "metadata": {
        "id": "yePXrmtCT7gl"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(len(train_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJMSQmuMfaCd",
        "outputId": "34496acb-9cce-4540-b645-76b7170f8436"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_dataset = MyDataset(sample_tr_data, sample_tr_label)"
      ],
      "metadata": {
        "id": "QUjpikl5CelL"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loader 만들기"
      ],
      "metadata": {
        "id": "1q5i3R95TVTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=10, shuffle=False) # 왜 valid loader에서는 shuffle을 false로 하지?"
      ],
      "metadata": {
        "id": "jn8MGXYtTW6Y"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader_data = next(iter(train_loader))"
      ],
      "metadata": {
        "id": "tF8oVJMuaVgN"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_loader = DataLoader(sample_dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "rK8Y8CnKCNYN"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 만들기"
      ],
      "metadata": {
        "id": "hEBzJynxXtRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 5, kernel_size=3, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc1 = nn.Linear(5*244*244, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        print('input size :', x.shape)\n",
        "        print('input max :', torch.amax(x, dim=(1,2,3)))\n",
        "        print('input min :', torch.amin(x, dim=(1,2,3)))\n",
        "        print('input l2norm :', torch.linalg.vector_norm(x, dim=(1,2,3)))\n",
        "\n",
        "        conv = self.conv1(x)\n",
        "        print('conv size :', conv.shape)\n",
        "        print('conv max :', torch.amax(conv, dim=(1,2,3)))\n",
        "        print('conv min :', torch.amin(conv, dim=(1,2,3)))\n",
        "        print('conv l2norm :', torch.linalg.vector_norm(conv, dim=(1,2,3)))\n",
        "\n",
        "        conv_out = self.relu(conv)\n",
        "        print('conv_out size :', conv_out.shape)\n",
        "        print('conv_out max :', torch.amax(conv_out, dim=(1,2,3)))\n",
        "        print('conv_out min :', torch.amin(conv_out, dim=(1,2,3)))\n",
        "        print('conv_out l2norm :', torch.linalg.vector_norm(conv_out, dim=(1,2,3)))\n",
        "\n",
        "        fc_input = conv_out.view(conv_out.size(0), -1)\n",
        "        print('fc_input size :', fc_input.shape)\n",
        "        print('fc_input max :', torch.amax(fc_input, dim=(1)))\n",
        "        print('fc_input min :', torch.amin(fc_input, dim=(1)))\n",
        "        print('fc_input l2norm :', torch.linalg.vector_norm(fc_input, dim=(1)))\n",
        "\n",
        "        fc_logit = self.fc1(fc_input)\n",
        "        print('fc_logit size :', fc_logit.shape)\n",
        "        print('fc_logit max :', torch.amax(fc_logit, dim=(1)))\n",
        "        print('fc_logit min :', torch.amin(fc_logit, dim=(1)))\n",
        "        print('fc_logit l2norm :', torch.linalg.vector_norm(fc_logit, dim=(1)))\n",
        "        print()\n",
        "\n",
        "        return fc_logit"
      ],
      "metadata": {
        "id": "1fR_fHs4Ynlj"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN().to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8v11c71bKJ4",
        "outputId": "1b90bf06-8e6f-4063-e17d-4e712628ff19"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (relu): ReLU()\n",
              "  (fc1): Linear(in_features=297680, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### loss function"
      ],
      "metadata": {
        "id": "OCb0U7mFbMqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "id": "191rvsBBbP0w"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### optimzer, lr_scheduler 설정"
      ],
      "metadata": {
        "id": "D4uHvlBIbS9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = SGD(model.parameters(), lr=0.001)\n",
        "scheduler = LinearLR(optimizer)"
      ],
      "metadata": {
        "id": "6PoD6t7ZbcjC"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 training"
      ],
      "metadata": {
        "id": "0jJQXZ_JcCiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(loader):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "\n",
        "    for i, data in enumerate(loader):\n",
        "        image_data, label_data = data\n",
        "        image_data = image_data.to(device)\n",
        "        label_data = label_data.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        hyphothesis = model(image_data)\n",
        "\n",
        "        loss = loss_fn(hyphothesis, label_data)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        print(f'batch{i+1} loss : {loss}')\n",
        "        print()\n",
        "        print(f'gradient max :', torch.amax(torch.tensor([torch.amax(param.grad) for param in model.parameters()])))\n",
        "        print(f'gradient min :', torch.amin(torch.tensor([torch.amax(param.grad) for param in model.parameters()])))\n",
        "        print(f'gradient l2norm :', torch.amax(torch.tensor([torch.linalg.vector_norm(param.grad) for param in model.parameters()])))\n",
        "        print()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # last_loss = running_loss / len(loader)\n",
        "        # print(f'Average batch loss :', last_loss)\n",
        "        # print()\n",
        "        # last_loss = 0\n",
        "\n",
        "\n",
        "        if i+1 == len(loader):\n",
        "            last_loss = running_loss / len(loader)\n",
        "            print(f'Average batch loss :', last_loss)\n",
        "            print()\n",
        "            running_loss = 0\n",
        "\n",
        "    return last_loss\n"
      ],
      "metadata": {
        "id": "i7NaWtP4eI8f"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 50\n",
        "for i in range(epoch):\n",
        "    print(f'========= Epoch{i+1} =========')\n",
        "    print()\n",
        "    model.train(True)\n",
        "    train_one_epoch(sample_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2OET9RvhreZ",
        "outputId": "1f6bdc84-d0d1-4142-f4f0-b4573e174747"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "fc_logit max : tensor([2.3738, 1.5128], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.6306, -1.6455], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.5433, 2.2352], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.02415481209754944\n",
            "\n",
            "gradient max : tensor(0.0320)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(4.0051)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([261.5967, 229.3072], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1247, 0.8228], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6742, -0.6172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([200.4118, 182.4229], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1247, 0.8228], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([176.7122, 156.4676], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1247, 0.8228], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([176.7122, 156.4676], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([3.1155, 1.9201], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-3.1962, -2.1309], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([4.4634, 2.8684], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.009534250013530254\n",
            "\n",
            "gradient max : tensor(0.0095)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(2.0670)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([203.0964, 223.8824], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0585, 1.1200], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6250, -0.6102], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([158.6949, 174.2481], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0585, 1.1200], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([138.4799, 150.4576], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0585, 1.1200], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([138.4799, 150.4576], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.0521, 1.7831], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1759, -2.1148], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9910, 2.7662], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.01727820560336113\n",
            "\n",
            "gradient max : tensor(0.0185)\n",
            "gradient min : tensor(-1.1634e-05)\n",
            "gradient l2norm : tensor(3.2735)\n",
            "\n",
            "Average batch loss : 0.01805082391947508\n",
            "\n",
            "========= Epoch19 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([233.3550, 229.3072], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9180, 0.8231], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6856, -0.6172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([182.8124, 182.5055], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9180, 0.8231], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([155.7982, 156.5647], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9180, 0.8231], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([155.7982, 156.5647], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.0689, 2.0891], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1888, -2.3000], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.0119, 3.1072], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.013194845989346504\n",
            "\n",
            "gradient max : tensor(0.0064)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.0539)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([212.0123, 203.0964], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9076, 1.0589], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6374, -0.6250], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([168.4069, 158.7806], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9076, 1.0589], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([141.2850, 138.5792], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9076, 1.0589], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([141.2850, 138.5792], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1480, 2.1442], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.4052, -2.2681], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.2247, 3.1212], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.011266937479376793\n",
            "\n",
            "gradient max : tensor(0.0053)\n",
            "gradient min : tensor(1.2449e-06)\n",
            "gradient l2norm : tensor(0.9155)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([236.9645, 261.5967], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9866, 1.1255], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6420, -0.6742], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([186.8379, 200.6008], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9866, 1.1255], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([163.3521, 176.9297], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9866, 1.1255], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([163.3521, 176.9297], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.6846, 3.2959], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-1.9384, -3.3769], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.5681, 4.7187], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.01380806602537632\n",
            "\n",
            "gradient max : tensor(0.0333)\n",
            "gradient min : tensor(0.0064)\n",
            "gradient l2norm : tensor(2.8927)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([163.1357, 220.2781], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8666, 0.8613], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5537, -0.6491], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([132.6024, 176.5200], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8666, 0.8613], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([109.2411, 149.2764], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8666, 0.8613], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([109.2411, 149.2764], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.8415, 1.7989], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-1.8866, -1.9605], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.6364, 2.6608], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.023391947150230408\n",
            "\n",
            "gradient max : tensor(0.0580)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(3.9346)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([223.8824, 232.2669], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1208, 0.9719], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6102, -0.5668], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([174.4879, 179.2195], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1208, 0.9719], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([150.7366, 155.6664], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1208, 0.9719], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([150.7366, 155.6664], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.6939, 1.6092], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.0260, -1.7420], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.6408, 2.3715], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.02919599413871765\n",
            "\n",
            "gradient max : tensor(0.0386)\n",
            "gradient min : tensor(0.0012)\n",
            "gradient l2norm : tensor(6.0408)\n",
            "\n",
            "Average batch loss : 0.018171558156609535\n",
            "\n",
            "========= Epoch20 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([163.1357, 220.2781], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8674, 0.8621], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5537, -0.6491], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([132.6983, 176.6539], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8674, 0.8621], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([109.3596, 149.4353], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8674, 0.8621], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([109.3596, 149.4353], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.8112, 1.7506], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-1.8563, -1.9124], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.5935, 2.5927], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.025275206193327904\n",
            "\n",
            "gradient max : tensor(0.0669)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(4.2651)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([229.3072, 236.9645], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8254, 0.9872], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6172, -0.6420], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([182.8415, 187.1084], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8254, 0.9872], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([156.9594, 163.6631], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8254, 0.9872], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([156.9594, 163.6631], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9729, 1.8184], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1842, -2.0726], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9433, 2.7573], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.01787494495511055\n",
            "\n",
            "gradient max : tensor(0.0090)\n",
            "gradient min : tensor(1.1936e-05)\n",
            "gradient l2norm : tensor(1.7027)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([261.5967, 212.0123], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1263, 0.9103], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6742, -0.6374], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([200.9597, 168.7192], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1263, 0.9103], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([177.3415, 141.6607], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1263, 0.9103], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([177.3415, 141.6607], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([3.1574, 2.2823], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-3.2383, -2.5399], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([4.5228, 3.4147], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.004842105321586132\n",
            "\n",
            "gradient max : tensor(0.0074)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(0.6565)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([233.3550, 223.8824], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9212, 1.1215], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6856, -0.6102], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([183.2254, 174.7030], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9212, 1.1215], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([156.2865, 150.9865], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9212, 1.1215], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([156.2865, 150.9865], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.2587, 1.7389], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.3788, -2.0713], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.2803, 2.7045], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.01576780527830124\n",
            "\n",
            "gradient max : tensor(0.0113)\n",
            "gradient min : tensor(-1.4326e-05)\n",
            "gradient l2norm : tensor(1.5428)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([203.0964, 232.2669], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0600, 0.9731], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6250, -0.5668], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([159.1399, 179.4895], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0600, 0.9731], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([138.9957, 155.9788], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0600, 0.9731], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([138.9957, 155.9788], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.0506, 1.6991], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1747, -1.8320], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9890, 2.4986], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.021684661507606506\n",
            "\n",
            "gradient max : tensor(0.0233)\n",
            "gradient min : tensor(0.0008)\n",
            "gradient l2norm : tensor(4.2713)\n",
            "\n",
            "Average batch loss : 0.017088944651186468\n",
            "\n",
            "========= Epoch21 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([229.3072, 212.0123], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8264, 0.9109], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6172, -0.6374], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([183.0151, 168.8232], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8264, 0.9109], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([157.1634, 141.7862], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8264, 0.9109], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([157.1634, 141.7862], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1120, 2.1625], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.3235, -2.4204], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.1400, 3.2457], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.010976146906614304\n",
            "\n",
            "gradient max : tensor(0.0047)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(0.7914)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([233.3550, 203.0964], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9220, 1.0605], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6856, -0.6250], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([183.3632, 159.2256], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9220, 1.0605], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([156.4500, 139.0949], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9220, 1.0605], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([156.4500, 139.0949], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.0880, 2.1780], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2083, -2.3021], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.0391, 3.1691], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.012397969141602516\n",
            "\n",
            "gradient max : tensor(0.0062)\n",
            "gradient min : tensor(2.2531e-06)\n",
            "gradient l2norm : tensor(1.1157)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([220.2781, 232.2669], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8642, 0.9738], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6491, -0.5668], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([176.9692, 179.6273], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8642, 0.9738], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([149.8091, 156.1384], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8642, 0.9738], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([149.8091, 156.1384], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.7687, 1.8421], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-1.9308, -1.9751], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.6185, 2.7008], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.023092366755008698\n",
            "\n",
            "gradient max : tensor(0.0098)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.4795)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([236.9645, 163.1357], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9882, 0.8700], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6420, -0.5537], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([187.4407, 132.9603], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9882, 0.8700], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([164.0456, 109.6840], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9882, 0.8700], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([164.0456, 109.6840], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.7017, 1.8318], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-1.9565, -1.8767], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.5930, 2.6225], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.024834860116243362\n",
            "\n",
            "gradient max : tensor(0.0667)\n",
            "gradient min : tensor(1.4999e-05)\n",
            "gradient l2norm : tensor(4.2353)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([261.5967, 223.8824], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1275, 1.1226], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6742, -0.6102], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([201.3428, 175.0140], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1275, 1.1226], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([177.7818, 151.3480], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1275, 1.1226], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([177.7818, 151.3480], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([3.1954, 1.7868], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-3.2765, -2.1197], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([4.5767, 2.7723], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.010728532448410988\n",
            "\n",
            "gradient max : tensor(0.0115)\n",
            "gradient min : tensor(0.0002)\n",
            "gradient l2norm : tensor(2.2744)\n",
            "\n",
            "Average batch loss : 0.016405975073575975\n",
            "\n",
            "========= Epoch22 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([203.0964, 220.2781], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0610, 0.8654], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6250, -0.6491], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([159.4065, 177.1299], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0610, 0.8654], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([139.3045, 149.9996], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0610, 0.8654], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([139.3045, 149.9996], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1268, 1.8357], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2510, -1.9979], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.0969, 2.7131], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.01693824492394924\n",
            "\n",
            "gradient max : tensor(0.0112)\n",
            "gradient min : tensor(2.4925e-06)\n",
            "gradient l2norm : tensor(1.8044)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([236.9645, 229.3072], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9885, 0.8284], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6420, -0.6172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([187.6078, 183.3114], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9885, 0.8284], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([164.2375, 157.5112], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9885, 0.8284], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([164.2375, 157.5112], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.8025, 2.0234], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.0575, -2.2352], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.7353, 3.0151], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.017446156591176987\n",
            "\n",
            "gradient max : tensor(0.0093)\n",
            "gradient min : tensor(1.2319e-05)\n",
            "gradient l2norm : tensor(1.7577)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([233.3550, 261.5967], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9244, 1.1279], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6856, -0.6742], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([183.6778, 201.5003], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9244, 1.1279], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([156.8218, 177.9626], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9244, 1.1279], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([156.8218, 177.9626], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.2386, 3.2200], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.3589, -3.3012], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.2520, 4.6116], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.005748621188104153\n",
            "\n",
            "gradient max : tensor(0.0104)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(0.9700)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([163.1357, 223.8824], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8718, 1.1231], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5537, -0.6102], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([133.1131, 175.1687], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8718, 1.1231], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([109.8730, 151.5278], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8718, 1.1231], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([109.8730, 151.5278], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9366, 1.7839], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-1.9813, -2.1171], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.7705, 2.7685], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.01985395886003971\n",
            "\n",
            "gradient max : tensor(0.0104)\n",
            "gradient min : tensor(-1.3123e-05)\n",
            "gradient l2norm : tensor(1.4010)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([212.0123, 232.2669], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9142, 0.9751], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6374, -0.5668], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([169.2112, 179.9910], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9142, 0.9751], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([142.2525, 156.5588], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9142, 0.9751], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([142.2525, 156.5588], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.2770, 1.7297], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.5355, -1.8627], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.4079, 2.5420], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.01762690767645836\n",
            "\n",
            "gradient max : tensor(0.0126)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(2.4221)\n",
            "\n",
            "Average batch loss : 0.01552277784794569\n",
            "\n",
            "========= Epoch23 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([223.8824, 220.2781], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1235, 0.8669], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6102, -0.6491], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([175.2764, 177.3538], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1235, 0.8669], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([151.6527, 150.2648], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1235, 0.8669], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([151.6527, 150.2648], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.8899, 1.8400], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2233, -2.0024], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9180, 2.7194], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.018719248473644257\n",
            "\n",
            "gradient max : tensor(0.0084)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.2523)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([233.3550, 203.0964], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9256, 1.0619], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6856, -0.6250], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([183.8603, 159.6598], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9256, 1.0619], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([157.0377, 139.5977], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9256, 1.0619], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([157.0377, 139.5977], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1978, 2.1424], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.3183, -2.2667], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.1946, 3.1189], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.011482099071145058\n",
            "\n",
            "gradient max : tensor(0.0054)\n",
            "gradient min : tensor(1.2320e-06)\n",
            "gradient l2norm : tensor(0.9766)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([261.5967, 236.9645], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1287, 0.9893], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6742, -0.6420], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([201.7533, 187.8985], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1287, 0.9893], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([178.2531, 164.5715], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1287, 0.9893], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([178.2531, 164.5715], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([3.2903, 1.7880], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-3.3717, -2.0435], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([4.7111, 2.7152], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.011362433433532715\n",
            "\n",
            "gradient max : tensor(0.0258)\n",
            "gradient min : tensor(0.0040)\n",
            "gradient l2norm : tensor(2.3563)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([212.0123, 229.3072], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9154, 0.8305], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6374, -0.6172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([169.3631, 183.6193], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9154, 0.8305], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([142.4353, 157.8723], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9154, 0.8305], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([142.4353, 157.8723], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.3062, 2.0007], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.5649, -2.2129], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.4492, 2.9833], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.011160073801875114\n",
            "\n",
            "gradient max : tensor(0.0059)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.1204)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([232.2669, 163.1357], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9759, 0.8737], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5668, -0.5537], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([180.2045, 133.2960], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9759, 0.8737], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([156.8059, 110.0990], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9759, 0.8737], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([156.8059, 110.0990], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.7590, 1.9240], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-1.8920, -1.9686], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.5834, 2.7526], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.022910911589860916\n",
            "\n",
            "gradient max : tensor(0.0109)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.8433)\n",
            "\n",
            "Average batch loss : 0.015126953274011612\n",
            "\n",
            "========= Epoch24 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([163.1357, 229.3072], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8740, 0.8311], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5537, -0.6172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([133.3419, 183.7224], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8740, 0.8311], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([110.1554, 157.9931], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8740, 0.8311], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([110.1554, 157.9931], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9078, 2.0824], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-1.9524, -2.2947], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.7298, 3.0987], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.01666411943733692\n",
            "\n",
            "gradient max : tensor(0.0101)\n",
            "gradient min : tensor(0.0008)\n",
            "gradient l2norm : tensor(1.4674)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([232.2669, 261.5967], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9766, 1.1294], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5668, -0.6742], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([180.3340, 201.9801], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9766, 1.1294], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([156.9550, 178.5127], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9766, 1.1294], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([156.9550, 178.5127], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.8075, 3.3097], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-1.9406, -3.3912], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.6519, 4.7386], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.012260113842785358\n",
            "\n",
            "gradient max : tensor(0.0193)\n",
            "gradient min : tensor(0.0006)\n",
            "gradient l2norm : tensor(2.6809)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([223.8824, 220.2781], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1247, 0.8688], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6102, -0.6491], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([175.5936, 177.6598], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1247, 0.8688], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([152.0206, 150.6270], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1247, 0.8688], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([152.0206, 150.6270], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9670, 1.7889], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.3011, -1.9517], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.0272, 2.6475], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.018687326461076736\n",
            "\n",
            "gradient max : tensor(0.0129)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.4903)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([212.0123, 236.9645], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9169, 0.9902], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6374, -0.6420], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([169.5826, 188.1973], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9169, 0.9902], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([142.6988, 164.9144], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9169, 0.9902], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([142.6988, 164.9144], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1972, 1.7510], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.4564, -2.0070], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.2957, 2.6635], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.016272401437163353\n",
            "\n",
            "gradient max : tensor(0.0436)\n",
            "gradient min : tensor(0.0090)\n",
            "gradient l2norm : tensor(3.4312)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([203.0964, 233.3550], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0630, 0.9284], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6250, -0.6856], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([159.9818, 184.2289], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0630, 0.9284], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([139.9700, 157.4727], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0630, 0.9284], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([139.9700, 157.4727], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1015, 2.2558], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2260, -2.3765], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.0612, 3.2766], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.011400321498513222\n",
            "\n",
            "gradient max : tensor(0.0060)\n",
            "gradient min : tensor(1.3381e-06)\n",
            "gradient l2norm : tensor(0.9864)\n",
            "\n",
            "Average batch loss : 0.015056856535375118\n",
            "\n",
            "========= Epoch25 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([236.9645, 223.8824], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9903, 1.1250], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6420, -0.6102], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([188.2867, 175.7287], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9903, 1.1250], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([165.0172, 152.1777], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9903, 1.1250], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([165.0172, 152.1777], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.8705, 1.8516], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1265, -2.1858], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.8321, 2.8647], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.01784612610936165\n",
            "\n",
            "gradient max : tensor(0.0080)\n",
            "gradient min : tensor(2.9851e-06)\n",
            "gradient l2norm : tensor(1.4181)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([232.2669, 212.0123], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9773, 0.9182], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5668, -0.6374], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([180.5596, 169.7063], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9773, 0.9182], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([157.2159, 142.8473], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9773, 0.9182], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([157.2159, 142.8473], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.7859, 2.3021], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-1.9191, -2.5614], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.6215, 3.4439], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.015998225659132004\n",
            "\n",
            "gradient max : tensor(0.0113)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(2.1539)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([203.0964, 233.3550], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0635, 0.9293], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6250, -0.6856], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([160.0985, 184.3603], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0635, 0.9293], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([140.1052, 157.6281], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0635, 0.9293], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([140.1052, 157.6281], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1542, 2.1997], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2788, -2.3205], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.1358, 3.1974], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.011318341828882694\n",
            "\n",
            "gradient max : tensor(0.0052)\n",
            "gradient min : tensor(1.2021e-06)\n",
            "gradient l2norm : tensor(0.9672)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([261.5967, 229.3072], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1304, 0.8334], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6742, -0.6172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([202.3265, 184.0816], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1304, 0.8334], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([178.9106, 158.4142], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1304, 0.8334], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([178.9106, 158.4142], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([3.3358, 2.0917], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-3.4174, -2.3044], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([4.7756, 3.1122], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.006708045955747366\n",
            "\n",
            "gradient max : tensor(0.0067)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.4770)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([220.2781, 163.1357], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8709, 0.8766], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6491, -0.5537], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([177.9426, 133.6008], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8709, 0.8766], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([150.9617, 110.4749], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8709, 0.8766], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([150.9617, 110.4749], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.8249, 1.8856], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-1.9879, -1.9300], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.6985, 2.6982], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.021816851571202278\n",
            "\n",
            "gradient max : tensor(0.0591)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(3.7252)\n",
            "\n",
            "Average batch loss : 0.014737518224865197\n",
            "\n",
            "========= Epoch26 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([212.0123, 220.2781], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9193, 0.8714], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6374, -0.6491], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([169.8596, 178.0085], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9193, 0.8714], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([143.0312, 151.0396], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9193, 0.8714], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([143.0312, 151.0396], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.3158, 1.9522], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.5754, -2.1152], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.4634, 2.8785], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.012230033986270428\n",
            "\n",
            "gradient max : tensor(0.0300)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(2.4165)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([236.9645, 223.8824], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9909, 1.1258], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6420, -0.6102], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([188.5658, 175.9882], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9909, 1.1258], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([165.3374, 152.4788], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9909, 1.1258], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([165.3374, 152.4788], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9569, 1.7727], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2134, -2.1073], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9545, 2.7537], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.01788461022078991\n",
            "\n",
            "gradient max : tensor(0.0094)\n",
            "gradient min : tensor(-3.3294e-06)\n",
            "gradient l2norm : tensor(1.4465)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([232.2669, 203.0964], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9783, 1.0640], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5668, -0.6250], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([180.8285, 160.2902], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9783, 1.0640], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([157.5265, 140.3269], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9783, 1.0640], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([157.5265, 140.3269], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.7252, 2.0721], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-1.8583, -2.1967], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.5357, 3.0198], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.02065020613372326\n",
            "\n",
            "gradient max : tensor(0.0256)\n",
            "gradient min : tensor(0.0006)\n",
            "gradient l2norm : tensor(4.1086)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([261.5967, 229.3072], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1312, 0.8349], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6742, -0.6172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([202.5990, 184.3178], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1312, 0.8349], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([179.2228, 158.6908], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1312, 0.8349], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([179.2228, 158.6908], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([3.3544, 2.1001], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-3.4361, -2.3131], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([4.8020, 3.1243], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.006583329755812883\n",
            "\n",
            "gradient max : tensor(0.0065)\n",
            "gradient min : tensor(4.0454e-05)\n",
            "gradient l2norm : tensor(1.4525)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([233.3550, 163.1357], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9313, 0.8782], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6856, -0.5537], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([184.6590, 133.7597], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9313, 0.8782], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([157.9805, 110.6708], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9313, 0.8782], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([157.9805, 110.6708], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1810, 1.9010], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.3020, -1.9453], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.1711, 2.7199], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.016184743493795395\n",
            "\n",
            "gradient max : tensor(0.0442)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(2.6986)\n",
            "\n",
            "Average batch loss : 0.014706584718078375\n",
            "\n",
            "========= Epoch27 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([163.1357, 236.9645], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8786, 0.9916], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5537, -0.6420], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([133.7957, 188.7602], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8786, 0.9916], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([110.7153, 165.5605], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8786, 0.9916], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([110.7153, 165.5605], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9689, 1.8628], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.0133, -2.1197], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.8160, 2.8219], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.018469907343387604\n",
            "\n",
            "gradient max : tensor(0.0469)\n",
            "gradient min : tensor(1.0940e-05)\n",
            "gradient l2norm : tensor(3.1692)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([232.2669, 233.3550], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9792, 0.9323], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5668, -0.6856], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([181.0265, 184.7761], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9792, 0.9323], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([157.7547, 158.1180], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9792, 0.9323], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([157.7547, 158.1180], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.7269, 2.3704], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-1.8602, -2.4913], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.5382, 3.4388], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.017505396157503128\n",
            "\n",
            "gradient max : tensor(0.0169)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(2.3250)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([223.8824, 220.2781], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1268, 0.8735], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6102, -0.6491], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([176.2734, 178.3213], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1268, 0.8735], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([152.8092, 151.4093], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1268, 0.8735], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([152.8092, 151.4093], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.8648, 1.9566], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1999, -2.1199], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.8839, 2.8848], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.01692359149456024\n",
            "\n",
            "gradient max : tensor(0.0077)\n",
            "gradient min : tensor(-1.1192e-05)\n",
            "gradient l2norm : tensor(1.0544)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([212.0123, 229.3072], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9219, 0.8364], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6374, -0.6172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([170.1950, 184.5507], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9219, 0.8364], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([143.4335, 158.9634], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9219, 0.8364], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([143.4335, 158.9634], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.3198, 2.0602], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.5799, -2.2735], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.4695, 3.0681], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.01022772490978241\n",
            "\n",
            "gradient max : tensor(0.0052)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(0.9735)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([261.5967, 203.0964], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1321, 1.0652], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6742, -0.6250], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([202.9094, 160.5771], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1321, 1.0652], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([179.5779, 140.6581], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1321, 1.0652], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([179.5779, 140.6581], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([3.3248, 2.1521], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-3.4066, -2.2769], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([4.7602, 3.1330], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.006524329073727131\n",
            "\n",
            "gradient max : tensor(0.0070)\n",
            "gradient min : tensor(1.1991e-06)\n",
            "gradient l2norm : tensor(1.2825)\n",
            "\n",
            "Average batch loss : 0.013930189795792103\n",
            "\n",
            "========= Epoch28 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([236.9645, 233.3550], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9922, 0.9332], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6420, -0.6856], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([188.9861, 184.9278], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9922, 0.9332], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([165.8195, 158.2972], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9922, 0.9332], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([165.8195, 158.2972], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.8465, 2.2554], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1037, -2.3765], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.7991, 3.2764], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.014379145577549934\n",
            "\n",
            "gradient max : tensor(0.0376)\n",
            "gradient min : tensor(0.0031)\n",
            "gradient l2norm : tensor(3.0654)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([223.8824, 220.2781], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1273, 0.8746], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6102, -0.6491], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([176.4229, 178.4675], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1273, 0.8746], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([152.9826, 151.5822], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1273, 0.8746], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([152.9826, 151.5822], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.8396, 1.9983], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1749, -2.1617], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.8486, 2.9438], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.016689542680978775\n",
            "\n",
            "gradient max : tensor(0.0081)\n",
            "gradient min : tensor(-1.1762e-05)\n",
            "gradient l2norm : tensor(1.0724)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([203.0964, 261.5967], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0655, 1.1324], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6250, -0.6742], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([160.6772, 203.0424], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0655, 1.1324], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([140.7739, 179.7303], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0655, 1.1324], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([140.7739, 179.7303], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1229, 3.2797], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2478, -3.3615], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.0918, 4.6964], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.006933813914656639\n",
            "\n",
            "gradient max : tensor(0.0074)\n",
            "gradient min : tensor(1.2668e-06)\n",
            "gradient l2norm : tensor(1.3636)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([212.0123, 229.3072], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9232, 0.8375], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6374, -0.6172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([170.3513, 184.7256], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9232, 0.8375], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([143.6208, 159.1680], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9232, 0.8375], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([143.6208, 159.1680], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.3219, 2.0804], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.5823, -2.2938], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.4726, 3.0967], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.00995387602597475\n",
            "\n",
            "gradient max : tensor(0.0050)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(0.9259)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([163.1357, 232.2669], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8811, 0.9805], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5537, -0.5668], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([134.0403, 181.3383], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8811, 0.9805], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([111.0167, 158.1146], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8811, 0.9805], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([111.0167, 158.1146], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9819, 1.8424], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.0260, -1.9757], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.8342, 2.7015], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.01986982859671116\n",
            "\n",
            "gradient max : tensor(0.0093)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.5556)\n",
            "\n",
            "Average batch loss : 0.013565241359174252\n",
            "\n",
            "========= Epoch29 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([232.2669, 233.3550], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9809, 0.9347], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5668, -0.6856], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([181.3999, 185.1394], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9809, 0.9347], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([158.1855, 158.5465], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9809, 0.9347], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([158.1855, 158.5465], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.8915, 2.2571], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.0249, -2.3783], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.7709, 3.2789], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.014686420559883118\n",
            "\n",
            "gradient max : tensor(0.0082)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.3980)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([220.2781, 261.5967], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8756, 1.1331], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6491, -0.6742], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([178.6660, 203.2246], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8756, 1.1331], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([151.8166, 179.9390], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8756, 1.1331], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([151.8166, 179.9390], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.8862, 3.4315], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.0498, -3.5136], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.7856, 4.9113], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.010150400921702385\n",
            "\n",
            "gradient max : tensor(0.0251)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.9633)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([236.9645, 229.3072], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9930, 0.8385], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6420, -0.6172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([189.2850, 184.8899], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9930, 0.8385], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([166.1622, 159.3602], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9930, 0.8385], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([166.1622, 159.3602], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.8608, 2.1176], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1185, -2.3313], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.8196, 3.1495], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.015075646340847015\n",
            "\n",
            "gradient max : tensor(0.0085)\n",
            "gradient min : tensor(1.0984e-05)\n",
            "gradient l2norm : tensor(1.5887)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([212.0123, 223.8824], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9247, 1.1283], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6374, -0.6102], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([170.5411, 176.7064], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9247, 1.1283], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([143.8483, 153.3108], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9247, 1.1283], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([143.8483, 153.3108], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.3181, 1.9083], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.5788, -2.2441], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.4675, 2.9458], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.01152315828949213\n",
            "\n",
            "gradient max : tensor(0.0076)\n",
            "gradient min : tensor(-1.0275e-05)\n",
            "gradient l2norm : tensor(1.2046)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([203.0964, 163.1357], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0664, 0.8825], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6250, -0.5537], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([160.9195, 134.1845], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0664, 0.8825], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([141.0536, 111.1943], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0664, 0.8825], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([141.0536, 111.1943], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1959, 1.9767], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.3208, -2.0207], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.1950, 2.8267], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.014531530439853668\n",
            "\n",
            "gradient max : tensor(0.0095)\n",
            "gradient min : tensor(2.1725e-06)\n",
            "gradient l2norm : tensor(1.1491)\n",
            "\n",
            "Average batch loss : 0.013193431310355663\n",
            "\n",
            "========= Epoch30 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([203.0964, 229.3072], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0666, 0.8394], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6250, -0.6172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([160.9657, 185.0250], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0666, 0.8394], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([141.1066, 159.5181], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0666, 0.8394], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([141.1066, 159.5181], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.2039, 2.1358], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.3289, -2.3496], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.2064, 3.1752], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.010951263830065727\n",
            "\n",
            "gradient max : tensor(0.0109)\n",
            "gradient min : tensor(1.0743e-06)\n",
            "gradient l2norm : tensor(2.1043)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([232.2669, 233.3550], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9819, 0.9364], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5668, -0.6856], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([181.6514, 185.3848], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9819, 0.9364], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([158.4753, 158.8355], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9819, 0.9364], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([158.4753, 158.8355], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9386, 2.2322], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.0721, -2.3536], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.8375, 3.2438], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.014051791280508041\n",
            "\n",
            "gradient max : tensor(0.0074)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.2009)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([261.5967, 212.0123], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1340, 0.9256], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6742, -0.6374], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([203.5051, 170.6871], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1340, 0.9256], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([180.2600, 144.0231], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1340, 0.9256], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([180.2600, 144.0231], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([3.4828, 2.2234], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-3.5650, -2.4845], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([4.9839, 3.3341], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.004926223773509264\n",
            "\n",
            "gradient max : tensor(0.0115)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(0.8303)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([236.9645, 220.2781], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9937, 0.8773], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6420, -0.6491], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([189.5291, 178.9162], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9937, 0.8773], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([166.4418, 152.1120], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9937, 0.8773], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([166.4418, 152.1120], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.8098, 1.8925], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.0679, -2.0564], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.7480, 2.7948], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.019789040088653564\n",
            "\n",
            "gradient max : tensor(0.0549)\n",
            "gradient min : tensor(0.0020)\n",
            "gradient l2norm : tensor(3.9606)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([163.1357, 223.8824], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8840, 1.1290], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5537, -0.6102], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([134.3203, 176.9422], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8840, 1.1290], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([111.3615, 153.5840], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8840, 1.1290], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([111.3615, 153.5840], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.0317, 1.8819], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.0756, -2.2182], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9045, 2.9090], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.016376078128814697\n",
            "\n",
            "gradient max : tensor(0.0086)\n",
            "gradient min : tensor(-1.0823e-05)\n",
            "gradient l2norm : tensor(1.1669)\n",
            "\n",
            "Average batch loss : 0.013218879420310258\n",
            "\n",
            "========= Epoch31 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([223.8824, 229.3072], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1292, 0.8408], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6102, -0.6172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([176.9961, 185.2308], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1292, 0.8408], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([153.6463, 159.7586], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1292, 0.8408], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([153.6463, 159.7586], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9120, 2.1109], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2483, -2.3249], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9514, 3.1402], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.01362928468734026\n",
            "\n",
            "gradient max : tensor(0.0135)\n",
            "gradient min : tensor(-1.0205e-05)\n",
            "gradient l2norm : tensor(2.7966)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([212.0123, 261.5967], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9269, 1.1345], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6374, -0.6742], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([170.8414, 203.7028], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9269, 1.1345], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([144.2076, 180.4858], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9269, 1.1345], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([144.2076, 180.4858], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.2653, 3.4533], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.5266, -3.5355], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.3934, 4.9422], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.004592197947204113\n",
            "\n",
            "gradient max : tensor(0.0101)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(0.7541)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([203.0964, 236.9645], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0674, 0.9941], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6250, -0.6420], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([161.1998, 189.7097], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0674, 0.9941], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([141.3768, 166.6486], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0674, 0.9941], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([141.3768, 166.6486], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.2364, 1.8666], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.3615, -2.1249], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.2524, 2.8283], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.01416357234120369\n",
            "\n",
            "gradient max : tensor(0.0110)\n",
            "gradient min : tensor(1.2204e-05)\n",
            "gradient l2norm : tensor(1.4004)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([220.2781, 233.3550], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8789, 0.9385], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6491, -0.6856], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([179.1230, 185.6584], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8789, 0.9385], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([152.3559, 159.1575], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8789, 0.9385], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([152.3559, 159.1575], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9585, 2.3054], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1225, -2.4268], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.8880, 3.3473], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.012759219855070114\n",
            "\n",
            "gradient max : tensor(0.0335)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(2.6637)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([232.2669, 163.1357], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9829, 0.8854], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5668, -0.5537], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([181.9681, 134.4527], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9829, 0.8854], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([158.8406, 111.5245], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9829, 0.8854], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([158.8406, 111.5245], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.8002, 2.0612], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-1.9338, -2.1051], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.6420, 2.9461], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.019503392279148102\n",
            "\n",
            "gradient max : tensor(0.0102)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.8261)\n",
            "\n",
            "Average batch loss : 0.012929533421993256\n",
            "\n",
            "========= Epoch32 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([212.0123, 233.3550], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9282, 0.9392], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6374, -0.6856], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([170.9820, 185.7551], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9282, 0.9392], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([144.3757, 159.2713], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9282, 0.9392], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([144.3757, 159.2713], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.3513, 2.3503], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.6127, -2.4718], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.5149, 3.4108], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.007489142939448357\n",
            "\n",
            "gradient max : tensor(0.0192)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.4996)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([261.5967, 229.3072], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1349, 0.8423], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6742, -0.6172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([203.9142, 185.4573], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1349, 0.8423], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([180.7274, 160.0234], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1349, 0.8423], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([180.7274, 160.0234], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([3.3138, 2.0759], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-3.3960, -2.2902], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([4.7449, 3.0911], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.006919024977833033\n",
            "\n",
            "gradient max : tensor(0.0069)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.5386)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([236.9645, 203.0964], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9946, 1.0680], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6420, -0.6250], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([189.9125, 161.3675], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9946, 1.0680], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([166.8808, 141.5703], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9946, 1.0680], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([166.8808, 141.5703], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9434, 2.1917], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2020, -2.3168], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9369, 3.1892], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.013334197923541069\n",
            "\n",
            "gradient max : tensor(0.0067)\n",
            "gradient min : tensor(1.0802e-05)\n",
            "gradient l2norm : tensor(1.0877)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([232.2669, 223.8824], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9836, 1.1302], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5668, -0.6102], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([182.1225, 177.2862], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9836, 1.1302], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([159.0183, 153.9820], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9836, 1.1302], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([159.0183, 153.9820], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.8366, 1.8996], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-1.9702, -2.2365], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.6935, 2.9343], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.018917031586170197\n",
            "\n",
            "gradient max : tensor(0.0243)\n",
            "gradient min : tensor(0.0005)\n",
            "gradient l2norm : tensor(4.0184)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([220.2781, 163.1357], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8803, 0.8865], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6491, -0.5537], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([179.3517, 134.5899], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8803, 0.8865], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([152.6257, 111.6928], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8803, 0.8865], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([152.6257, 111.6928], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9041, 1.9716], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.0684, -2.0155], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.8114, 2.8195], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.018517177551984787\n",
            "\n",
            "gradient max : tensor(0.0518)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(3.2055)\n",
            "\n",
            "Average batch loss : 0.013035314995795489\n",
            "\n",
            "========= Epoch33 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([232.2669, 212.0123], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9841, 0.9296], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5668, -0.6374], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([182.2351, 171.1629], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9841, 0.9296], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([159.1479, 144.5920], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9841, 0.9296], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([159.1479, 144.5920], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.8809, 2.3515], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.0145, -2.6133], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.7561, 3.5155], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.013542331755161285\n",
            "\n",
            "gradient max : tensor(0.0094)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.7772)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([163.1357, 261.5967], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8872, 1.1357], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5537, -0.6742], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([134.6549, 204.1603], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8872, 1.1357], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([111.7727, 181.0090], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8872, 1.1357], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([111.7727, 181.0090], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.0132, 3.4418], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.0569, -3.5242], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.8782, 4.9260], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.008937183767557144\n",
            "\n",
            "gradient max : tensor(0.0215)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.2563)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([236.9645, 203.0964], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9952, 1.0687], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6420, -0.6250], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([190.1485, 161.5652], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9952, 1.0687], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([167.1508, 141.7980], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9952, 1.0687], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([167.1508, 141.7980], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9216, 2.2245], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1806, -2.3497], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9065, 3.2357], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.013331376016139984\n",
            "\n",
            "gradient max : tensor(0.0079)\n",
            "gradient min : tensor(1.1116e-05)\n",
            "gradient l2norm : tensor(1.1909)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([223.8824, 229.3072], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1309, 0.8441], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6102, -0.6172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([177.5064, 185.7460], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1309, 0.8441], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([154.2365, 160.3604], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1309, 0.8441], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([154.2365, 160.3604], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9341, 2.1317], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2714, -2.3464], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9833, 3.1701], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.013047546148300171\n",
            "\n",
            "gradient max : tensor(0.0130)\n",
            "gradient min : tensor(-9.7664e-06)\n",
            "gradient l2norm : tensor(2.6883)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([220.2781, 233.3550], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8817, 0.9416], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6491, -0.6856], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([179.5580, 186.1139], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8817, 0.9416], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([152.8688, 159.6932], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8817, 0.9416], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([152.8688, 159.6932], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9372, 2.2781], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1016, -2.3998], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.8583, 3.3089], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.013359775766730309\n",
            "\n",
            "gradient max : tensor(0.0368)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(2.7976)\n",
            "\n",
            "Average batch loss : 0.012443642690777778\n",
            "\n",
            "========= Epoch34 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([233.3550, 223.8824], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9420, 1.1312], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6856, -0.6102], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([186.1555, 177.5883], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9420, 1.1312], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([159.7422, 154.3312], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9420, 1.1312], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([159.7422, 154.3312], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.3768, 1.9398], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.4984, -2.2772], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.4484, 2.9914], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.011119963601231575\n",
            "\n",
            "gradient max : tensor(0.0076)\n",
            "gradient min : tensor(-9.6600e-06)\n",
            "gradient l2norm : tensor(0.9893)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([236.9645, 163.1357], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9957, 0.8885], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6420, -0.5537], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([190.3179, 134.7846], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9957, 0.8885], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([167.3447, 111.9320], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9957, 0.8885], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([167.3447, 111.9320], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9335, 2.0539], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1928, -2.0976], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9235, 2.9357], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.01581633649766445\n",
            "\n",
            "gradient max : tensor(0.0414)\n",
            "gradient min : tensor(9.5240e-06)\n",
            "gradient l2norm : tensor(2.7558)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([203.0964, 261.5967], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0693, 1.1364], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6250, -0.6742], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([161.7505, 204.4452], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0693, 1.1364], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([142.0117, 181.3338], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0693, 1.1364], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([142.0117, 181.3338], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1533, 3.3289], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2787, -3.4113], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.1351, 4.7664], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.006501124240458012\n",
            "\n",
            "gradient max : tensor(0.0070)\n",
            "gradient min : tensor(2.3621e-06)\n",
            "gradient l2norm : tensor(1.2904)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([212.0123, 232.2669], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9317, 0.9854], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6374, -0.5668], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([171.4367, 182.5491], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9317, 0.9854], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([144.9190, 159.5092], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9317, 0.9854], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([144.9190, 159.5092], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.3884, 1.8545], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.6506, -1.9882], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.5679, 2.7188], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.013834911398589611\n",
            "\n",
            "gradient max : tensor(0.0100)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.9251)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([220.2781, 229.3072], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8830, 0.8455], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6491, -0.6172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([179.7389, 185.9760], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8830, 0.8455], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([153.0819, 160.6290], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8830, 0.8455], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([153.0819, 160.6290], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.0084, 2.1665], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1730, -2.3815], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9590, 3.2195], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.012847183272242546\n",
            "\n",
            "gradient max : tensor(0.0066)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.0018)\n",
            "\n",
            "Average batch loss : 0.01202390380203724\n",
            "\n",
            "========= Epoch35 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([163.1357, 203.0964], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8896, 1.0697], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5537, -0.6250], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([134.8895, 161.8425], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8896, 1.0697], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([112.0607, 142.1177], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8896, 1.0697], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([112.0607, 142.1177], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.0701, 2.2335], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1138, -2.3589], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9586, 3.2485], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.012601330876350403\n",
            "\n",
            "gradient max : tensor(0.0065)\n",
            "gradient min : tensor(2.0156e-06)\n",
            "gradient l2norm : tensor(0.9891)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([233.3550, 236.9645], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9436, 0.9963], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6856, -0.6420], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([186.3924, 190.5310], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9436, 0.9963], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([160.0203, 167.5882], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9436, 0.9963], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([160.0203, 167.5882], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.3814, 1.9438], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.5033, -2.2034], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.4551, 2.9382], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.011608963832259178\n",
            "\n",
            "gradient max : tensor(0.0301)\n",
            "gradient min : tensor(0.0022)\n",
            "gradient l2norm : tensor(2.5106)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([223.8824, 212.0123], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1321, 0.9329], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6102, -0.6374], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([177.8576, 171.5819], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1321, 0.9329], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([154.6424, 145.0924], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1321, 0.9329], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([154.6424, 145.0924], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.8815, 2.4303], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2193, -2.6927], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9096, 3.6273], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.011181605979800224\n",
            "\n",
            "gradient max : tensor(0.0083)\n",
            "gradient min : tensor(-1.0833e-05)\n",
            "gradient l2norm : tensor(1.3737)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([261.5967, 232.2669], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1372, 0.9861], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6742, -0.5668], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([204.6972, 182.7504], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1372, 0.9861], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([181.6217, 159.7409], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1372, 0.9861], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([181.6217, 159.7409], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([3.3777, 1.8626], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-3.4602, -1.9964], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([4.8354, 2.7304], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.01097051426768303\n",
            "\n",
            "gradient max : tensor(0.0202)\n",
            "gradient min : tensor(0.0004)\n",
            "gradient l2norm : tensor(2.4445)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([220.2781, 229.3072], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8842, 0.8466], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6491, -0.6172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([179.9185, 186.1629], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8842, 0.8466], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([153.2934, 160.8470], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8842, 0.8466], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([153.2934, 160.8470], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.0014, 2.1924], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1662, -2.4076], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9492, 3.2562], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.01268660370260477\n",
            "\n",
            "gradient max : tensor(0.0068)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.0271)\n",
            "\n",
            "Average batch loss : 0.01180980373173952\n",
            "\n",
            "========= Epoch36 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([232.2669, 236.9645], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9865, 0.9966], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5668, -0.6420], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([182.8226, 190.6806], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9865, 0.9966], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([159.8240, 167.7595], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9865, 0.9966], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([159.8240, 167.7595], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9340, 1.9446], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.0677, -2.2044], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.8312, 2.9395], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.016888203099370003\n",
            "\n",
            "gradient max : tensor(0.0079)\n",
            "gradient min : tensor(9.3162e-06)\n",
            "gradient l2norm : tensor(1.4219)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([163.1357, 223.8824], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8912, 1.1326], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5537, -0.6102], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([135.0468, 178.0072], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8912, 1.1326], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([112.2537, 154.8153], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8912, 1.1326], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([112.2537, 154.8153], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.0564, 2.0034], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.0999, -2.3415], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9390, 3.0816], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.014217395335435867\n",
            "\n",
            "gradient max : tensor(0.0066)\n",
            "gradient min : tensor(3.8201e-05)\n",
            "gradient l2norm : tensor(0.9383)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([229.3072, 233.3550], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8475, 0.9453], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6172, -0.6856], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([186.3003, 186.6297], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8475, 0.9453], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([161.0072, 160.2993], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8475, 0.9453], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([161.0072, 160.2993], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.2088, 2.3422], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.4242, -2.4642], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.2796, 3.3997], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.008911127224564552\n",
            "\n",
            "gradient max : tensor(0.0038)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(0.7426)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([203.0964, 220.2781], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0707, 0.8852], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6250, -0.6491], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([162.1204, 180.0809], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0707, 0.8852], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([142.4375, 153.4846], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0707, 0.8852], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([142.4375, 153.4846], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.2654, 1.9979], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.3910, -2.1628], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.2938, 2.9443], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.012466425076127052\n",
            "\n",
            "gradient max : tensor(0.0080)\n",
            "gradient min : tensor(1.8917e-06)\n",
            "gradient l2norm : tensor(1.3357)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([212.0123, 261.5967], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9347, 1.1381], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6374, -0.6742], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([171.8229, 204.9699], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9347, 1.1381], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([145.3804, 181.9333], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9347, 1.1381], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([145.3804, 181.9333], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.3530, 3.4596], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.6158, -3.5423], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.5184, 4.9514], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.003918515983968973\n",
            "\n",
            "gradient max : tensor(0.0080)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(0.6259)\n",
            "\n",
            "Average batch loss : 0.011280333343893289\n",
            "\n",
            "========= Epoch37 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([233.3550, 223.8824], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9460, 1.1331], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6856, -0.6102], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([186.7166, 178.1407], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9460, 1.1331], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([160.4013, 154.9695], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9460, 1.1331], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([160.4013, 154.9695], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.3926, 1.9824], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.5145, -2.3207], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.4709, 3.0521], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.010401382111012936\n",
            "\n",
            "gradient max : tensor(0.0069)\n",
            "gradient min : tensor(-8.8823e-06)\n",
            "gradient l2norm : tensor(0.8926)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([220.2781, 163.1357], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8858, 0.8923], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6491, -0.5537], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([180.1650, 135.1603], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8858, 0.8923], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([153.5836, 112.3929], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8858, 0.8923], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([153.5836, 112.3929], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.0362, 2.0792], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2012, -2.1227], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9985, 2.9713], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.01459936797618866\n",
            "\n",
            "gradient max : tensor(0.0391)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(2.5371)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([232.2669, 212.0123], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9875, 0.9355], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5668, -0.6374], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([183.0941, 171.9113], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9875, 0.9355], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([160.1362, 145.4857], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9875, 0.9355], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([160.1362, 145.4857], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.8667, 2.4200], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.0006, -2.6830], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.7362, 3.6132], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.013379402458667755\n",
            "\n",
            "gradient max : tensor(0.0103)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.9010)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([261.5967, 203.0964], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1385, 1.0712], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6742, -0.6250], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([205.1244, 162.2731], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1385, 1.0712], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([182.1096, 142.6135], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1385, 1.0712], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([182.1096, 142.6135], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([3.4469, 2.2570], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-3.5297, -2.3826], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([4.9336, 3.2819], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.005274077411741018\n",
            "\n",
            "gradient max : tensor(0.0057)\n",
            "gradient min : tensor(9.4936e-07)\n",
            "gradient l2norm : tensor(1.0524)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([229.3072, 236.9645], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8489, 0.9976], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6172, -0.6420], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([186.5242, 191.0199], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8489, 0.9976], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([161.2683, 168.1473], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8489, 0.9976], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([161.2683, 168.1473], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.2006, 1.9271], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.4163, -2.1875], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.2682, 2.9153], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.013018017634749413\n",
            "\n",
            "gradient max : tensor(0.0082)\n",
            "gradient min : tensor(9.6458e-06)\n",
            "gradient l2norm : tensor(1.4115)\n",
            "\n",
            "Average batch loss : 0.011334449518471956\n",
            "\n",
            "========= Epoch38 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([212.0123, 163.1357], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9361, 0.8933], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6374, -0.5537], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([171.9976, 135.2598], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9361, 0.8933], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([145.5888, 112.5148], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9361, 0.8933], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([145.5888, 112.5148], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.3771, 2.0982], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.6402, -2.1416], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.5526, 2.9982], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.010453538969159126\n",
            "\n",
            "gradient max : tensor(0.0277)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.5967)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([261.5967, 223.8824], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1388, 1.1338], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6742, -0.6102], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([205.2404, 178.3578], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1388, 1.1338], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([182.2415, 155.2200], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1388, 1.1338], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([182.2415, 155.2200], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([3.4081, 1.9466], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-3.4908, -2.2852], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([4.8786, 3.0019], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.00771505618467927\n",
            "\n",
            "gradient max : tensor(0.0084)\n",
            "gradient min : tensor(0.0001)\n",
            "gradient l2norm : tensor(1.6816)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([203.0964, 233.3550], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0716, 0.9477], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6250, -0.6856], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([162.3826, 186.9614], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0716, 0.9477], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([142.7392, 160.6885], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0716, 0.9477], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([142.7392, 160.6885], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.2667, 2.3951], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.3923, -2.5172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.2956, 3.4746], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.008379754610359669\n",
            "\n",
            "gradient max : tensor(0.0043)\n",
            "gradient min : tensor(9.2934e-07)\n",
            "gradient l2norm : tensor(0.7336)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([229.3072, 232.2669], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8498, 0.9884], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6172, -0.5668], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([186.6582, 183.2887], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8498, 0.9884], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([161.4244, 160.3597], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8498, 0.9884], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([161.4244, 160.3597], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.2004, 1.9470], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.4162, -2.0809], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.2680, 2.8497], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.013747002929449081\n",
            "\n",
            "gradient max : tensor(0.0136)\n",
            "gradient min : tensor(0.0012)\n",
            "gradient l2norm : tensor(2.8762)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([236.9645, 220.2781], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9981, 0.8875], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6420, -0.6491], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([191.2052, 180.4331], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9981, 0.8875], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([168.3589, 153.8991], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9981, 0.8875], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([168.3589, 153.8991], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.8725, 1.9715], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1332, -2.1368], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.8384, 2.9073], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.017175298184156418\n",
            "\n",
            "gradient max : tensor(0.0492)\n",
            "gradient min : tensor(0.0019)\n",
            "gradient l2norm : tensor(3.4862)\n",
            "\n",
            "Average batch loss : 0.011494130175560714\n",
            "\n",
            "========= Epoch39 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([203.0964, 236.9645], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0719, 0.9981], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6250, -0.6420], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([162.4878, 191.2585], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0719, 0.9981], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([142.8604, 168.4197], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0719, 0.9981], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([142.8604, 168.4197], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.2580, 2.0004], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.3837, -2.2612], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.2834, 3.0190], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.011798114515841007\n",
            "\n",
            "gradient max : tensor(0.0061)\n",
            "gradient min : tensor(9.6169e-06)\n",
            "gradient l2norm : tensor(0.9861)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([212.0123, 220.2781], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9377, 0.8883], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6374, -0.6491], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([172.1955, 180.5190], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9377, 0.8883], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([145.8247, 154.0001], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9377, 0.8883], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([145.8247, 154.0001], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.4192, 2.0990], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.6826, -2.2643], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.6123, 3.0875], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.00936189852654934\n",
            "\n",
            "gradient max : tensor(0.0242)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.8843)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([229.3072, 163.1357], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8510, 0.8952], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6172, -0.5537], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([186.8202, 135.4276], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8510, 0.8952], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([161.6131, 112.7207], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8510, 0.8952], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([161.6131, 112.7207], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1101, 2.1629], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.3261, -2.2062], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.1406, 3.0896], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.01217697188258171\n",
            "\n",
            "gradient max : tensor(0.0056)\n",
            "gradient min : tensor(0.0004)\n",
            "gradient l2norm : tensor(1.1731)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([233.3550, 232.2669], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9495, 0.9891], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6856, -0.5668], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([187.1984, 183.4990], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9495, 0.9891], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([160.9663, 160.6013], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9495, 0.9891], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([160.9663, 160.6013], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.4940, 1.8649], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.6162, -1.9988], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.6145, 2.7337], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.013394387438893318\n",
            "\n",
            "gradient max : tensor(0.0131)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.7947)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([261.5967, 223.8824], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1398, 1.1347], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6742, -0.6102], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([205.5796, 178.6490], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1398, 1.1347], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([182.6286, 155.5561], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1398, 1.1347], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([182.6286, 155.5561], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([3.4442, 1.9750], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-3.5271, -2.3142], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([4.9298, 3.0424], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.007280607707798481\n",
            "\n",
            "gradient max : tensor(0.0079)\n",
            "gradient min : tensor(0.0001)\n",
            "gradient l2norm : tensor(1.5909)\n",
            "\n",
            "Average batch loss : 0.010802396014332772\n",
            "\n",
            "========= Epoch40 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([232.2669, 261.5967], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9894, 1.1399], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5668, -0.6742], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([183.5599, 205.6055], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9894, 1.1399], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([160.6712, 182.6583], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9894, 1.1399], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([160.6712, 182.6583], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9848, 3.5036], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1187, -3.5865], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9031, 5.0138], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.008606820367276669\n",
            "\n",
            "gradient max : tensor(0.0146)\n",
            "gradient min : tensor(0.0002)\n",
            "gradient l2norm : tensor(1.9332)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([229.3072, 223.8824], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8516, 1.1350], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6172, -0.6102], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([186.9459, 178.6958], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8516, 1.1350], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([161.7596, 155.6099], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8516, 1.1350], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([161.7596, 155.6099], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.2836, 2.0959], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.4997, -2.4352], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.3858, 3.2129], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.009522730484604836\n",
            "\n",
            "gradient max : tensor(0.0095)\n",
            "gradient min : tensor(-7.0967e-06)\n",
            "gradient l2norm : tensor(1.9831)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([212.0123, 236.9645], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9388, 0.9989], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6374, -0.6420], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([172.3649, 191.5032], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9388, 0.9989], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([146.0269, 168.6992], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9388, 0.9989], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([146.0269, 168.6992], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.2681, 1.8588], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.5319, -2.1200], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.3993, 2.8196], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.013364661484956741\n",
            "\n",
            "gradient max : tensor(0.0400)\n",
            "gradient min : tensor(0.0085)\n",
            "gradient l2norm : tensor(2.8776)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([203.0964, 233.3550], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0728, 0.9505], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6250, -0.6856], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([162.7269, 187.3533], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0728, 0.9505], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([143.1354, 161.1484], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0728, 0.9505], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([143.1354, 161.1484], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.3097, 2.3517], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.4355, -2.4740], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.3565, 3.4134], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.00832226499915123\n",
            "\n",
            "gradient max : tensor(0.0039)\n",
            "gradient min : tensor(8.5303e-07)\n",
            "gradient l2norm : tensor(0.7270)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([163.1357, 220.2781], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8965, 0.8899], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5537, -0.6491], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([135.5849, 180.7690], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8965, 0.8899], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([112.9130, 154.2940], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8965, 0.8899], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([112.9130, 154.2940], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.0781, 2.0189], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1213, -2.1845], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9695, 2.9746], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.014864286407828331\n",
            "\n",
            "gradient max : tensor(0.0416)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(2.6019)\n",
            "\n",
            "Average batch loss : 0.010936152748763561\n",
            "\n",
            "========= Epoch41 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([220.2781, 236.9645], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8903, 0.9991], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6491, -0.6420], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([180.8178, 191.6291], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8903, 0.9991], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([154.3513, 168.8429], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8903, 0.9991], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([154.3513, 168.8429], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1099, 2.0339], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2754, -2.2952], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.1031, 3.0667], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.012737402692437172\n",
            "\n",
            "gradient max : tensor(0.0333)\n",
            "gradient min : tensor(7.8093e-06)\n",
            "gradient l2norm : tensor(2.5950)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([229.3072, 163.1357], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8531, 0.8974], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6172, -0.5537], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([187.1407, 135.6434], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8531, 0.8974], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([161.9864, 112.9849], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8531, 0.8974], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([161.9864, 112.9849], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1158, 2.1921], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.3321, -2.2352], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.1489, 3.1307], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.01175558939576149\n",
            "\n",
            "gradient max : tensor(0.0053)\n",
            "gradient min : tensor(9.7398e-05)\n",
            "gradient l2norm : tensor(1.1521)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([223.8824, 233.3550], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1356, 0.9518], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6102, -0.6856], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([178.9287, 187.5195], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1356, 0.9518], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([155.8787, 161.3427], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1356, 0.9518], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([155.8787, 161.3427], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9233, 2.5243], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2629, -2.6466], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9698, 3.6575], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.010376767255365849\n",
            "\n",
            "gradient max : tensor(0.0080)\n",
            "gradient min : tensor(-9.9736e-06)\n",
            "gradient l2norm : tensor(1.1671)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([212.0123, 261.5967], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9408, 1.1408], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6374, -0.6742], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([172.5786, 205.9433], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9408, 1.1408], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([146.2811, 183.0430], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9408, 1.1408], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([146.2811, 183.0430], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.4536, 3.4299], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.7177, -3.5129], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.6614, 4.9097], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.0033132079988718033\n",
            "\n",
            "gradient max : tensor(0.0059)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(0.4963)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([232.2669, 203.0964], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9905, 1.0733], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5668, -0.6250], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([183.8723, 162.9087], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9905, 1.0733], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([161.0300, 143.3443], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9905, 1.0733], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([161.0300, 143.3443], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.8913, 2.2183], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.0253, -2.3441], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.7710, 3.2273], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.01504870131611824\n",
            "\n",
            "gradient max : tensor(0.0193)\n",
            "gradient min : tensor(0.0003)\n",
            "gradient l2norm : tensor(3.0649)\n",
            "\n",
            "Average batch loss : 0.010646333731710911\n",
            "\n",
            "========= Epoch42 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([203.0964, 229.3072], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0736, 0.8537], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6250, -0.6172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([162.9479, 187.2695], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0736, 0.8537], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([143.3893, 162.1364], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0736, 0.8537], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([143.3893, 162.1364], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.3086, 2.2490], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.4345, -2.4655], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.3551, 3.3372], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.008798690512776375\n",
            "\n",
            "gradient max : tensor(0.0088)\n",
            "gradient min : tensor(8.5083e-07)\n",
            "gradient l2norm : tensor(1.7191)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([223.8824, 233.3550], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1362, 0.9524], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6102, -0.6856], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([179.0472, 187.6366], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1362, 0.9524], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([156.0151, 161.4803], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1362, 0.9524], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([156.0151, 161.4803], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1025, 2.3616], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.4424, -2.4840], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.2226, 3.4275], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.009199090301990509\n",
            "\n",
            "gradient max : tensor(0.0053)\n",
            "gradient min : tensor(-7.0058e-06)\n",
            "gradient l2norm : tensor(0.6410)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([261.5967, 212.0123], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1414, 0.9413], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6742, -0.6374], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([206.0764, 172.6804], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1414, 0.9413], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([183.1951, 146.4026], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1414, 0.9413], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([183.1951, 146.4026], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([3.5990, 2.3345], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-3.6822, -2.5988], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([5.1489, 3.4934], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.003932443913072348\n",
            "\n",
            "gradient max : tensor(0.0094)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(0.6754)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([236.9645, 232.2669], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9998, 0.9912], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6420, -0.5668], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([191.8912, 183.9943], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9998, 0.9912], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([169.1421, 161.1700], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9998, 0.9912], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([169.1421, 161.1700], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9506, 2.0480], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2124, -2.1821], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9495, 2.9927], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.014942793175578117\n",
            "\n",
            "gradient max : tensor(0.0068)\n",
            "gradient min : tensor(9.2072e-06)\n",
            "gradient l2norm : tensor(1.2761)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([220.2781, 163.1357], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8921, 0.8988], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6491, -0.5537], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([181.0959, 135.8150], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8921, 0.8988], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([154.6781, 113.1944], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8921, 0.8988], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([154.6781, 113.1944], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.0294, 2.0926], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1952, -2.1357], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9896, 2.9900], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.014498302713036537\n",
            "\n",
            "gradient max : tensor(0.0411)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(2.5464)\n",
            "\n",
            "Average batch loss : 0.010274264123290777\n",
            "\n",
            "========= Epoch43 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([236.9645, 233.3550], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0000, 0.9535], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6420, -0.6856], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([191.9891, 187.7748], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0000, 0.9535], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([169.2536, 161.6421], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0000, 0.9535], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([169.2536, 161.6421], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.0409, 2.4579], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.3028, -2.5803], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.0770, 3.5636], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.009685084223747253\n",
            "\n",
            "gradient max : tensor(0.0258)\n",
            "gradient min : tensor(0.0016)\n",
            "gradient l2norm : tensor(2.1148)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([212.0123, 261.5967], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9426, 1.1416], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6374, -0.6742], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([172.8061, 206.2369], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9426, 1.1416], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([146.5520, 183.3776], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9426, 1.1416], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([146.5520, 183.3776], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.4867, 3.4257], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.7511, -3.5088], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.7084, 4.9038], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.00313533004373312\n",
            "\n",
            "gradient max : tensor(0.0054)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(0.4596)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([163.1357, 229.3072], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8997, 0.8553], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5537, -0.6172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([135.8752, 187.4832], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8997, 0.8553], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([113.2685, 162.3850], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8997, 0.8553], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([113.2685, 162.3850], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1992, 2.1512], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2422, -2.3680], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.1407, 3.1992], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.011274520307779312\n",
            "\n",
            "gradient max : tensor(0.0052)\n",
            "gradient min : tensor(0.0004)\n",
            "gradient l2norm : tensor(1.0884)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([232.2669, 220.2781], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9918, 0.8931], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5668, -0.6491], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([184.1768, 181.2273], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9918, 0.8931], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([161.3794, 154.8323], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9918, 0.8931], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([161.3794, 154.8323], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9033, 2.1772], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.0374, -2.3431], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.7881, 3.1985], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.015038155019283295\n",
            "\n",
            "gradient max : tensor(0.0088)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.3775)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([223.8824, 203.0964], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1369, 1.0744], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6102, -0.6250], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([179.3080, 163.2084], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1369, 1.0744], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([156.3158, 143.6887], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1369, 1.0744], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([156.3158, 143.6887], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9887, 2.2573], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.3289, -2.3833], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.0625, 3.2826], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.0114245330914855\n",
            "\n",
            "gradient max : tensor(0.0125)\n",
            "gradient min : tensor(5.8882e-05)\n",
            "gradient l2norm : tensor(2.2546)\n",
            "\n",
            "Average batch loss : 0.010111524537205697\n",
            "\n",
            "========= Epoch44 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([236.9645, 261.5967], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0005, 1.1422], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6420, -0.6742], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([192.1635, 206.3893], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0005, 1.1422], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([169.4526, 183.5513], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0005, 1.1422], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([169.4526, 183.5513], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.0128, 3.5498], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2750, -3.6330], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.0376, 5.0794], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.00720027182251215\n",
            "\n",
            "gradient max : tensor(0.0177)\n",
            "gradient min : tensor(0.0024)\n",
            "gradient l2norm : tensor(1.5541)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([220.2781, 212.0123], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8937, 0.9436], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6491, -0.6374], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([181.3240, 172.9448], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8937, 0.9436], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([154.9459, 146.7171], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8937, 0.9436], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([154.9459, 146.7171], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1240, 2.4412], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2899, -2.7058], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.1233, 3.6443], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.008917432278394699\n",
            "\n",
            "gradient max : tensor(0.0237)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.8061)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([163.1357, 233.3550], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9008, 0.9552], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5537, -0.6856], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([135.9926, 187.9944], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9008, 0.9552], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([113.4118, 161.8992], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9008, 0.9552], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([113.4118, 161.8992], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1989, 2.5287], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2418, -2.6512], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.1401, 3.6637], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.00866641104221344\n",
            "\n",
            "gradient max : tensor(0.0219)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.4757)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([229.3072, 223.8824], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8566, 1.1372], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6172, -0.6102], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([187.6900, 179.4288], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8566, 1.1372], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([162.6255, 156.4551], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8566, 1.1372], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([162.6255, 156.4551], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1359, 1.9246], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.3529, -2.2650], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.1778, 2.9723], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.013104637153446674\n",
            "\n",
            "gradient max : tensor(0.0130)\n",
            "gradient min : tensor(-9.9478e-06)\n",
            "gradient l2norm : tensor(2.7385)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([232.2669, 203.0964], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9926, 1.0750], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5668, -0.6250], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([184.3879, 163.3530], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9926, 1.0750], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([161.6216, 143.8545], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9926, 1.0750], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([161.6216, 143.8545], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9649, 2.2779], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.0991, -2.4040], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.8753, 3.3119], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.013126048259437084\n",
            "\n",
            "gradient max : tensor(0.0155)\n",
            "gradient min : tensor(0.0003)\n",
            "gradient l2norm : tensor(2.6825)\n",
            "\n",
            "Average batch loss : 0.01020296011120081\n",
            "\n",
            "========= Epoch45 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([232.2669, 229.3072], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9929, 0.8568], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5668, -0.6172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([184.4274, 187.7673], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9929, 0.8568], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([161.6668, 162.7154], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9929, 0.8568], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([161.6668, 162.7154], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.0648, 2.3081], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1989, -2.5253], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.0164, 3.4212], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.010950149968266487\n",
            "\n",
            "gradient max : tensor(0.0109)\n",
            "gradient min : tensor(0.0010)\n",
            "gradient l2norm : tensor(2.3124)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([236.9645, 233.3550], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0012, 0.9559], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6420, -0.6856], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([192.3756, 188.1396], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0012, 0.9559], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([169.6945, 162.0695], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0012, 0.9559], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([169.6945, 162.0695], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9215, 2.3297], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1841, -2.4524], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9090, 3.3825], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.012344684451818466\n",
            "\n",
            "gradient max : tensor(0.0370)\n",
            "gradient min : tensor(0.0041)\n",
            "gradient l2norm : tensor(2.6969)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([220.2781, 223.8824], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8950, 1.1378], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6491, -0.6102], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([181.5292, 179.5790], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8950, 1.1378], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([155.1868, 156.6279], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8950, 1.1378], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([155.1868, 156.6279], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.0684, 2.1012], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2346, -2.4420], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.0449, 3.2215], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.012010324746370316\n",
            "\n",
            "gradient max : tensor(0.0055)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(0.8177)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([212.0123, 261.5967], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9453, 1.1431], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6374, -0.6742], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([173.1692, 206.7061], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9453, 1.1431], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([146.9843, 183.9123], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9453, 1.1431], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([146.9843, 183.9123], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.3994, 3.5816], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.6645, -3.6650], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.5856, 5.1245], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.003506482345983386\n",
            "\n",
            "gradient max : tensor(0.0078)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(0.5859)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([203.0964, 163.1357], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0755, 0.9023], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6250, -0.5537], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([163.4953, 136.1529], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0755, 0.9023], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([144.0181, 113.6074], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0755, 0.9023], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([144.0181, 113.6074], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.3266, 2.1482], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.4528, -2.1910], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.3808, 3.0684], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.010664388537406921\n",
            "\n",
            "gradient max : tensor(0.0063)\n",
            "gradient min : tensor(1.6741e-06)\n",
            "gradient l2norm : tensor(0.8528)\n",
            "\n",
            "Average batch loss : 0.009895206009969116\n",
            "\n",
            "========= Epoch46 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([203.0964, 220.2781], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0756, 0.8956], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6250, -0.6491], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([163.5311, 181.6163], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0756, 0.8956], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([144.0590, 155.2889], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0756, 0.8956], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([144.0590, 155.2889], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.3348, 2.1126], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.4610, -2.2789], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.3923, 3.1075], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.01026846468448639\n",
            "\n",
            "gradient max : tensor(0.0055)\n",
            "gradient min : tensor(1.6472e-06)\n",
            "gradient l2norm : tensor(1.0754)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([233.3550, 229.3072], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9573, 0.8582], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6856, -0.6172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([188.3042, 187.9643], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9573, 0.8582], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([162.2618, 162.9444], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9573, 0.8582], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([162.2618, 162.9444], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.4752, 2.2619], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.5979, -2.4793], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.5882, 3.3560], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.007467236369848251\n",
            "\n",
            "gradient max : tensor(0.0031)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(0.6686)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([232.2669, 261.5967], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9938, 1.1435], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5668, -0.6742], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([184.6570, 206.8382], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9938, 1.1435], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([161.9300, 184.0623], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9938, 1.1435], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([161.9300, 184.0623], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.0197, 3.5537], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1540, -3.6371], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9528, 5.0850], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.008015725761651993\n",
            "\n",
            "gradient max : tensor(0.0143)\n",
            "gradient min : tensor(0.0002)\n",
            "gradient l2norm : tensor(1.8157)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([236.9645, 212.0123], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0017, 0.9462], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6420, -0.6374], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([192.6002, 173.2907], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0017, 0.9462], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([169.9504, 147.1287], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0017, 0.9462], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([169.9504, 147.1287], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9837, 2.3801], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2466, -2.6454], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9970, 3.5585], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.010494985617697239\n",
            "\n",
            "gradient max : tensor(0.0301)\n",
            "gradient min : tensor(0.0058)\n",
            "gradient l2norm : tensor(2.2776)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([223.8824, 163.1357], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1385, 0.9034], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6102, -0.5537], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([179.7841, 136.2588], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1385, 0.9034], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([156.8642, 113.7368], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1385, 0.9034], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([156.8642, 113.7368], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.0577, 2.1750], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.3988, -2.2177], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.1605, 3.1062], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.01191350445151329\n",
            "\n",
            "gradient max : tensor(0.0060)\n",
            "gradient min : tensor(5.6075e-05)\n",
            "gradient l2norm : tensor(0.8377)\n",
            "\n",
            "Average batch loss : 0.009631983377039433\n",
            "\n",
            "========= Epoch47 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([163.1357, 212.0123], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9036, 0.9468], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5537, -0.6374], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([136.2877, 173.3591], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9036, 0.9468], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([113.7719, 147.2098], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9036, 0.9468], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([113.7719, 147.2098], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1763, 2.4345], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2191, -2.6998], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.1082, 3.6353], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.00906599685549736\n",
            "\n",
            "gradient max : tensor(0.0249)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.4027)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([261.5967, 232.2669], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1439, 0.9943], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6742, -0.5668], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([206.9909, 184.7921], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1439, 0.9943], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([184.2356, 162.0849], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1439, 0.9943], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([184.2356, 162.0849], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([3.5188, 1.9880], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-3.6023, -2.1223], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([5.0357, 2.9080], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.008538074791431427\n",
            "\n",
            "gradient max : tensor(0.0159)\n",
            "gradient min : tensor(0.0003)\n",
            "gradient l2norm : tensor(1.9349)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([236.9645, 229.3072], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0020, 0.8593], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6420, -0.6172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([192.7409, 188.1462], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0020, 0.8593], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([170.1106, 163.1557], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0020, 0.8593], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([170.1106, 163.1557], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.0414, 2.2966], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.3045, -2.5141], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.0787, 3.4052], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.010492684319615364\n",
            "\n",
            "gradient max : tensor(0.0063)\n",
            "gradient min : tensor(7.6931e-06)\n",
            "gradient l2norm : tensor(1.1326)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([203.0964, 233.3550], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0764, 0.9588], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6250, -0.6856], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([163.7535, 188.5235], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0764, 0.9588], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([144.3141, 162.5183], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0764, 0.9588], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([144.3141, 162.5183], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.3260, 2.4680], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.4523, -2.5907], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.3800, 3.5781], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.0073539866134524345\n",
            "\n",
            "gradient max : tensor(0.0039)\n",
            "gradient min : tensor(8.1622e-07)\n",
            "gradient l2norm : tensor(0.6534)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([220.2781, 223.8824], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8974, 1.1390], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6491, -0.6102], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([181.8832, 179.9438], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8974, 1.1390], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([155.6019, 157.0479], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8974, 1.1390], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([155.6019, 157.0479], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1251, 2.0803], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2916, -2.4217], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.1253, 3.1925], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.011513866484165192\n",
            "\n",
            "gradient max : tensor(0.0051)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(0.7423)\n",
            "\n",
            "Average batch loss : 0.009392921812832355\n",
            "\n",
            "========= Epoch48 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([223.8824, 229.3072], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1392, 0.8600], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6102, -0.6172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([179.9798, 188.2445], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1392, 0.8600], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([157.0893, 163.2699], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1392, 0.8600], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([157.0893, 163.2699], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.0855, 2.2889], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.4269, -2.5066], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.1999, 3.3944], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.009572369046509266\n",
            "\n",
            "gradient max : tensor(0.0095)\n",
            "gradient min : tensor(-7.2419e-06)\n",
            "gradient l2norm : tensor(2.0121)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([163.1357, 220.2781], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9048, 0.8978], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5537, -0.6491], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([136.4162, 181.9498], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9048, 0.8978], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([113.9284, 155.6799], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9048, 0.8978], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([113.9284, 155.6799], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1476, 2.0728], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1903, -2.2394], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.0675, 3.0515], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.013146612793207169\n",
            "\n",
            "gradient max : tensor(0.0380)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(2.3301)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([203.0964, 212.0123], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0769, 0.9484], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6250, -0.6374], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([163.8779, 173.5685], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0769, 0.9484], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([144.4566, 147.4585], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0769, 0.9484], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([144.4566, 147.4585], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.3427, 2.4412], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.4690, -2.7069], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.4035, 3.6451], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.006947453133761883\n",
            "\n",
            "gradient max : tensor(0.0038)\n",
            "gradient min : tensor(7.8514e-07)\n",
            "gradient l2norm : tensor(0.6171)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([236.9645, 261.5967], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0026, 1.1447], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6420, -0.6742], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([192.9539, 207.2491], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0026, 1.1447], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([170.3532, 184.5293], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0026, 1.1447], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([170.3532, 184.5293], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.0535, 3.5802], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.3169, -3.6637], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.0959, 5.1225], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.006640711799263954\n",
            "\n",
            "gradient max : tensor(0.0163)\n",
            "gradient min : tensor(0.0021)\n",
            "gradient l2norm : tensor(1.4387)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([232.2669, 233.3550], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9952, 0.9602], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5668, -0.6856], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([185.0444, 188.7124], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9952, 0.9602], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([162.3738, 162.7391], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9952, 0.9602], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([162.3738, 162.7391], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([1.9991, 2.5241], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.1335, -2.6470], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([2.9238, 3.6575], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.010787812992930412\n",
            "\n",
            "gradient max : tensor(0.0083)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.3097)\n",
            "\n",
            "Average batch loss : 0.009418991953134536\n",
            "\n",
            "========= Epoch49 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([203.0964, 232.2669], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0771, 0.9954], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6250, -0.5668], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([163.9462, 185.0763], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0771, 0.9954], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([144.5351, 162.4105], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0771, 0.9954], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([144.5351, 162.4105], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.3469, 2.0480], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.4733, -2.1823], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.4095, 2.9928], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.011238477192819118\n",
            "\n",
            "gradient max : tensor(0.0124)\n",
            "gradient min : tensor(0.0002)\n",
            "gradient l2norm : tensor(2.3073)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([220.2781, 229.3072], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.8988, 0.8610], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6491, -0.6172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([182.0997, 188.4329], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.8988, 0.8610], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([155.8557, 163.4888], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.8988, 0.8610], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([155.8557, 163.4888], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.0831, 2.3573], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2499, -2.5752], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.0661, 3.4912], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.01011284813284874\n",
            "\n",
            "gradient max : tensor(0.0082)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(0.9245)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([212.0123, 261.5967], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9494, 1.1451], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6374, -0.6742], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([173.6974, 207.3876], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9494, 1.1451], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([147.6118, 184.6872], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9494, 1.1451], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([147.6118, 184.6872], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.4044, 3.6428], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.6704, -3.7265], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.5933, 5.2112], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.0034315611701458693\n",
            "\n",
            "gradient max : tensor(0.0081)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(0.5888)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([236.9645, 223.8824], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0030, 1.1400], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6420, -0.6102], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([193.0955, 180.2140], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0030, 1.1400], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([170.5146, 157.3587], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0030, 1.1400], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([170.5146, 157.3587], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.0306, 2.1269], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2943, -2.4688], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.0638, 3.2586], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.0115968594327569\n",
            "\n",
            "gradient max : tensor(0.0054)\n",
            "gradient min : tensor(3.3286e-06)\n",
            "gradient l2norm : tensor(1.0400)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([163.1357, 233.3550], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9065, 0.9612], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5537, -0.6856], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([136.5773, 188.8605], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9065, 0.9612], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([114.1251, 162.9125], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9065, 0.9612], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([114.1251, 162.9125], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1764, 2.4626], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2190, -2.5856], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.1082, 3.5707], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.009329375810921192\n",
            "\n",
            "gradient max : tensor(0.0263)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.6081)\n",
            "\n",
            "Average batch loss : 0.009141824347898364\n",
            "\n",
            "========= Epoch50 =========\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([163.1357, 261.5967], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9068, 1.1453], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.5537, -0.6742], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([136.6007, 207.4852], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9068, 1.1453], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([114.1536, 184.7980], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9068, 1.1453], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([114.1536, 184.7980], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.2183, 3.5667], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.2609, -3.6503], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.1674, 5.1036], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch1 loss : 0.006006368901580572\n",
            "\n",
            "gradient max : tensor(0.0143)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(0.8497)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([212.0123, 233.3550], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9503, 0.9617], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6374, -0.6856], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([173.7959, 188.9208], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9503, 0.9617], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([147.7285, 162.9826], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9503, 0.9617], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([147.7285, 162.9826], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.4898, 2.5432], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.7559, -2.6662], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.7140, 3.6846], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch2 loss : 0.005353277549147606\n",
            "\n",
            "gradient max : tensor(0.0143)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(1.0946)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([203.0964, 232.2669], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.0776, 0.9962], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6250, -0.5668], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([164.1180, 185.2772], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.0776, 0.9962], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([144.7322, 162.6406], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.0776, 0.9962], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([144.7322, 162.6406], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.2959, 1.9751], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.4224, -2.1096], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.3376, 2.8899], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch3 loss : 0.012789302505552769\n",
            "\n",
            "gradient max : tensor(0.0166)\n",
            "gradient min : tensor(0.0003)\n",
            "gradient l2norm : tensor(2.6326)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([223.8824, 236.9645], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([1.1405, 1.0034], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6102, -0.6420], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([180.3644, 193.2564], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([1.1405, 1.0034], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([157.5316, 170.6977], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([1.1405, 1.0034], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([157.5316, 170.6977], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1037, 2.0695], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.4458, -2.3334], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.2261, 3.1189], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch4 loss : 0.011341754347085953\n",
            "\n",
            "gradient max : tensor(0.0050)\n",
            "gradient min : tensor(2.5388e-06)\n",
            "gradient l2norm : tensor(0.9638)\n",
            "\n",
            "input size : torch.Size([2, 3, 244, 244])\n",
            "input max : tensor([1., 1.], device='cuda:0')\n",
            "input min : tensor([0., 0.], device='cuda:0')\n",
            "input l2norm : tensor([220.2781, 229.3072], device='cuda:0')\n",
            "conv size : torch.Size([2, 5, 244, 244])\n",
            "conv max : tensor([0.9005, 0.8627], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv min : tensor([-0.6491, -0.6172], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv l2norm : tensor([182.3256, 188.6683], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out size : torch.Size([2, 5, 244, 244])\n",
            "conv_out max : tensor([0.9005, 0.8627], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "conv_out min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "conv_out l2norm : tensor([156.1204, 163.7621], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input size : torch.Size([2, 297680])\n",
            "fc_input max : tensor([0.9005, 0.8627], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_input min : tensor([0., 0.], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_input l2norm : tensor([156.1204, 163.7621], device='cuda:0',\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_logit size : torch.Size([2, 2])\n",
            "fc_logit max : tensor([2.1565, 2.2995], device='cuda:0', grad_fn=<AmaxBackward0>)\n",
            "fc_logit min : tensor([-2.3234, -2.5177], device='cuda:0', grad_fn=<AminBackward0>)\n",
            "fc_logit l2norm : tensor([3.1699, 3.4098], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "\n",
            "batch5 loss : 0.009663889184594154\n",
            "\n",
            "gradient max : tensor(0.0050)\n",
            "gradient min : tensor(0.)\n",
            "gradient l2norm : tensor(0.7585)\n",
            "\n",
            "Average batch loss : 0.009030918497592211\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9jhRSFG0iDrw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}