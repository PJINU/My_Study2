{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_1_Loss_Function.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_69jtknXNPhR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ex = torch.randn((1,3,244,244))\n",
        "input_ex.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOY-Jq1eNX0c",
        "outputId": "2a859467-ce4b-445f-9acd-b85f190b08ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 244, 244])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 가져오기"
      ],
      "metadata": {
        "id": "Fp_5M5zCSywj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.frame import DataFrame\n",
        "paths = []\n",
        "dataset_type = []\n",
        "labels = []\n",
        "\n",
        "for dirname, _, filenames in os.walk('/content/drive/MyDrive/고모부_머신러닝/dogncat'):\n",
        "    for filename in filenames:\n",
        "        filepath = dirname + '/' + filename\n",
        "        paths.append(filepath)\n",
        "\n",
        "        if '/training_set' in filepath:\n",
        "            dataset_type.append('train')\n",
        "\n",
        "        elif '/test_set' in filepath:\n",
        "            dataset_type.append('test')\n",
        "\n",
        "        if 'dogs' in filepath:\n",
        "            labels.append('DOG')\n",
        "        \n",
        "        elif 'cats' in filepath:\n",
        "            labels.append('CAT')"
      ],
      "metadata": {
        "id": "7LzvCT3ROcIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cat n Dog 데이터를 데이터 프레임으로 만들기(path, datatype, label)\n",
        "cnd_df = pd.DataFrame({'path' : paths, 'type' : dataset_type, 'label' : labels})\n",
        "\n",
        "# '.jpg'를 포함하는 path만 df로 만들기\n",
        "filter = cnd_df['path'].str.contains('.jpg') \n",
        "cnd_df = cnd_df[filter]\n",
        "\n",
        "# train, testset으로 분리\n",
        "train_df = cnd_df[cnd_df['type'] == 'train']\n",
        "test_df = cnd_df[cnd_df['type'] == 'test']\n",
        "\n",
        "train_path = train_df['path'].values\n",
        "test_path = test_df['path'].values\n",
        "\n",
        "train_label = train_df['label'].values\n",
        "test_label = test_df['label'].values\n"
      ],
      "metadata": {
        "id": "eWDq2CnEOpqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAgbqtcBghu5",
        "outputId": "2679f8f2-8f1b-4eab-f1a7-9d69cb492adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['CAT', 'CAT', 'CAT', ..., 'DOG', 'DOG', 'DOG'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_train_label = torch.tensor(pd.get_dummies(train_df['label']).values, dtype=torch.float32)\n",
        "onehot_test_label = torch.tensor(pd.get_dummies(test_df['label']).values, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "ob_eZW979raf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_label_indices = train_df['label'].replace(['CAT', 'DOG'], [0,1]).values\n",
        "print(train_label_indices)\n",
        "test_label_indices = test_df['label'].replace(['CAT', 'DOG'], [0,1]).values\n",
        "print(test_label_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bHCyblogSgB",
        "outputId": "701cdf1a-dd4a-4937-dce1-f36ba5f959fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 1 1 1]\n",
            "[0 0 0 ... 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Dataset만들기"
      ],
      "metadata": {
        "id": "ghuc8aUjS1kX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, path, label):\n",
        "        super(MyDataset, self).__init__()\n",
        "        self.paths = path\n",
        "        self.labels = label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = cv2.cvtColor(cv2.imread(self.paths[idx]), cv2.COLOR_BGR2RGB)\n",
        "        image = cv2.resize(image, (244,244))\n",
        "        image = np.asarray(image, dtype=np.float32).transpose(2,0,1)\n",
        "\n",
        "        if self.labels is not None:\n",
        "            label = self.labels[idx]\n",
        "\n",
        "        return image, label\n",
        "\n"
      ],
      "metadata": {
        "id": "wBCs8X0rOvH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 만들기"
      ],
      "metadata": {
        "id": "wl7vmRgRhUds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.hidden1 = nn.Conv2d(3, 5, kernel_size=3, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.fc1 = nn.Linear(3*244*244 ,2)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        print('input shape:', x.shape)\n",
        "        print(' input max : ', torch.amax(x, dim=(1,2,3)))\n",
        "        print(' input min : ', torch.amin(x, dim=(1,2,3)))\n",
        "        print(' input l2norm : ', torch.linalg.vector_norm(x, dim=(1,2,3)))\n",
        "\n",
        "        # hidden layer\n",
        "        conv = self.hidden1(x)\n",
        "        print('conv result shape :', conv.shape)\n",
        "        print(' conv max : ', torch.amax(conv, dim=(1,2,3)))\n",
        "        print(' conv min : ', torch.amin(conv, dim=(1,2,3)))\n",
        "        print(' conv l2norm : ', torch.linalg.vector_norm(conv, dim=(1,2,3)))\n",
        "        conv_out = self.relu(conv)\n",
        "        print('conv_out shape :', conv_out.shape)\n",
        "        print(' conv_out max : ', torch.amax(conv_out, dim=(1,2,3)))\n",
        "        print(' conv_out min : ', torch.amin(conv_out, dim=(1,2,3)))\n",
        "        print(' conv_out l2norm : ', torch.linalg.vector_norm(conv_out, dim=(1,2,3)))\n",
        "\n",
        "        fc_input = x.view(x.size(0), -1)\n",
        "        print('fc_input shape :', fc_input.shape)\n",
        "        print(' fc_input max : ', torch.amax(fc_input, dim=1))\n",
        "        print(' fc_input min : ', torch.amin(fc_input, dim=1))\n",
        "        print(' fc_input l2norm : ', torch.linalg.vector_norm(fc_input, dim=1))\n",
        "\n",
        "        # output layer\n",
        "        fc_logit = self.fc1(fc_input)\n",
        "        print('fc_logit shape :', fc_logit.shape)\n",
        "        print(' fc_logit max : ', torch.amax(fc_logit, dim=1))\n",
        "        print(' fc_logit min : ', torch.amin(fc_logit, dim=1))\n",
        "        print(' fc_logit l2norm : ', torch.linalg.vector_norm(fc_logit, dim=1))\n",
        "        fc_output = self.softmax(fc_logit)\n",
        "        print('fc_output :', fc_output)\n",
        "        print('fc_output shape :', fc_output.shape)\n",
        "        print(' fc_output max : ', torch.amax(fc_output, dim=1))\n",
        "        print(' fc_output min : ', torch.amin(fc_output, dim=1))\n",
        "        print(' fc_output l2norm : ', torch.linalg.vector_norm(fc_output, dim=1))\n",
        "\n",
        "        return fc_logit\n",
        "        "
      ],
      "metadata": {
        "id": "ijct1ktVOvTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn4euQOXOvWP",
        "outputId": "b142ab78-f7fc-4249-c8c3-86699f4ddc4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (hidden1): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (relu): ReLU()\n",
              "  (fc1): Linear(in_features=178608, out_features=2, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnd_dataset = MyDataset(train_path, train_label_indices)\n",
        "loader = DataLoader(cnd_dataset, batch_size=10, shuffle=True)\n",
        "image_data, label_data = next(iter(loader))\n",
        "print(image_data.view(image_data.size(0), -1))\n",
        "print(label_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lt-7CvgROvZa",
        "outputId": "73442f5c-7e39-4fbd-a0cc-4e62695099e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[194., 191., 189.,  ...,  31.,  32.,  33.],\n",
            "        [ 84.,  83.,  83.,  ..., 168., 168., 168.],\n",
            "        [145., 151., 126.,  ..., 115., 114., 115.],\n",
            "        ...,\n",
            "        [ 81.,  76.,  76.,  ...,  44.,  50.,  37.],\n",
            "        [226., 252., 243.,  ...,  75.,  76.,  53.],\n",
            "        [212., 212., 213.,  ...,  96.,  92.,  94.]])\n",
            "tensor([1, 0, 1, 0, 1, 0, 0, 1, 1, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CrossEntropyLoss 사용\n",
        "- input 데이터 : raw, unnormalized data. output layer에서 activation function으로 softmax를 적용하기 전 logit을 input으로 전달한다.\n",
        "- target 데이터 : indices class. 각각의 class에 대해 index번호가 매겨진 데이터\n",
        "- 참조  \n",
        "https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html?highlight=crossentropy#torch.nn.CrossEntropyLoss"
      ],
      "metadata": {
        "id": "8w7WW0vqQlez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss(reduction='mean')\n",
        "for _ in range(5):\n",
        "    image_data, label_data = next(iter(loader))\n",
        "    hyphothesis = model(image_data)\n",
        "    loss = loss_fn(hyphothesis, label_data)\n",
        "    # print('hyphothesis :\\n' ,hyphothesis)\n",
        "    print('loss : \\n', loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syJQo3xbhovB",
        "outputId": "1cf310cf-9e7c-4c3e-d67d-475ff0b426a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape: torch.Size([10, 3, 244, 244])\n",
            " input max :  tensor([168., 255., 255., 255., 255., 220., 255., 255., 239., 238.])\n",
            " input min :  tensor([ 0.,  0.,  0.,  2., 78.,  0.,  0.,  0.,  0.,  0.])\n",
            " input l2norm :  tensor([28804.8516, 59670.8125, 59410.4062, 49933.3984, 83045.0156, 53540.6875,\n",
            "        36942.7500, 64919.6523, 64001.0039, 29392.0430])\n",
            "conv result shape : torch.Size([10, 5, 244, 244])\n",
            " conv max :  tensor([230.0371, 418.4395, 330.2481, 314.6115, 385.9077, 284.3976, 403.2035,\n",
            "        332.3542, 329.5766, 284.0697], grad_fn=<AmaxBackward0>)\n",
            " conv min :  tensor([ -96.5343, -137.6742, -167.1531,  -77.6474, -159.6629, -103.3288,\n",
            "        -134.5518, -139.8193, -134.0641, -119.0906], grad_fn=<AminBackward0>)\n",
            " conv l2norm :  tensor([22175.7344, 47443.0273, 45555.9648, 39738.1562, 64834.5117, 41881.2969,\n",
            "        28453.8242, 46941.9727, 51059.8164, 23192.2246],\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out shape : torch.Size([10, 5, 244, 244])\n",
            " conv_out max :  tensor([230.0371, 418.4395, 330.2481, 314.6115, 385.9077, 284.3976, 403.2035,\n",
            "        332.3542, 329.5766, 284.0697], grad_fn=<AmaxBackward0>)\n",
            " conv_out min :  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<AminBackward0>)\n",
            " conv_out l2norm :  tensor([21995.8535, 47102.1406, 45314.3555, 39514.4766, 64491.3164, 41650.5547,\n",
            "        28184.2734, 46717.0352, 50757.6133, 23045.4043],\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input shape : torch.Size([10, 178608])\n",
            " fc_input max :  tensor([168., 255., 255., 255., 255., 220., 255., 255., 239., 238.])\n",
            " fc_input min :  tensor([ 0.,  0.,  0.,  2., 78.,  0.,  0.,  0.,  0.,  0.])\n",
            " fc_input l2norm :  tensor([28804.8516, 59670.8125, 59410.4062, 49933.3984, 83045.0156, 53540.6875,\n",
            "        36942.7500, 64919.6523, 64001.0039, 29392.0430])\n",
            "fc_logit shape : torch.Size([10, 2])\n",
            " fc_logit max :  tensor([ 36.7399,  61.1672,  39.7305,  21.0986,  86.7005,  89.3090,  -9.2816,\n",
            "         14.0445,  79.7675, -32.1178], grad_fn=<AmaxBackward0>)\n",
            " fc_logit min :  tensor([ -37.8091,  -96.3914, -124.9223, -100.2756,  -98.2516,  -49.5060,\n",
            "         -53.0465, -181.1408, -109.5127,  -97.5331], grad_fn=<AminBackward0>)\n",
            " fc_logit l2norm :  tensor([ 52.7196, 114.1610, 131.0881, 102.4712, 131.0357, 102.1124,  53.8524,\n",
            "        181.6844, 135.4839, 102.6852], grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_output : tensor([[1.0000e+00, 4.2048e-33],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 9.8427e-20],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 3.8950e-29]], grad_fn=<SoftmaxBackward0>)\n",
            "fc_output shape : torch.Size([10, 2])\n",
            " fc_output max :  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], grad_fn=<AmaxBackward0>)\n",
            " fc_output min :  tensor([4.2048e-33, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        9.8427e-20, 0.0000e+00, 0.0000e+00, 3.8950e-29],\n",
            "       grad_fn=<AminBackward0>)\n",
            " fc_output l2norm :  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "loss : \n",
            " tensor(26.6739, grad_fn=<NllLossBackward0>)\n",
            "input shape: torch.Size([10, 3, 244, 244])\n",
            " input max :  tensor([255., 255., 254., 255., 255., 255., 255., 255., 255., 255.])\n",
            " input min :  tensor([14., 44.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            " input l2norm :  tensor([48826.7148, 72493.5156, 39279.7383, 52416.1680, 39001.3203, 44903.7109,\n",
            "        57970.3867, 62514.1211, 64226.1406, 47884.2305])\n",
            "conv result shape : torch.Size([10, 5, 244, 244])\n",
            " conv max :  tensor([396.0663, 335.6042, 310.0226, 337.7081, 313.1126, 340.9229, 403.3438,\n",
            "        421.7368, 394.8657, 318.3546], grad_fn=<AmaxBackward0>)\n",
            " conv min :  tensor([-100.9955, -151.6300,  -95.6598, -130.7728,  -65.1531, -120.2372,\n",
            "        -162.9349, -167.1291, -165.8651, -168.2657], grad_fn=<AminBackward0>)\n",
            " conv l2norm :  tensor([39305.8320, 58002.8320, 30116.2012, 41251.5547, 28511.9277, 34583.8164,\n",
            "        40724.3398, 51000.1719, 50887.1445, 36011.8281],\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out shape : torch.Size([10, 5, 244, 244])\n",
            " conv_out max :  tensor([396.0663, 335.6042, 310.0226, 337.7081, 313.1126, 340.9229, 403.3438,\n",
            "        421.7368, 394.8657, 318.3546], grad_fn=<AmaxBackward0>)\n",
            " conv_out min :  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<AminBackward0>)\n",
            " conv_out l2norm :  tensor([39055.8359, 57666.7461, 29882.9824, 40976.6016, 28355.0625, 34304.8750,\n",
            "        40461.0312, 50673.9570, 50556.1367, 35784.9453],\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input shape : torch.Size([10, 178608])\n",
            " fc_input max :  tensor([255., 255., 254., 255., 255., 255., 255., 255., 255., 255.])\n",
            " fc_input min :  tensor([14., 44.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            " fc_input l2norm :  tensor([48826.7148, 72493.5156, 39279.7383, 52416.1680, 39001.3203, 44903.7109,\n",
            "        57970.3867, 62514.1211, 64226.1406, 47884.2305])\n",
            "fc_logit shape : torch.Size([10, 2])\n",
            " fc_logit max :  tensor([ 50.6798,  43.5831,  17.7870,  11.6047,  25.4708, -20.2780,   1.6920,\n",
            "         22.7005, -12.9863,  21.0880], grad_fn=<AmaxBackward0>)\n",
            " fc_logit min :  tensor([ -17.9356, -119.7381, -127.4332,  -65.1351, -112.4210,  -57.9745,\n",
            "         -81.0500,  -31.5655, -154.7339,   19.9611], grad_fn=<AminBackward0>)\n",
            " fc_logit l2norm :  tensor([ 53.7599, 127.4233, 128.6686,  66.1608, 115.2703,  61.4186,  81.0677,\n",
            "         38.8805, 155.2779,  29.0370], grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_output : tensor([[1.0000e+00, 1.5875e-30],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 4.7022e-34],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 4.2520e-17],\n",
            "        [1.0000e+00, 1.1630e-36],\n",
            "        [1.0000e+00, 2.7076e-24],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [7.5526e-01, 2.4474e-01]], grad_fn=<SoftmaxBackward0>)\n",
            "fc_output shape : torch.Size([10, 2])\n",
            " fc_output max :  tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        0.7553], grad_fn=<AmaxBackward0>)\n",
            " fc_output min :  tensor([1.5875e-30, 0.0000e+00, 0.0000e+00, 4.7022e-34, 0.0000e+00, 4.2520e-17,\n",
            "        1.1630e-36, 2.7076e-24, 0.0000e+00, 2.4474e-01],\n",
            "       grad_fn=<AminBackward0>)\n",
            " fc_output l2norm :  tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        0.7939], grad_fn=<LinalgVectorNormBackward0>)\n",
            "loss : \n",
            " tensor(55.4065, grad_fn=<NllLossBackward0>)\n",
            "input shape: torch.Size([10, 3, 244, 244])\n",
            " input max :  tensor([244., 255., 254., 255., 255., 213., 255., 255., 255., 255.])\n",
            " input min :  tensor([ 0.,  0.,  0., 29.,  0., 82., 29., 16.,  0.,  0.])\n",
            " input l2norm :  tensor([42212.0859, 61312.6641, 72828.8984, 74147.7344, 49220.1836, 61015.5859,\n",
            "        62604.3789, 80276.3281, 60630.4180, 49036.5625])\n",
            "conv result shape : torch.Size([10, 5, 244, 244])\n",
            " conv max :  tensor([265.5370, 325.0963, 368.6798, 423.4084, 325.2613, 262.6314, 353.0488,\n",
            "        406.3602, 419.6353, 395.1448], grad_fn=<AmaxBackward0>)\n",
            " conv min :  tensor([ -81.8284, -111.0248, -141.4191, -168.3868, -160.0405, -106.6159,\n",
            "        -168.4047, -168.3422, -135.1330, -167.4079], grad_fn=<AminBackward0>)\n",
            " conv l2norm :  tensor([32927.0898, 42887.3828, 56801.1992, 60157.3555, 39376.4570, 48324.4766,\n",
            "        49770.3633, 62607.6758, 46284.1172, 35284.1719],\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out shape : torch.Size([10, 5, 244, 244])\n",
            " conv_out max :  tensor([265.5370, 325.0963, 368.6798, 423.4084, 325.2613, 262.6314, 353.0488,\n",
            "        406.3602, 419.6353, 395.1448], grad_fn=<AmaxBackward0>)\n",
            " conv_out min :  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<AminBackward0>)\n",
            " conv_out l2norm :  tensor([32724.8379, 42619.0234, 56493.9570, 59772.0039, 39036.7891, 48058.1055,\n",
            "        49473.3984, 62224.8945, 45991.6953, 35096.1758],\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input shape : torch.Size([10, 178608])\n",
            " fc_input max :  tensor([244., 255., 254., 255., 255., 213., 255., 255., 255., 255.])\n",
            " fc_input min :  tensor([ 0.,  0.,  0., 29.,  0., 82., 29., 16.,  0.,  0.])\n",
            " fc_input l2norm :  tensor([42212.0859, 61312.6641, 72828.8984, 74147.7344, 49220.1836, 61015.5859,\n",
            "        62604.3789, 80276.3281, 60630.4180, 49036.5625])\n",
            "fc_logit shape : torch.Size([10, 2])\n",
            " fc_logit max :  tensor([-13.2974,  -4.4713,  93.8073,  80.9862, -58.1086,  55.8318,  21.7065,\n",
            "        112.6756,  29.5952,  24.0450], grad_fn=<AmaxBackward0>)\n",
            " fc_logit min :  tensor([-121.1839,  -96.6235,  -49.5629,  -67.9185,  -67.6970,  -80.5562,\n",
            "        -125.4031,  -99.5945, -130.5282,  -67.4233], grad_fn=<AminBackward0>)\n",
            " fc_logit l2norm :  tensor([121.9113,  96.7269, 106.0957, 105.6962,  89.2159,  98.0127, 127.2679,\n",
            "        150.3823, 133.8413,  71.5826], grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_output : tensor([[1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 9.5236e-41],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [9.9993e-01, 6.8515e-05],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 1.8873e-40]], grad_fn=<SoftmaxBackward0>)\n",
            "fc_output shape : torch.Size([10, 2])\n",
            " fc_output max :  tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000], grad_fn=<AmaxBackward0>)\n",
            " fc_output min :  tensor([0.0000e+00, 9.5236e-41, 0.0000e+00, 0.0000e+00, 6.8515e-05, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8873e-40],\n",
            "       grad_fn=<AminBackward0>)\n",
            " fc_output l2norm :  tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000], grad_fn=<LinalgVectorNormBackward0>)\n",
            "loss : \n",
            " tensor(64.2029, grad_fn=<NllLossBackward0>)\n",
            "input shape: torch.Size([10, 3, 244, 244])\n",
            " input max :  tensor([253., 255., 255., 237., 255., 239., 255., 255., 255., 255.])\n",
            " input min :  tensor([ 0.,  6.,  3., 14.,  0.,  3.,  0.,  5.,  0.,  0.])\n",
            " input l2norm :  tensor([37693.2148, 73266.7188, 60724.3242, 64710.3125, 29217.8594, 63892.8633,\n",
            "        43669.9883, 59894.7617, 60594.6406, 59926.1953])\n",
            "conv result shape : torch.Size([10, 5, 244, 244])\n",
            " conv max :  tensor([331.1933, 422.9358, 319.5015, 365.8453, 419.8006, 320.8896, 326.6455,\n",
            "        311.8033, 356.6243, 421.7537], grad_fn=<AmaxBackward0>)\n",
            " conv min :  tensor([-124.4811, -168.2548, -147.4993, -146.5017,  -70.2753, -143.8624,\n",
            "        -125.0409, -113.6219, -155.8991, -164.5722], grad_fn=<AminBackward0>)\n",
            " conv l2norm :  tensor([28374.5996, 54289.7344, 48799.9648, 52417.8711, 20737.8848, 50096.1094,\n",
            "        32862.7852, 47152.2656, 48028.2539, 44744.1914],\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out shape : torch.Size([10, 5, 244, 244])\n",
            " conv_out max :  tensor([331.1933, 422.9358, 319.5015, 365.8453, 419.8006, 320.8896, 326.6455,\n",
            "        311.8033, 356.6243, 421.7537], grad_fn=<AmaxBackward0>)\n",
            " conv_out min :  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<AminBackward0>)\n",
            " conv_out l2norm :  tensor([28160.7422, 54012.5703, 48475.2148, 52017.2422, 20610.9199, 49822.4766,\n",
            "        32449.5918, 46883.4492, 47724.5273, 44440.7617],\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input shape : torch.Size([10, 178608])\n",
            " fc_input max :  tensor([253., 255., 255., 237., 255., 239., 255., 255., 255., 255.])\n",
            " fc_input min :  tensor([ 0.,  6.,  3., 14.,  0.,  3.,  0.,  5.,  0.,  0.])\n",
            " fc_input l2norm :  tensor([37693.2148, 73266.7188, 60724.3242, 64710.3125, 29217.8594, 63892.8633,\n",
            "        43669.9883, 59894.7617, 60594.6406, 59926.1953])\n",
            "fc_logit shape : torch.Size([10, 2])\n",
            " fc_logit max :  tensor([ 7.2167, 53.9353, 52.4539, 91.1292, -1.6292, 71.5502, 11.6454, 52.5154,\n",
            "        75.4753, 58.2709], grad_fn=<AmaxBackward0>)\n",
            " fc_logit min :  tensor([ -93.1505,  -94.0066,  -76.1799,  -99.8726,  -75.1655,  -93.2703,\n",
            "         -44.0917, -135.1423,  -66.2874, -146.2585], grad_fn=<AminBackward0>)\n",
            " fc_logit l2norm :  tensor([ 93.4297, 108.3802,  92.4921, 135.2001,  75.1831, 117.5533,  45.6037,\n",
            "        144.9872, 100.4516, 157.4390], grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_output : tensor([[1.0000e+00, 2.5223e-44],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 1.1577e-32],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 6.2181e-25],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
            "fc_output shape : torch.Size([10, 2])\n",
            " fc_output max :  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], grad_fn=<AmaxBackward0>)\n",
            " fc_output min :  tensor([2.5223e-44, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1577e-32, 0.0000e+00,\n",
            "        6.2181e-25, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "       grad_fn=<AminBackward0>)\n",
            " fc_output l2norm :  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "loss : \n",
            " tensor(59.3507, grad_fn=<NllLossBackward0>)\n",
            "input shape: torch.Size([10, 3, 244, 244])\n",
            " input max :  tensor([215., 190., 255., 255., 255., 253., 255., 207., 255., 255.])\n",
            " input min :  tensor([0., 0., 0., 0., 1., 0., 0., 4., 0., 0.])\n",
            " input l2norm :  tensor([55028.6133, 47262.8477, 48402.0977, 51494.1289, 83285.7031, 62870.5664,\n",
            "        63357.6445, 58079.8477, 68245.4062, 56190.2656])\n",
            "conv result shape : torch.Size([10, 5, 244, 244])\n",
            " conv max :  tensor([250.0855, 299.4852, 419.3487, 321.9107, 421.8020, 340.3995, 358.5607,\n",
            "        310.5958, 348.7572, 306.4103], grad_fn=<AmaxBackward0>)\n",
            " conv min :  tensor([-103.5757, -121.0493, -163.4589, -128.5349, -164.7753, -152.8590,\n",
            "        -114.6959, -127.9486, -119.7966,  -60.4630], grad_fn=<AminBackward0>)\n",
            " conv l2norm :  tensor([41283.6992, 38043.9062, 40215.9766, 39415.7773, 66494.2891, 49043.7109,\n",
            "        48844.0469, 46208.3945, 53090.0547, 42094.5586],\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "conv_out shape : torch.Size([10, 5, 244, 244])\n",
            " conv_out max :  tensor([250.0855, 299.4852, 419.3487, 321.9107, 421.8020, 340.3995, 358.5607,\n",
            "        310.5958, 348.7572, 306.4103], grad_fn=<AmaxBackward0>)\n",
            " conv_out min :  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<AminBackward0>)\n",
            " conv_out l2norm :  tensor([41077.2852, 37818.3984, 39911.2617, 39134.9492, 66130.6797, 48711.4062,\n",
            "        48570.0000, 45932.3477, 52749.7461, 41885.7031],\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_input shape : torch.Size([10, 178608])\n",
            " fc_input max :  tensor([215., 190., 255., 255., 255., 253., 255., 207., 255., 255.])\n",
            " fc_input min :  tensor([0., 0., 0., 0., 1., 0., 0., 4., 0., 0.])\n",
            " fc_input l2norm :  tensor([55028.6133, 47262.8477, 48402.0977, 51494.1289, 83285.7031, 62870.5664,\n",
            "        63357.6445, 58079.8477, 68245.4062, 56190.2656])\n",
            "fc_logit shape : torch.Size([10, 2])\n",
            " fc_logit max :  tensor([ 48.2994,  45.4610,  75.0258,  50.9090, 123.8790,  64.7590,  78.7893,\n",
            "         76.1881,  20.0692,  -8.8067], grad_fn=<AmaxBackward0>)\n",
            " fc_logit min :  tensor([ -73.2020,  -25.1274,    2.8360,  -78.1375,   18.8790,  -76.3122,\n",
            "        -105.0295,  -66.4759, -110.6431, -112.8051], grad_fn=<AminBackward0>)\n",
            " fc_logit l2norm :  tensor([ 87.7004,  51.9431,  75.0794,  93.2587, 125.3093, 100.0864, 131.2972,\n",
            "        101.1122, 112.4486, 113.1483], grad_fn=<LinalgVectorNormBackward0>)\n",
            "fc_output : tensor([[1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 2.2073e-31],\n",
            "        [1.0000e+00, 4.4498e-32],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
            "fc_output shape : torch.Size([10, 2])\n",
            " fc_output max :  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], grad_fn=<AmaxBackward0>)\n",
            " fc_output min :  tensor([0.0000e+00, 2.2073e-31, 4.4498e-32, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "       grad_fn=<AminBackward0>)\n",
            " fc_output l2norm :  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       grad_fn=<LinalgVectorNormBackward0>)\n",
            "loss : \n",
            " tensor(66.8790, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.exp(torch.tensor(26.6739))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-BtZzHplNin",
        "outputId": "5d64c698-e33a-4c8b-b27f-fcb3c883405f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.8400e+11)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CrossEntropyLoss 예제(pytorch document)"
      ],
      "metadata": {
        "id": "Lfx4--yzK1Hc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_p = nn.CrossEntropyLoss(reduction='mean')\n",
        "input = torch.randn(3, 5, requires_grad=True)\n",
        "target = torch.empty(3, dtype=torch.long).random_(5)\n",
        "output = loss_p(input, target)"
      ],
      "metadata": {
        "id": "e_tYllFdnjMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input)\n",
        "print()\n",
        "print(target)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NReP75B1AGGl",
        "outputId": "42b5f7db-f84a-48d0-aa55-668e5ff12ce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0585, -0.1539,  0.2935, -0.6673,  0.9894],\n",
            "        [ 2.1771, -0.1619, -0.2550,  0.0030, -1.6859],\n",
            "        [ 0.5653, -0.9964, -0.5865, -0.8744, -1.6881]], requires_grad=True)\n",
            "\n",
            "tensor([3, 0, 2])\n",
            "tensor(1.5228, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target2 = torch.randn(3,5).softmax(dim=1)\n",
        "output2 = loss(input, target2)\n",
        "\n",
        "print(target2)\n",
        "print(output2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7xm5M6WAHgz",
        "outputId": "c9a2c186-2ce7-4f1d-d049-3fd206beb4b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2395, 0.1087, 0.0064, 0.1246, 0.5209],\n",
            "        [0.0881, 0.1126, 0.5270, 0.0960, 0.1763],\n",
            "        [0.1382, 0.0414, 0.2380, 0.4794, 0.1029]])\n",
            "tensor(1.6698, grad_fn=<DivBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "normalized -> 0~1사이의 값으로 만들어주는 것"
      ],
      "metadata": {
        "id": "sGbpM1TBE_LP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "scheduler method = linear.  \n",
        "optimizer = SGD(lr : 0.001).  \n",
        "1step training\n"
      ],
      "metadata": {
        "id": "uhofE2-QPAVc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### softmax\n",
        "공식\n",
        "$$Softmax(x_i) = {\\exp(x_i) \\over\\sum_{j=1}^{n} \\exp(x_j)}$$\n",
        "n = class 개수"
      ],
      "metadata": {
        "id": "x3FrEY1wl4Q7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 엔트로피\n",
        "- ex) 따뜻한 물과 차가운 물을 섞을 경우\n",
        "    - 섞기 전 : 엔트로피 min\n",
        "    - 완전히 섞은 후 : 엔트로피 max\n",
        "\n",
        "- Uniform probalility Distribution\n",
        "    - 치우치지 않고 완벽하게 섞인 상태. 즉, 어떤 사건이 발생할 확률이 동일한 상태\n",
        "    - Maximum entropy\n",
        "\n",
        "- Expectation 공식\n",
        "$$E(x) = \\sum_{i=1}^{n} x_i p(x_i)  $$\n",
        "    - ex) X = {x1, x2}, x1 = 1, x2 = 0  \n",
        "\\begin{align}\n",
        "E(X) \n",
        "& = \\sum_{i=1}^{2} x_i p(x_i)\\\\\n",
        "& = x_1 p(x_1) + x_2 p(x_2)\\\\\n",
        "& = x_1 p(x_1) + (1 - x_2)) p(x_2)\\\\\n",
        "\\end{align}\n",
        "\n",
        "- Entorpy 공식\n",
        "$$E(X) = \\sum_{i=1}^{n} p(x_i) log_2(1/p(x_i))$$\n",
        "    - 데이터를 비트로 표현한 것 :  $$log_2(1/p(x_i))$$\n",
        "    - 즉, 엔트로피는 데이터를 표현하는 비트 개수의 평균이라고 할 수 있다?"
      ],
      "metadata": {
        "id": "9w5RvcwoJu_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GKG-e2BzK-kT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}